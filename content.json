{"meta":{"title":"程序猿升级课","subtitle":null,"description":"本站是程序猿升级课（刘鑫）的技术分享博客。内容涵盖Java后端技术、Spring Boot、Spring Cloud、微服务架构、系统监控等相关的研究与知识分享。","author":"liuxin","url":"https://blog.springlearn.cn"},"pages":[],"posts":[{"title":"Python报表API之Pyecharts使用","slug":"Python报表API之Pyecharts使用","date":"2018-06-28T07:16:06.000Z","updated":"2018-06-28T07:21:21.165Z","comments":true,"path":"2018/06/28/Python报表API之Pyecharts使用/","link":"","permalink":"https://blog.springlearn.cn/2018/06/28/Python报表API之Pyecharts使用/","excerpt":"","text":"今天给大家介绍一个制作报表的API工具,语言是Python,是小编平时做报表用的,主要是以图片的形式分享,因为头条放代码排版会很乱,今天把他分享出来。如果想要代码的话,私信发送报表。 目录 安装pyecharts库 环形图 条形图 折线图 雷达图 水球图 词云 1.安装pyecharts库 2. 环形图 3. 条形图 4. 折线图 5. 雷达图 6. 水球图 7. 词云","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blog.springlearn.cn/tags/python/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"Java多线程之隔离技术ThreadLocal源码详解","slug":"Java多线程之隔离技术ThreadLocal源码详解","date":"2018-06-26T14:47:48.000Z","updated":"2018-06-26T14:57:08.742Z","comments":true,"path":"2018/06/26/Java多线程之隔离技术ThreadLocal源码详解/","link":"","permalink":"https://blog.springlearn.cn/2018/06/26/Java多线程之隔离技术ThreadLocal源码详解/","excerpt":"","text":"本篇文章是对ThreadLocal和InheritableThreadLocal,TransmittableThreadLocal的原理和源码进行深入分析,并举例讲解,其中前两个是JDK自带的。原理相对比较简单,其解决了单线程环境和在单线程中又创建线程(父子线程)中线程隔离的问题, TransmittableThreadLocal主要是解决,线程池中线程复用的场景。全文涉及到源码比较多阅读起来需要动脑筋思考,文章前半部分比较简单,后半部分比较困难,注意看代码注释。有不懂的可以留言。 以上是百度百科检索到的描述,相信通过上面的描述大家已经有了一个大概的了解,也相信大多数开发人员对这个类也是比较了解的,小编首先从原理开始讲解,开始吧! 目录 使用原理简介 根据JDK原理,自己实现一个 单线程隔离 父子线程隔离 线程池线程复用隔离 抛出问题和总结，让你更深入了解细节 1. ThreadLocal 的原理是什么呢 ?其实就相当于一个Map集合,只不过这个Map 的Key是固定的,都是当前线程。它能解决什么问题呢? 它存在的价值是什么呢? 它的存在就是为了线程隔离,让每个线程都能拥有属于自己的变量空间,线程之间互相不影响,为什么这么说呢? 看下代码就明白 通过上面的代码,可以发现其实ThreadLocal的set()方法就相当于 之所以能起到线程隔离的作用,是因为Key就是当前的线程,所以每个线程的值都是隔离的，就像上图那样。 其实并不是这样简单,之所以这样讲是为了,大家理解,其实这里的核心点在getMap中,从Thread中拿到一个Map，然后把value放到这个线程的map中 因为每个线程都有一个自己的Map，也就是threadLocals。从而起到了线程隔离的作用 2. 根据JDK原理,自己实现一个类似的 测试用例 Result: 3. 单线程隔离什么是单线程隔离，这个是小编自己想的名字,其实是为了和父子线程区分开来，上面我们演示的都是属于在单一线程的情况下的使用。 4.父子线程隔离什么是父子线程,需要解释下是，当我们创建一个线程,在线程内有去运行另一个线程的时候，作为子线程，如何去拿到父线程的私有属性呢? 我们怎么能拿到父线程的属性呢? 我们看前面标记的①,在get()时候有一个getMap(),在②有一个createMap方法 既然我们想拿到父线程的私有变量,那我们想在线程内创建线程时候,子线程能不能拿到父线程的的私有变量呢? 答案:当然是可以的, 我们看Thread的源码的时候，可以找到这样两个属性 那么它是如何实现继承的呢？我们可以在Thread的构造初始化init方法中，找到答案 看到这里我们分析，为什么ThreadLocal不能把父线程的私有变量传递给子线程? 因为getMap和createMap都是对threadLocals进行操作，而threadLocals变量是不能被继承的。 那么我们怎么去实现能传递呢? 其实JDK是为我们实现了一套的,这个类就是InheritableThreadLocal,我们看他为什么能实现呢? 在看代码前，我们先自己思考下，是不是InheritableThreadLocal操作的是可继承的字段inheritableThreadLocals呢？答案也是肯定的 在父线程内创建子线程的时候,子线程会在拿到父线程中的可继承的私有变量空间属性,也就是inheritableThreadLocals字段。 测试用例 5. 线程池线程复用隔离在解决上面的问题后，我们来研究一个更有难度的问题,就是线程池线程复用的情况，怎么实现? 为什么会遇到这个问题呢? 是因为在线程池中核心线程用完，并不会直接被回收,而是返回到线程池中，既然是重新利用， 那么久不会重新创建线程，不会创建线程，父子之间就不会传递(如果这点没有明白,请继续看上面父子线程)。 那么这时父子线程关系的ThreadLocal值传递已经没有意义。 那么根据这个原理 ，我们继续来深入研究一波。 解决方案是什么呢？ 123在submit的时候把父线程copy给子线程在execute的时候结束后吧线程的ThreadLocal清理，就能解决这个问题 上面是网上搜到的答案，小编在证实上面答案的时候走了很多坑，根本没有找到清理的代码。最后小编发现,根本就没有清理的代码，而是重新赋值的形式来实现清理。 到底是怎么来实现的呢？我们看TransmittableThreadLocal核心代码 拿到创建线程时候的备份所有线程空间 【深复制】因为浅复制会结果会被修改 在执行时候将之前的备份恢复，将最新的值返回到backup变量中 执行完成后，再将backup最新的值重新写入到TransmittableThreadLocal中 代码看起来很简洁，但是理解起来并不容易，每一步都有很多细节？我们一个一个来看 copy方法。 TransmittableThreadLocal内维护了一个holder保存所有TransmittableThreadLocal实例当set时候addValue方法 如果还没添加就添加，null在这里只是占位,没有其他用，因为this就包含了所有值 copy方法就是将holder里面维护的TransmittableThreadLocal实例和值通过深复制的形式返回，为什么是深复制,因为引用复制可能会在其他地方值被修改。 backupAndSetToCopied方法从copide中恢复数据，然后新值返回出去，放到backup变量中 当线程已经执行完，在调用restoreBackup方法恢复backup变量中的值。 这点理解其他优点困难，尽管小编已经很努力的讲清楚，但是可以通过下面一个例子可以将以上几种方法的用处讲清。 请注意文中的注释! 问题子线程修改变量空间值，是否会影响父线程值？ 答案：当然影响。因为子线程获取父线程的inheritableThreadLocals时候，方法ThreadLocal.createInheritedMap(parent.inheritableThreadLocals)其实是浅复制，也就是引用复制，其主要用途是从key.childValue，就是运行ThreadLocal的继承者，重写childValue方法，从而能改变父线程的本地空间ThreadLocal 交给子类去实现了 总结: ThreadLocal 基础实现 (原理: 保存着线程中) inheritableThreadLocals 实现了父子直接的传递 （原理: 可继承的变量空间,在Thread初始化init方法时候给子赋值） TransmittableThreadLocal 实现线程复用 (原理: 在每次线程执行时候重新给ThreadLocal赋值) 好了，时间不早了， 今天的课程到此。 喜欢的童鞋请点击关注，谢谢你的支持。 没有任何广告，纯粹分析技术，一起共同成长进步 。","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://blog.springlearn.cn/categories/源码阅读/"}],"tags":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://blog.springlearn.cn/tags/源码阅读/"}],"keywords":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://blog.springlearn.cn/categories/源码阅读/"}]},{"title":"Springboot2.0中webflux到底优秀在哪里","slug":"Springboot2-0中webflux到底优秀在哪里","date":"2018-06-26T14:39:16.000Z","updated":"2018-06-26T14:44:20.000Z","comments":true,"path":"2018/06/26/Springboot2-0中webflux到底优秀在哪里/","link":"","permalink":"https://blog.springlearn.cn/2018/06/26/Springboot2-0中webflux到底优秀在哪里/","excerpt":"","text":"Spring-boot-webflux中所说的反应堆式编程reactor到底优秀在哪里？ 小编的Springboot2.0的课程已经快全部写完了。总结来看，对于有基础的同学学习难度不是很大,一周内就能上手。但是在小编看来编程如果说只会用,而不了解其编程模型和这样设计的好处，其实对于开发人员来说，并没有多大的收获！所以为了让感兴趣的同学对2.0编程模型反应式编程和Mono，Flux有一个清醒的认识，减少后面的学习难度。小编我总结了这篇文章。文章概念性东西比较多,希望大家有所收获! 目录 什么是反应式编程(Reactive)？ 反应式的编程模型的好处是什么？ 代码如何去实现反应式编程? Mono和Flux常用API Mono和Flux在Webflux中的用处？ 1.什么是反应式编程(Reactive)？Reactive小编理解下来就是基于事件驱动(事件模式或者说订阅者模式)，类似于Netty异步事件编程模型，对不同的事件做不同的处理。所有信息都通过一个编程模型处理，就像水在管道里面运动一样（这里把事件比作水流） 所有的信息都封装成一个Channel,这个channel就像在管道中流动一样,被管道中的这些处理器所处理。 比如大名鼎鼎的React 前端框架配合redux 流模型，将服务器返回的信息包装成action数据流，然后根据action去映射到页面上，页面随着action的改变而改变。页面和数据就相当于这管道中的东西，被一层一层的梳理，展示。 2. 反应式的编程模型的好处是什么？为了给各位看官充分证明其好处，我们先来分析下传统的模式有哪些不足！ 作为Java web开发人员，我们写的最多的代码都是放在web容器中tomcat中运行的，Tomcat就是基于Servelt运行的,我们回顾下Servlet的知识,可能我们最熟悉的就是HttpServletRequest，和HttpServletResponse 当你脑子中有Servlet的概念就好理解了。 Servlet3.0之前 线程会一直阻塞，只有当业务处理完成并返回后时结束 Servlet线程。 3.0规范其中一个新特性是异步处理支持,即是在接收到请求之后，Servlet 线程可以将耗时的操作委派给另一个线程来完成，在不生成响应的情况下返回至容器 这样说可能大家还不太容易理解，我们来举一个例子(这点引用小编之前写的文章)SpringBoot2.0之WebFlux解析及实战eg： 我们假设,设置tomcat最大线程为200,遇到200个非常耗时的请求 那么当有200个线程同时并发在处理,那么当来201个请求的时候,就已经处理不了，因为所有的线程都阻塞了。这是3.0之前的处理情况 而3.0之后异步处理是怎样处理呢？学过Netty通信框架的同学会比较容易理解一点，Servlet3.0类似于Netty一样就一个boss线程池和work线程池，boss线程只负责接收请求,work线程只负责处理逻辑。那么servlet3.0规范中，这200个线程只负责接收请求，然后每个线程将收到的请求，转发到work线程去处理。因为这200个线程只负责接收请求，并不负责处理逻辑，故不会被阻塞，而影响通信，就算处理非常耗时，也只是对work线程形成阻塞，所以当再来请求，同样可以处理,其主要应用场景是针对业务处理较耗时的情况可以减少服务器资源的占用，并且提高并发处理速度。 3.代码如何去实现反应式编程?前面说了反应式编程可以理解为事件模式或者是订阅者模式,我们如何去实现事件模式？ 小编在这里引入两个框架或许各位看官就理解了 RxJava 下图是RxJava小编写的例子,大概描述下,事件源即使onNext方法的入参，将信息发送,消费者就是 subscribe方法，里面会对事件源做处理，onCompleted: 完成 onError:错误 Guava的EventBus实现 怎么样订阅者模式,或者是观察者模式是不是很好理解 但是我们还是觉得这种方法,太复杂了,比如我们为了扩展性,就创建了这么多类. 那么我们怎么更简单呢? 接下来介绍EventBus使用,只要掌握一个注解@Subscribe就可以了. 4.Mono和Flux常用APIMone和Flux都是数据反应式编程的核心组件，开发人员就是多利用其编写出高效率的代码 Reactor是JVM的完全非阻塞反应式编程基础，具有高效的需求管理（以管理“背压”的形式）。它直接与Java 8功能的API，特别是整合CompletableFuture，Stream和 Duration。它提供了可组合的异步序列API Flux（用于[N]元素）和Mono（用于[0 | 1]元素），广泛地实现了Reactive Extensions规范。这段的重点是和Java8结合利用lambda表达式简洁的优点。 Flux 相当于一个 RxJava Observable 观察者 观察者可以把生产者的消息Publisher,推送给消费者subscribe 我们可以把Mono理解为一个结果它对应的数据是 1，其实可以理解为对结果的一个包装 5.Mono和Flux在Webflux中的用处？更令小编感到热血沸腾的是SpringBoot2.0后可以用Netty作为web容器,我们构建一个web项目更简单了,小编曾羡慕过Node.js构建web项目的便捷，只需要10行左右代码,就能构建出一个web项目或者更短。如今我们利用SpringBoot2.0也可以了5行。 好了这篇文章就到这里了,相信你对springboot2的webflux和reactive都有一个大概的认识了，下一步学习Springboot2其他webflux组件就相对比较简单了，喜欢的童鞋点击下关注,小编会持续为你推送最新的技术文章。 Flux参考地址 以上是小编的理解，可能也不是全对，欢迎指出问题批评，技术交流,思想碰撞的火花，才能促进进步，最后小编希望和各位看官一起共同进步。","categories":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/categories/Spring-Boot2-0/"}],"tags":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/tags/Spring-Boot2-0/"}],"keywords":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/categories/Spring-Boot2-0/"}]},{"title":"SpringBoot2.0中MVC和WebFlux控制层Controller对比","slug":"SpringBoot2-0中MVC和WebFlux控制层Controller对比","date":"2018-06-26T14:34:37.000Z","updated":"2018-06-26T14:38:46.418Z","comments":true,"path":"2018/06/26/SpringBoot2-0中MVC和WebFlux控制层Controller对比/","link":"","permalink":"https://blog.springlearn.cn/2018/06/26/SpringBoot2-0中MVC和WebFlux控制层Controller对比/","excerpt":"","text":"本篇文章是SpringBoot2.0关于Controller控制层的对比，相信很多开发最好奇的也是这块。那么小编就带着大家一起先来看一下，尝尝鲜,本篇文章比较短小精悍,只讲如何使用(前面一直在讲概念,从这篇开始以后都是编程了),注意看图,至于原理剖析,后面会讲。阅读时间大概3分钟 ！ (合理利用碎片时间) 目录 演示demo目录结构 启动类 webmvc控制层 webflux控制层 总结 注意: 1,2,3,4主要是图片,主要展示demo的启动环境. 主要看3,4定义路由的方法! 和 5总结(请结合图) 1.目录结构 2.启动类定义这里为了方便看到被Spring加载到的Bean故打印了一下 3.WebMVC控制层 4.WebFlux控制层 5.总结传统Web层我们看到了熟悉的注解,不用介绍。 我们看下为什么Webflux没有用@Controller,注意这里使用配置的注解,将定义的RouterFunctions路由函数交给 Spring管理，我们这里的命名是customer-webflux-route-01 看起来都很清爽,不过有几个类，在SpringBoot1.0是没有的，这里列举一下 ServerResponse 类似于HttpServletResponse (各位童鞋应该都知道,请忽略) ServerRequest 类似于HttpServletRequest (各位童鞋应该都知道,请忽略) Mono和 Flux 反应式编程核心类上文链接介绍 Springboot2.0中webflux到底优秀在哪里 RouteFunctions 将路由和处理方法连接 HandlerFunction 处理方法 RequestPredicates 定义请求方法,对请求方法的一些定义，比如权限或者对Headers的限制 下图结合route的源码,很生动将这五个类的关系描述描述出来 通过webmvc和Webflux控制层的简单demo,和WebFlux的常用类的演示,SpringBoot2.0的功能使用大概都已经表述清楚了，细节本文不做描述,下一篇主要讲这几个核心类的API使用细节! API代码比较多,所以分两篇展示。最后谢谢你的阅读，很高兴为你的碎片时间,传播一点知识。我们下篇见!","categories":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/categories/Spring-Boot2-0/"}],"tags":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/tags/Spring-Boot2-0/"}],"keywords":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/categories/Spring-Boot2-0/"}]},{"title":"Python30行代码开发属于自己的智能微信机器人","slug":"Python30行代码开发属于自己的智能微信机器人","date":"2018-06-26T12:49:24.000Z","updated":"2018-06-28T07:16:28.192Z","comments":true,"path":"2018/06/26/Python30行代码开发属于自己的智能微信机器人/","link":"","permalink":"https://blog.springlearn.cn/2018/06/26/Python30行代码开发属于自己的智能微信机器人/","excerpt":"","text":"今天我们不做Java代码的分享,小编今天发现了一个好玩的东西,我们利用免费的图灵机器人和微信接口调用,做一个智能的微信机器人,像这样，当你不想聊天时候,把机器人启动，让朋友给你聊天。当然itchat和图灵机器人不只是玩的，我们可以做出更多有趣的应用，或者是客服系统之类。也可以调用百度的自然语言分析,做一个翻译,分词之类的应用。下面给大家介绍下。Python30行代码开发属于自己的智能微信机器人 目录 安装Python运行环境 安装微信库itchat(利用web微信接口的python调用库) 注册图灵机器人 代码示例 安装Python运行环境Mac的用户不用安装,因为系统自带有Python,如果没有可以用用 安装微信库itchat(利用web微信接口的python调用库) 注册图灵机器人可以给机器人定义名字或者是性别,及选择词库 复制下面代码即可使用(头条展示代码比较另类所以通过截图的方式,感兴趣的童鞋点击关注私信:机器人，就可获取代码)","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blog.springlearn.cn/tags/python/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"OVAL验证框架","slug":"OVAL验证框架","date":"2018-06-19T14:47:35.000Z","updated":"2018-06-19T14:48:52.895Z","comments":true,"path":"2018/06/19/OVAL验证框架/","link":"","permalink":"https://blog.springlearn.cn/2018/06/19/OVAL验证框架/","excerpt":"","text":"本篇文章没有技术点,只给各位看官介绍有这么一个东西,浏览全文预计需要1分钟,小编相信各位看官会在30s就知道是否对你有用,如果有用知道即可 功能对入参进行校验,不需要专门写校验代码,只加一个注解即可 ###使用场景 web开发controller层对入参进行校验rpc调用,对入参校验 使用前后对比图,如果看到这里你还感兴趣,那么可以继续学习! 字符类型 @AsserURL、@Email、@Length、@MaxLength、@MinLength @NotNull、@NotBlank、@NotEmpty、 @Digits、@HasSubstring: 是否包含子串 数值类型 @Range、@Max、@Min、@NotNegative 布尔类型 @AssertFalse、@AssertTrue 集合数组 @Size、@MaxSize、@MinSize、@MemberOf、@NotMemberOf 表达式或自定义 @Assert、@CheckWith、@NotMatchPatternCheck，@MatchPatternCheck、 @ValidateWithMethod","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"「涨知识」一篇文章让你了解Java核心线程池","slug":"「涨知识」一篇文章让你了解Java核心线程池","date":"2018-06-02T09:56:58.000Z","updated":"2018-06-02T10:05:21.470Z","comments":true,"path":"2018/06/02/「涨知识」一篇文章让你了解Java核心线程池/","link":"","permalink":"https://blog.springlearn.cn/2018/06/02/「涨知识」一篇文章让你了解Java核心线程池/","excerpt":"","text":"本篇文章通读时间大概3分钟,希望在三分钟内的讲解，对你有所帮助，一定要认真看并思考，好了。废话不多数，直接上干货,本节内容我们讲的是Java的线程池,在讲之前我们首先看一下有哪些线程池，这些线程池我们不过多讲解,因为我们的关注点是他们是如何实现的,和其运行的原理。 目录 常用线程池列表 ThreadPoolExecutor ThreadFactory线程工厂 RejectedExecutionHandler拒绝策略 Queue任务队列 一. 常用线程池列表这部分内容,只是帮助你回顾一下线程池的知识，大家重点看方法内的实现 1、构造一个固定线程数目的线程池，配置的corePoolSize与maximumPoolSize大小相同，同时使用了一个无界LinkedBlockingQueue存放阻塞任务，因此多余的任务将存在再阻塞队列，不会由RejectedExecutionHandler处理 2、构造一个缓冲功能的线程池，配置corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE，keepAliveTime=60s,以及一个无容量的阻塞队列 SynchronousQueue，因此任务提交之后，将会创建新的线程执行；线程空闲超过60s将会销毁 3、构造一个只支持一个线程的线程池，配置corePoolSize=maximumPoolSize=1，无界阻塞队列LinkedBlockingQueue；保证任务由一个线程串行执行 4、构造有定时功能的线程池，配置corePoolSize，无界延迟阻塞队列DelayedWorkQueue；有意思的是：maximumPoolSize=Integer.MAX_VALUE，由于DelayedWorkQueue是无界队列，所以这个值是没有意义的 二. ThreadPoolExecutor相信大家从上面的众多线程池中都已经看到了这个类,因为上面的线程池底层的构造都是由这个类创建的, 那么我们就开始研究这个类 首先看一下构造方法，关于注释一定要好好看，每个参数都理解了，那么你就弄懂了 核心的线程池 最大线程池就是说你定义的线程池运行创建的最大线程数量 空闲时间回收，当这个时间后还没有任务执行就将线程回收 单位,控制上面时间的单位，可以为秒，或者分钟 核心线程都已经去执行任务但是，任务还有，那么久先放到这个队列里，就相当于集合 创建线程用户的线程工厂,里面只有一个方法就是newThread，你可以自定义线程名 拒绝策略，当任务已经执行不了，你拒绝的策略 上面的文字可能你看的不太明白，小编这里画了一个图，大家仔细看看 三. ThreadFactoryThreadFactory有什么用呢？ 其实就是一个接口，既然是线程工厂，那么肯定就是创建线程的了 接口就是这么简单，那么我们在开发中到底有什么实际用处呢？ 下面是小编写的一个线程工厂，主要是在创建线程的时候 给当前线程分配名字和线程组方便控制。读到这里，有没有一点启发呢？ 四. 拒绝策略拒绝策略就是任务实在是已经执行不了，那么就需要你告诉程序，怎么样去拒绝在执行其他任务 ThreadPoolExecutor类里面是内置了4中拒绝策略，我们一个一个来分析 策略-1用于被拒绝任务的处理程序，它直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。如下： 策略-2 直接抛出异常 策略-3什么都不做直接丢弃 策略-4从任务队列中移除最早的一个，然后将拒绝的任务重新执行 到这里拒绝策略就说完了，应该都明白了吧，下面我们说下实际中会怎么用。 如果在任务不是特别多特别重要的情境下，可以在执行拒绝策略发送一个通知事件，通知相关的人查看。 比如以下这种 但是当任务特别重要的时候，比如说银行处理用户的转账信息更新事物的任务时候，那么这个任务就比较重要了，不可能用这种的，这种对数据要求高的我们都是用Elastic-Job，这种分布式任务处理框架，任务会首先落数据库，然后从数据库中批量读取任务执行。感兴趣的童鞋可以下去自行了解。 五. 任务队列扩展点知识，队列再次，小编不对队列进行讲解，只提到，感兴趣的童鞋下去在深入研究 Queue:分为阻塞队列和非阻塞队里 阻塞队列一共有四套方法分别用来进行insert、remove和examine，当每套方法对应的操作不能马上执行时会有不同的反应，下面这个表格就分类列出了这些方法： ThrowsException：如果操作不能马上进行，则抛出异常 SpecialValue：如果操作不能马上进行，将会返回一个特殊的值，一般是true或者false Blocks:如果操作不能马上进行，操作会被阻塞 TimesOut:如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是true或者false 需要注意的是，我们不能向BlockingQueue中插入null，否则会报NullPointerException。 LinkedBlockingQueue 无边界队里 PriorityBlockingQueue 排序队列，内部会排序但是要实现排序接口 SynchronousQueue 同步队列 ArrayBlockingQueue 阻塞队里，内不是数组，有边界 DelayQueue 延迟队里","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"Java开发者们for(;;)和while(true)的区别应该了解下","slug":"Java开发者们for-和while-true-的区别应该了解下","date":"2018-05-02T15:34:33.000Z","updated":"2018-05-02T15:38:09.823Z","comments":true,"path":"2018/05/02/Java开发者们for-和while-true-的区别应该了解下/","link":"","permalink":"https://blog.springlearn.cn/2018/05/02/Java开发者们for-和while-true-的区别应该了解下/","excerpt":"","text":"在我们阅读源码的时候经常会看到源码中会有下面这样的代码,当我看到这段代码自然而然就明白，这不就是一个无线循环吗？ 为什么不使用while呢？我们不禁疑问？那么带着这样的疑问，我们来探索一下吧 ! for(;;)和while(true)区别 从寓意上来看，两种写法都是无限循环 从效率上看，while(true)每次循环要判断循环条件,for(;;)循环没有判断，理论上节省机器指令。 下面我们就通过查看编译后的代码,来证明以下for(;;)和while(true)的区别 首先整理一个带编译的测试代码,如下 通过javac 将Test.java 编译成Test.class 字节码文件 在通过javap -c Test 查看下编译后的字节码文件，如下图 结论无论是for(;;)还是while(true),在Java中都是优化成goto没区别,结果来看,两种方法经过编译优化后,是一样的效果. 那么问题又来了，为什么有的人喜欢写成for(;;)的形式呢 这个问题，我也疑惑，最后通过谷歌得到一个结果: 对于早期的C语言，两种写法性能会不一样。for语句编译器会优化成一条汇编指令，而while判断则编译器会生成好几条汇编指令。小伙伴们,你们喜欢哪一种方式呢？请在文章下面留下你的看法吧!","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"做一个优秀的Coder,必须要知道的设计模式六大原则","slug":"做一个优秀的Coder-必须要知道的设计模式六大原则","date":"2018-05-02T15:31:40.000Z","updated":"2018-05-02T15:33:39.144Z","comments":true,"path":"2018/05/02/做一个优秀的Coder-必须要知道的设计模式六大原则/","link":"","permalink":"https://blog.springlearn.cn/2018/05/02/做一个优秀的Coder-必须要知道的设计模式六大原则/","excerpt":"","text":"如果说编码是筋骨皮，那么思想就是一口气，就是内功。内功深厚决定你功力的大小。刚刚读完了设计模式那本书。随着项目业务的复杂，越发的感觉到设计模式的重要性。在此参考CSDN、伯乐在线和开源中国社区，优秀的博文，以此总结。开始新的起点。写于2017/02/28 分析内容,属于当第二次看设计模式的感悟,写于2017/12/10 凌晨02:44 一、开闭原则定义一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 问题由来在软件的生命周期内，因为变化、升级和维护等原因需要对软件原有代码进行修改时，可能会给旧代码中引入错误，也可能会使我们不得不对整个功能进行重构，并且需要原有代码经过重新测试。 解决方案当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 表达用抽象构建框架，用实现扩展细节因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节，我们用从抽象派生的实现类来进行扩展，当软件需要发生变化时，我们只需要根据需求重新派生一个实现类来扩展就可以了。当然前提是我们的抽象要合理，要对需求的变更有前瞻性和预见性才行。 分析就是对扩展开放,对修改关闭, 里式替换原则理论支持了这个一说法,及子类要能替换父类,这样子类就可以在父类的基础上,扩展 二、单一职责原则定义不要存在多于一个导致类变更的原因通俗的说，即一个类只负责一项职责。 问题由来类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。 解决方案遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。 表达不要让责任扩散 分析一个类,指责要单一,避免如果有多种职责,修改一个职责的时候,误触到其他职责的问题 三、里氏替换原则定义所有引用基类的地方必须能透明地使用其子类的对象。 问题由来有一功能P由类A完成，现在要扩展P,其中P由类A的子类B完成，则子类在完成的同时，可能会导致原来功能故障 解决方案当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。 表达使用继承的时候，不要随便修改父类中已经实现的方法 分析子类要能替换父类 四、依赖倒置原则定义高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。 问题由来类A直接依赖类B，假如要将类A改为依赖类C，则必须通过修改类A的代码来达成。这种场景下，类A一般是高层模块，负责复杂的业务逻辑；类B和类C是低层模块，负责基本的原子操作；假如修改类A，会给程序带来不必要的风险。 解决方案将类A修改为依赖接口I，类B和类C各自实现接口I，类A通过接口I间接与类B或者类C发生联系，则会大大降低修改类A的几率。 表达如果A依赖B，现在要改为依赖C，如果直接修改A有风险，可以让A去依赖一个接口，BC都实现这个接口，也就是策略模式 分析白话就是说,要根据接口或者抽象去设计,不要依赖于细节,eg.项目中要换数据库,不用重新写底层的数据库代码. 就是使用了hibernate一样,替换方言就好了,因为hibernate是根据接口设计的,不同数据库有不同的实现,可以直接使用. eg2: 我生病了要去买药,如果A药铺,没有我就用B药铺买. 因为他们都是药铺,都有一样的功能,可以友好的替换 五、接口隔离原则定义客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。 问题由来类A通过接口I依赖类B，类C通过接口I依赖类D，如果接口I对于类A和类B来说不是最小接口，则类B和类D必须去实现他们不需要的方法。 解决方案将臃肿的接口I拆分为独立的几个接口，类A和类C分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则 表达防止去实现不需要的接口方法，可以按接口拆分，避免臃肿。 分析白话,接口要最小化,功能更细分. 目的是:不需要的功能,就不要去实现 比如有些接口可能里面什么方法都没有，其存在的意义，就是为了其实现类拥有特殊的功能.所以我们也要怕我们的接口里面没有方法，就怀疑了它存在的价值 当实现RandomAccess的类比如ArrayList就具有随机访问的能力，而没有实现该接口的，就只能去迭代访问 六、迪米特法则定义一个对象应该对其他对象保持最少的了解。 问题由来类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大。 解决方案尽量降低类与类之间的耦合。 表达尽量降低类与类之间的耦合。 分析降低类与类之间直接交互,能隐藏的属性就可以隐藏. eg. 修电脑,去IT部门,之前一直找小张,现在小张走了,还需要重新认识小李. 迪米特法则,就是直接找IT主管,让主管派人修.这里其实也抢到了接口的重要性","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"跟我动手搭框架三之Web容器实现","slug":"跟我动手搭框架三之Web容器实现","date":"2018-04-30T03:31:47.000Z","updated":"2018-04-30T03:32:22.201Z","comments":true,"path":"2018/04/30/跟我动手搭框架三之Web容器实现/","link":"","permalink":"https://blog.springlearn.cn/2018/04/30/跟我动手搭框架三之Web容器实现/","excerpt":"","text":"本篇主要对Web的实现做说明,在参考文章的同事,可以把code clone下来,看,代码中有很多需要优化的地址,我已经用TODO标记处理啊,小编会不断的进行优化和分析,演示SmileBootDemo也可以git clone,debug学习 Smile源码地址 SmileBootDemo 目录 核心描述类介绍 Smile启动核心实现 Http请求多线程异步实现 下一篇主要介绍内容 扩展 ​ 1. 核心描述类,主要保存处理方法及参数类型其实所有方法的执行,都离不开ioc的实现,IOC主要将组件(被@SmileComponent标记过的都为组件)保存为BeanDefinition的形式,而组件中的method,主要保存为WebDefinition的形式,而method的参数名称,参数类型,参数位置索引,主要保存在ParamterDefinition,对于请求的处理,就是根据url找到对应的method,然后根据ParamterDefinition将请求参数,转换成参数原本类型,然后处理 描述类 说明 存放位置 BeanDefinition 保存组件Class字节码及实例化对象 Map&lt;String(beanName), BeanDefinition&gt; registeredBeans WebDefinition 保存Url及对应的处理方法,及实例化对象,及参数类型 Map&lt;String(url), WebDefinition&gt; webHandlerMaps = new ConcurrentHashMap&lt;&gt;(); ParamterDefinition 保存参数位置索引及参数名称,参数类型,参数注解 WebDefinition.ParamterDefinition 2. Smile启动核心 2.1 SmileApplicationContext 扫描所有组件,并check 是否需要代理,最终生成IOC容器 IOC实现 Map&lt;String, BeanDefinition&gt; registeredBeans = new ConcurrentHashMap&lt;&gt;(); 2.2 SmileApplicationContext生成IOC容器之后,加载是否有实现ExtApplicationContext扩展类scanExtContext()方法 WebApplicationContext此时会执行,并扫描被@ResController注解修饰的路由类,然后 扫描其Methods,获取方法中有@GetMapping和@PostMapping 的方法生成WebDefinition和ParamterDefinition 123456789101112131415161718Consumer&lt;Map.Entry&lt;String, BeanDefinition&gt;&gt; entryConsumer = entry -&gt; &#123; BeanDefinition beanDefinition = entry.getValue(); Class&lt;?&gt; controllerClass = beanDefinition.getClazz(); RestController annotation = controllerClass.getAnnotation(RestController.class); String oneUrl = annotation.value(); Method[] methods = controllerClass.getMethods(); for (Method method : methods) &#123; boolean isGet = method.isAnnotationPresent(GetMapping.class); if (isGet) &#123; bindGetMethod(oneUrl, method, beanDefinition); &#125; boolean isPost = method.isAnnotationPresent(PostMapping.class); if (isPost) &#123; bindPostMethod(oneUrl, method, beanDefinition); &#125; &#125; &#125;; definitionMap.entrySet().forEach(entryConsumer); 123456789101112131415161718192021/** * 绑定get请求 * * @param oneUrl 一级url * @param method 方法 * @param beanDefinition bean描述 */ public void bindGetMethod(String oneUrl, Method method, BeanDefinition beanDefinition) &#123; Object controllerInstance = beanDefinition.getInstance(); Package aPackage = beanDefinition.getClazz().getPackage(); GetMapping getMapping = method.getAnnotation(GetMapping.class); String twoUrl = getMapping.value(); String[] parameterNames = WebTools.getParameterNames(method); if (StringTools.isEmpty(twoUrl)) &#123; throw new BindUrlHanderException(\"[ \" + aPackage.getName() + \" ]:绑定url异常,请检查,请填写需要绑定的url地址\"); &#125; String realUrl = WebTools.checkUrl(oneUrl, twoUrl); String methodPath = method.toGenericString(); logger.info(\"Mapped url:[&#123;&#125;],produces:[&#123;&#125;],consumes:[&#123;&#125;],paramter:&#123;&#125;,onto:&#123;&#125;\", realUrl, getMapping.produces(), getMapping.consumes(), parameterNames, methodPath); webHandlerMaps.put(realUrl, new WebDefinition(realUrl, RequestMethod.GET, getMapping.consumes(), getMapping.produces(), controllerInstance, method, parameterNames)); &#125; ​ 3. HTTP处理实现核心 3.1将每个请求生成一个MessageRequest及MessageResponse,作为一个任务交给线程池去异步执行 1234MessageRequest messageRequest = new MessageRequest(randomUUID, requestMethod, requestParams, webDefinition, headerMaps);MessageResponse messageResponse = new MessageResponse();SmileTaskChoice smileTaskChoice = new DefaultTaskProcessChoice(messageRequest, messageResponse, false);SmileMessageExecutor.submit(smileTaskChoice.choice(), ctx, req, messageRequest, messageResponse); 3.2 SmileTaskChoice 是执行策略,当为ture时候,为rpc默认,可以定义自己的rpc远程调用的方式实现结果返回 12345678910111213141516171819202122232425262728public class DefaultTaskProcessChoice implements SmileTaskChoice &#123; private boolean isRpc = false; private MessageRequest messageRequest; private MessageResponse messageResponse; /** * * @param request * @param response * @param isRpc 本地方法:false rpc调用:true */ public DefaultTaskProcessChoice(final MessageRequest request, final MessageResponse response, boolean isRpc) &#123; this.messageRequest = request; this.messageResponse = response; this.isRpc = isRpc; &#125; @Override public Callable choice() &#123; Callable callTask =null; if (!isRpc) &#123; callTask = new LocalMessageTask(messageRequest, messageResponse); &#125;else &#123; callTask=new RpcProcessTask(messageRequest,messageResponse); &#125; return callTask; &#125;&#125; ​ 3.3 SmileTask中 主要利用反射，将请求 URL 获取到 WebDefinition ,拿到执行方法,将请求参数,绑定到方法,作为实参,传递 Object invokeResult = method.invoke(controller, args); 并通过Netty 连接通道Channel把处理结果返回给客户端 3.4 SmileMessageExecutor.submit 方法中监听任务是否成功处理,成功并通过Netty 连接通道Channel把处理结果返回给客户端 1234567891011121314151617181920212223242526272829303132333435public static void submit(Callable&lt;Boolean&gt; task, final ChannelHandlerContext ctx, HttpRequest metaRequest, final MessageRequest request, final MessageResponse response) &#123; /** * SmileThreadFactory 目的构建自己的线程名,并通过线程组进行统一管理 * SmileThreadPoolExecutor 构建自己的线程池,对任务进行,细微管理 */ if (threadPoolExecutor == null) &#123; SmileThreadPoolExecutor smileThreadPoolExecutor = new SmileThreadPoolExecutor(new SmileThreadFactory(\"Smile\")); ThreadPoolExecutor executorService = (ThreadPoolExecutor) smileThreadPoolExecutor.getExecutory(); threadPoolExecutor = MoreExecutors.listeningDecorator(executorService); &#125; /** * 处理完成任务如果任务完成就,渲染出去 */ ListenableFuture&lt;Boolean&gt; listenableFuture = threadPoolExecutor.submit(task); Futures.addCallback(listenableFuture, new FutureCallback&lt;Boolean&gt;() &#123; @Override public void onSuccess(Boolean result) &#123; if (result)&#123; NettyResponse.writeResponseAndListener(ctx.channel(), request, response, new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture channelFuture) throws Exception &#123; channelFuture.channel().close(); logger.info(\"Smile Server Send message-id:&#123;&#125;\" , request.getMessageId()); &#125; &#125;); &#125; &#125; @Override public void onFailure(Throwable t) &#123; t.printStackTrace(); &#125; &#125;, threadPoolExecutor); &#125; ​ 4. 下一篇主要介绍内容框架的实现方案属于传统的MVC机构,只不过吧视图层V取消掉了,这也是趋势,前后分离,后端只做关心数据处理, 而传统的MVC架构,核心为Servlet,SpringMVC核心为DispatchServlet,是对原始Java Servlet的一个封装,关于这点可以看小编的另一篇文章手写一个轻量级的网关API,当然使用Netty也是如此,我们的入口就是HttpDispatchServerHandler 核心方法就是messageReceivedDispatch 而只知道,这些是远远不够的,Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具,我会新开二篇,专门介绍IO模型重点介绍IO multiplexing(IO多路复用)和Netty如何工作 ! 包括如何实现,心跳检测 主要会介绍下面写模块 Bootstrap or ServerBootstrap EventLoop EventLoopGroup ChannelPipeline Future or ChannelFuture ChannelInitializer ChannelHandler ByteToMessageDecoder MessageToByteEncoder 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public void messageReceivedDispatch(ChannelHandlerContext ctx, HttpObject msg) throws Exception &#123; String dispatchUrl = \"\"; Map&lt;String, Object&gt; headerMaps = new ConcurrentHashMap&lt;&gt;(); if (msg instanceof HttpRequest) &#123; HttpRequest req = this.request = (HttpRequest) msg; HttpHeaders headers = req.headers(); headers.entries().stream().forEach(x -&gt; &#123; headerMaps.put(x.getKey(), x.getValue()); &#125;); String contentType = request.headers().get(\"Content-Type\"); String methodName = request.getMethod().name(); dispatchUrl = req.getUri(); String randomUUID = UUID.randomUUID().toString().replaceAll(\"-\", \"\"); Map&lt;String, Object&gt; requestParams = new ConcurrentHashMap&lt;&gt;(); // 处理get请求 if (methodName.equalsIgnoreCase(\"GET\")) &#123; boolean contains = dispatchUrl.contains(\"?\"); if (contains)&#123; String queryContent = dispatchUrl.substring(dispatchUrl.indexOf(\"?\") + 1); Map&lt;String, Object&gt; queryParameterFromContent = URLTools.getQueryParameterFromContent(queryContent); queryParameterFromContent.entrySet().forEach(entry -&gt; &#123; requestParams.put(entry.getKey(), entry.getValue()); &#125;); &#125; &#125; // 处理POST请求 if (methodName.equalsIgnoreCase(\"POST\")) &#123; if (StringTools.endsWithIgnoreCase(contentType, \"application/json\")) &#123; FullHttpRequest request1 = (FullHttpRequest) msg; ByteBuf jsonBuf = request1.content(); String jsonStr = jsonBuf.toString(CharsetUtil.UTF_8).replaceAll(\"\\\\\\\\s*|\\\\t|\\\\r|\\\\n\", \"\"); if (!StringTools.isEmpty(jsonStr)) &#123; requestParams.put(\"BODY\", jsonStr); &#125; &#125; else &#123; HttpPostRequestDecoder decoder = new HttpPostRequestDecoder( new DefaultHttpDataFactory(false), req); List&lt;InterfaceHttpData&gt; postData = decoder.getBodyHttpDatas(); // for (InterfaceHttpData data : postData) &#123; if (data.getHttpDataType() == InterfaceHttpData.HttpDataType.Attribute) &#123; MemoryAttribute attribute = (MemoryAttribute) data; requestParams.put(attribute.getName(), attribute.getValue()); &#125; &#125; &#125; &#125; if (StringTools.contains(dispatchUrl,\"?\"))&#123; dispatchUrl = dispatchUrl.substring(0, dispatchUrl.indexOf(\"?\")); &#125; RequestMethod requestMethod = WebTools.getRequestMethod(methodName); WebDefinition webDefinition = WebContextTools.getWebDefinitionByUrl(dispatchUrl, requestMethod); if (webDefinition instanceof Web404Definition) &#123; NettyResponse.writeResponse(ctx.channel(), \"Not Found\", HttpResponseStatus.NOT_FOUND); return; &#125; if (webDefinition instanceof Web405Definition) &#123; NettyResponse.writeResponse(ctx.channel(), \"Method Not Allowed\", HttpResponseStatus.METHOD_NOT_ALLOWED); return; &#125; String consumes = webDefinition.getConsumes(); if (StringTools.isNotEmpty(contentType))&#123; if (StringTools.isNotEmpty(consumes)&amp;(!contentType.equalsIgnoreCase(consumes)))&#123; NettyResponse.writeResponse(ctx.channel(), \"Bad Request (The content-type don't match)\", HttpResponseStatus.BAD_REQUEST); return; &#125; &#125; /** * //TODO 异步处理url获取处理的 bean */ MessageRequest messageRequest = new MessageRequest(randomUUID, requestMethod, requestParams, webDefinition, headerMaps); MessageResponse messageResponse = new MessageResponse(); /** * //TODO 根据启动配置,当如果是rpc服务就要使用MessageProcessTask * 如果是本地服务使用LocalMessageTask * * 此时MessageRequest和MessageResponse都是final 修饰,目的是保证始终是对当前的MessageResponse */ SmileTaskChoice smileTaskChoice = new DefaultTaskProcessChoice(messageRequest, messageResponse, false); /** * //TODO 交给线程处理异步处理响应 */ SmileMessageExecutor.submit(smileTaskChoice.choice(), ctx, req, messageRequest, messageResponse); &#125; &#125; 扩展再次声明小编也是一个菜鸟,是一只具有学习精神,并热爱编程的菜鸟, 所有的文章都是经过参考很多优秀博文,给我带来的进步,小编,希望将学习到的所有知识点,也分享给大家 ! 小编会在这里列出,参考到的优秀博文,尊重每位知识传播者的劳动果实. 如果您发现小编文章中,有错误,请及时指出,并通知小编改正,小编在此谢过. 欢迎继续关注小编~ 小编努力coding… 参考 Smart Framework 设计动力来源 segmentfault-Netty 源码分析 Netty强化学习 SpringIOC源码分析 描述类灵感来源 基于Netty打造RPC服务器设计经验谈","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"跟我动手搭框架二之AOP实现","slug":"跟我动手搭框架二之AOP实现","date":"2018-04-30T03:30:34.000Z","updated":"2018-04-30T03:31:27.014Z","comments":true,"path":"2018/04/30/跟我动手搭框架二之AOP实现/","link":"","permalink":"https://blog.springlearn.cn/2018/04/30/跟我动手搭框架二之AOP实现/","excerpt":"","text":"代理这里主要用CGLIB代理,主要为实现前置通知,后置通知,环绕通知和异常通知 本篇主要承上启下,承上根据IOC容易实现简单AOP代理, 启下,对将要实现的WEB模块做一个规划 文章中多有代码,会在第三部分WEB容器实现,列出参考文档及GITHUB源码地址 目录 1.编写工具类 2.实现AOP 3.web实现规划 定义接口类并提供抽象空实现抽象目的: 实现类只需要继承要,实现的方法,即可 12345678910111213141516171819202122232425262728293031323334353637383940/** * @Package: smile.proxy * @Description: 代理通知 * @author: liuxin * @date: 2017/10/18 上午10:18 */public interface ProxyAspect &#123; /** * 前置通知 */ void before(); /** * 后置通知 */ void after(); /** * 异常通知 */ void throwed(); /** * 环绕通知 */ void around();&#125;/** * @Package: smile.proxy * @Description: * @author: liuxin * @date: 2017/10/18 上午10:22 */public abstract class DefaultProxyAspect implements ProxyAspect &#123; @Override public void before() &#123;&#125; @Override public void after() &#123;&#125; @Override public void throwed() &#123;&#125; @Override public void around() &#123;&#125;&#125; 定义CGLIBProxy工具主要逻辑 实现提供方法级代理,也就是对象不用实例化 对实例进行代理 代码更有说服力,直接看注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * @Package: com.example.proxy * @Description: JDK自带动态代理，只能代理，拥有接口的，而Cglib代理，是运行在动态生成字节码的工具中 * 根据注解实现 * @author: liuxin * @date: 17/3/31 上午10:24 */public class CGLibProxy implements MethodInterceptor &#123; private ProxyAspect proxyAspect; private Class cls; private Object object; /** * 预处理 * 当代理逻辑中依赖其他类,需要提前注入时候,仅扩展此类 * * 扩展逻辑类 proxyAspect 从ioc容器中获取实例 * * @return */ public List&lt;String&gt; preProcessing() &#123; SmileProxyAspect smileProxyAspect = (SmileProxyAspect) cls.getAnnotation(SmileProxyAspect.class); try &#123; proxyAspect = smileProxyAspect.proxyAspect().newInstance(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; return Arrays.asList(smileProxyAspect.methods()); &#125; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object result = null; //判断方法是否使用代理 boolean contains = preProcessing().contains(method.getName()); if (contains) &#123; proxyAspect.around(); proxyAspect.before(); try &#123; if (object == null) &#123; result = methodProxy.invokeSuper(obj, args); &#125; else &#123; result = methodProxy.invoke(object, args); &#125; &#125; catch (Throwable throwable) &#123; proxyAspect.throwed(); &#125; proxyAspect.after(); proxyAspect.around(); &#125; else &#123; result = methodProxy.invokeSuper(obj, args); &#125; return result; &#125; public static CGLibProxy instance() &#123; return new CGLibProxy(); &#125; /** * 利用泛型 * 获取代理类型 * * @param cls * @param &lt;T&gt; * @return */ public &lt;T&gt; T getProxy(Class&lt;T&gt; cls) &#123; this.cls = cls; return (T) Enhancer.create(cls, this); &#125; /** * 获取代理类 * @param cls * @return */ public Object toProxyObject(Class cls) &#123; this.cls = cls; return Enhancer.create(cls, this); &#125; /** * 注入代理对象实例 * * @param obj * @return */ public CGLibProxy setProxyObject(Object obj) &#123; this.object = obj; return this; &#125; /** * 演示代码中,均使用@SmileProxyAspect注解实现 * 注解中 * proxyAspect 代理切面类,需要包括处理逻辑 要实现DefaultProxyAspect 需要实现的抽象方法 * methods 需要代理的方法名称 * * @param args */ public static void main(String[] args) &#123; /****************************************** * 方法级代理 */ /** * 实现前置通知和后置通知 */ Jay2 proxy1 = CGLibProxy.instance().getProxy(Jay2.class); proxy1.dance(\"芭蕾舞\"); System.out.println(proxy1); /** * 使用默认通知,只打印日志 */ Jay2 proxy = CGLibProxy.instance().getProxy(Jay2.class); System.out.println(proxy); proxy.dance(\"芭蕾舞\"); /****************************************** * 实例代理 */ /** * 拦截对象 */ Jay2 jay2 = CGLibProxy.instance().setProxyObject(new Jay2(\"周杰伦\")).getProxy(Jay2.class); jay2.say(); Jay2 jay3 = CGLibProxy.instance().setProxyObject(new Jay2(\"周杰伦\")).getProxy(Jay2.class); jay3.say(); System.out.println(Jay2.class.isAssignableFrom(jay3.getClass())); System.out.println(jay3); Object jay4= CGLibProxy.instance().setProxyObject(new Jay2(\"周杰伦\")).toProxyObject(Jay2.class); &#125;&#125; AOP实现 实现方案 当IOC容器扫描所有被@SmileComonpent标记的组件时候,会判断是否被@SmileProxyAspect 注解修饰, 如果有@SmileProxyAspect,则对实例化对象生成代理,注入 123456789101112131415/** * 扫描所有被标记的组件 */ public void scanComponent(Class&lt;?&gt; nextCls) &#123; SmileComponent declaredAnnotation = nextCls.getDeclaredAnnotation(SmileComponent.class); Object beanInstance = null; beanInstance = nextCls.newInstance(); //判断是否包括代理注解,如过包括就生成代理对象 SmileProxyAspect smileProxyAspect = (SmileProxyAspect) nextCls.getAnnotation(SmileProxyAspect.class); if (smileProxyAspect != null) &#123; beanInstance=CGLibProxy.instance().setProxyObject(beanInstance).toProxyObject(nextCls); .... .... registeredBeans.put(beanName, new BeanDefinition(nextCls, beanInstance)); &#125; 3. web规划在对ioc容器及代理编写完成后,就到重点我们要实现,对HTTP请求的解析和处理. 在此实现,要对项目做一个规划,打一个草稿 项目基于Maven多模块实现 3.1 包名groupId: org.smileframework.boot artifactId: org.smileframework.web org.smileframework.tool org.smileframework.data org.smileframework.ioc ３.２TOOLS部分工欲善其事必先利其器,所以先写我们将会遇到的工具类 生成代理部分 CGLIB代理 org.smileframework.tool.proxy 线程工厂及拒绝策略 org.smileframework.tool.threadpool json及xml转换 org.smileframework.tool.json | .xml 数据流工具类 org.smileframework.tool.io 类加载器器 org.smileframework.tool.clazz 文件读取工具 org.smileframework.tool.io.SmileClassPathResource 3.3 IOC部分 123在处理器中扫描注解可以知道项目具有哪些功能@SmileBootApplication 如果有改扫描器,就到子目录中的使用@SmileComponent注解的都加入到默认的beans容器中然后开始实例化,如果发现Class中包括@InsertBean()将从bean容器中的对象,反射进去生成对象.发现方法中用@SmileBean修饰的同样从ioc容器中获取实例,并注入到该对象中,最终保存到IOC容器 3.4 合并WEB上下文从bean容器中获取到ExtApplicationContext 3.5 绑定Url和处理类1234567891011121314151617181920@GetMapping 标记get请求方法@PostMapping 标记post请求方法@RequestBody 将请求体绑定到方法指定类型@RequestHander 绑定请求头到被就是的map类型@RequestParam 指定方法请求参数名WebDefinition webDefinition = WebContextTools.getWebDefinitionByUrl(dispatchUrl, requestMethod);校验使用反射,将该方法的参数名称和请求到的参数做一个简单校验//测试将POST请求体中数据,反序列化为User@PostMapping(value = \"/smile/test/requestBody\", consumes.., produces..)public String testRequestBody(@RequestBoby UserDto user) &#123; return user.getName() + \"--\" + user.getAge();&#125;//Method: 获取到的执行方法 parameters:请求参数 headers:请求头//将以上信息根据consumes定义的解析方法,转换成方法指定类型Object[] args = ControllerUtils.getArgs(method, parameters,headers);Object invokeResult = method.invoke(controller, args);//根据produces定义的返回值类型,通过Netty channle返回给客户端 3.6 AOP 拦截在扫描时候找到切面类,读取里面的class类型 123proxyAspect: 代理逻辑,实现 1.前置 2. 后置 3.环绕 4.异常通知@SmileProxyAspect(proxyAspect = ControllerProxyAspectDemo.class, methods = &#123;\"testRequestBody\", \"testRequestParam\"&#125;) 获取到这个注解,并获取class类型,从bean容器中,获取这个对象(A),根据Smile的方法把这个A对象,进行代理. 3.7 web容器使用Netty(请看下一节) 定义WebApplicationContext 类实现ExtApplicationContext上下文信息获取IOC容器,并扫描ioc获取url绑定handler绑定的信息 创建netty server端","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"跟我动手搭框架一之IOC容器实现","slug":"跟我动手搭框架一之IOC容器实现","date":"2018-04-30T03:29:08.000Z","updated":"2018-04-30T03:30:10.919Z","comments":true,"path":"2018/04/30/跟我动手搭框架一之IOC容器实现/","link":"","permalink":"https://blog.springlearn.cn/2018/04/30/跟我动手搭框架一之IOC容器实现/","excerpt":"","text":"本篇文章面对的是有开发经验的Java developer 因为我们将要实现的Spring的IOC容器, 前些天由于工作中要开发公司的Callback系统,一直在研究Netty及IO模型,对于Netty这种非阻塞异步框架,非常崇拜,于是萌发一个想法,用Netty作为web容器,替换Tomcat研究性能.出于这种初衷,就开始为SmileBoot项目开始慢慢积累开发知识.本篇属于小编SmileBoot中的一个模块,为什么要起名Smile呢?因为小编始终认为,我们要带着好的心态,才能学更多的东西,其实小编也是一个菜鸟,之所以要写下来,就是为了记忆和理解更深.因为如果把自己理解的东西,能清楚的讲给其他人,那么才算是真正的理解. 目录 1.原理分析及设计 2.实现方案 2.1 拿到扫描范围 2.2 更具扫描范围加载范围内所有字节码文件 2.3 定义自己的上下文对象接口及实现类 3.测试可用性 4.扩展性 5.下篇预告 1.原理分析及设计Spring的源码,这里不跟着阅读,直接去实现,然后刚兴趣的童鞋,可以自己在看看,原理是一样的. 1.加载项目中所有的Class文件到Set集合 2.遍历Set将标记有IOC的组件的Class,获取到,注册到IOC容器,这个里面的重点是如何将Class里面的组件,注入进来. @SmileComponent在这里@SmileComponent注解是用来标记,需要加入到IOC容器的类 @SmileBean@SmileBean是用来标记方法中返回值作为Bean,是将要被注册到IOC容器的对象 ＠InsertBean@InserBean是标记,该字段是一个Bean,需要从IOC容器中获取,然后注入到该对象中 2.实现方案1.获取所有的Class字节码,在这中间我们有一个困难那就是如果知道,开发者的所有字节码呢?这个时候我们就可以用注解的形式,在启动类上做一个标记,那么我们就能获取到启动类的字节码,从而获取到将要扫描的跟目录. 我们看下Spring是如何实现的吧 123456@SpringBootApplicationpublic class OtoSaasApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OtoSaasApplication.class, args); &#125;&#125; 在这段代码中,有一个注解@SpringBootApplication ,了解Spring的开发同事,都是知道这个注解其实包括了多个注解的,其中一个就是@ComponentScan 12345678@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan &#123; @AliasFor(\"basePackages\") String[] value() default &#123;&#125;&#125; 那么我们就可以知道,其实也main方法所包含的注解,拿到根目录的.这个有一个Spring的特性,那就是如果启动类在最外层的,那么默认就是扫描,其子目录中的Class,如果不是在根目录,那么要指定扫描的范围. 2.1拿到扫描范围那么我们想,如果用户不指定,我们怎么拿到根目录呢? 好,如果有疑惑的话,那么久带着疑惑,看下面这段代码吧! 我们定一个注解@SmileBootApplication 目录就是获取到用户的根目录,这里关于注解不在解释,如果有不了解实现注解的可以看小编SpringBoot实践中的自定义注解 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface SmileBootApplication &#123; String[] basePackages() default &#123;&#125;;&#125; 123456@SmileBootApplicationpublic class SmileApplication &#123; public static void main(String[] args) &#123; SmileApplication.run(SmileApplication.class, args); &#125;&#125; 我们定义一个方法也就是在run方法中,根据class,文件,获取到注解的根目录 123456789101112131415161718public static String getBaseRootPackage(Class&lt;?&gt; cls) &#123; SmileBootApplication declaredAnnotation = null; try &#123; declaredAnnotation = cls.getDeclaredAnnotation(SmileBootApplication.class); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"请添加@SmileBootApplication\"); &#125; /** * 获取注解上的扫描目录 * 如果没有指定,就从当前目录获取 */ String[] strings = declaredAnnotation.basePackages(); String baseRootPackage = \"\"; if (strings.length == 0) &#123; baseRootPackage = cls.getPackage().getName(); &#125; return baseRootPackage; &#125; 看到这里,我们已经拿到了项目的根目录,或者说是将要扫描的范围了 2.2 获取指定目录下的所有字节码文件这个时候我们要知道一个基础的方法,那就是 1234567/** * @param className 完整类路径 * @param isInitialized 是否初始化 第2个boolean参数表示类是否需要初始化Class.forName(className)默认是需要初始化。一旦初始化，就会触发目标对象的 static块代码执行，static参数也也会被再次初始化 * @param classLoader 类加载器 * @return */Class.forName(className, isInitialized, classLoader); 我们要用到一个工具类ClassUtils,该类中可以将根目录中所有字节码(.java,.jar文件)加载到Set&lt;Class&lt;?&gt;&gt;set中 这个工具也不是小编写的,是参考了很多博客大拿,发现都有用到,但是具体出自哪位,就不晓得了,那么也分享给大家 可以参考 GITHUB 2.3 定义自己的上下文对象接口及实现类12345678910111213/** * @Package: pig.boot.ioc.context * @Description: 上下文 * @author: liuxin * @date: 2017/11/17 下午11:52 */public interface ApplicationContext &#123; Object getBean(String var1); &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType); &lt;T&gt; T getBean(Class&lt;T&gt; name); boolean containsBean(String var1); void scan(String basePackRoot);&#125; 1234567891011121314151617181920212223242526272829303132public class SmileApplicationContext implements ApplicationContext &#123; /** * 扫描所有的类,并装载 * * @param basePackRoot */ @Override public void scan(String basePackRoot) &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); Set&lt;Class&lt;?&gt;&gt; classesByPackage = null; try &#123; /** * recursively 是否从根目录,向下查找 */ classesByPackage = ClassUtils.getClassesByPackageName(classLoader, basePackRoot, true); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; /** * 加载到所有的bean */ allBeans.addAll(classesByPackage); /** *扫描所有的标记,加入到容器 */ classesByPackage.forEach(this::scanComponent); /** * 将没有注册的bean检查,然后注入 */ processEarlyBeans(); &#125;&#125; 这个类的重点方法就是scan扫描所有的标记,并从set中拿到每个字节码,传给scanComponent 方法去解析注册 这个时候我们可能遇到一种情况,就是BeanA中需要注册BeanB但是可能BeanB此时并没有解析到,那么这个时候,就要考虑,把暂时实例化不了的,放入到delayBeans,等所有能解析的解析之后,在回过头加载,我们来看这个方法,在看之前我们定义这样一个类 BeanDefinition 用处就是讲Bean的class和实例化对象都保存起来 1234567891011121314/** * @Package: pig.boot.ioc.context * @Description: bean描述 * @author: liuxin * @date: 2017/11/17 下午11:53 */public class BeanDefinition &#123; Class&lt;?&gt; clazz; Object instance; public BeanDefinition(Class&lt;?&gt; clazz, Object instance) &#123; this.clazz = clazz; this.instance = instance; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 扫描所有被标记的组件 */ public void scanComponent(Class&lt;?&gt; nextCls) &#123; SmileComponent declaredAnnotation = nextCls.getDeclaredAnnotation(SmileComponent.class); Object beanInstance = null; if (declaredAnnotation != null) &#123; try &#123; beanInstance = nextCls.newInstance(); String beanName = declaredAnnotation.vlaue(); if (beanName.isEmpty()) &#123; beanName = nextCls.getSimpleName(); &#125; /** * 保证bean名称的唯一性 */ Long beanId = beanIds.get(); //将类名,首字母小写,并检查是否存在,如果存在就后面添加id,这个id是原子操作,保证唯一. beanName= getUniqueBeanNameByClassAndBeanId(nextCls,beanId); /** * 实例化里面的需要注入的字段都获取到 * 如果返回true就可以直接添加到IOC容器 * lastChance=true 如果注入失败就报错,false不报错,因为第一次,可能所有类没有初始化,所以等待延迟加载方法去,加载 */ if (autowireFields(beanInstance, nextCls, false)) &#123; registeredBeans.put(beanName, new BeanDefinition(nextCls, beanInstance)); &#125; else &#123; /** * 上面那种情况,可能会出现,当要注入,但是被注入的未加载到IOC容器中的情况,所以对于这种,就添加到earlyBeans中,后期注入 */ delayBeans.put(beanName, new BeanDefinition(nextCls, beanInstance)); &#125; /** * 获取方法上的bean * 因为方法肯定是有返回值,的返回值就是实例化对象,所以可以直接,加入到IOC容器 */ createBeansByMethodsOfClass(beanInstance, nextCls); &#125; catch (Exception e) &#123; &#125; &#125; &#125; 3.测试可用性1234567891011@SmileBootApplicationpublic class SmileApplication &#123; public static void main(String[] args) &#123; SmileApplicationContext run = SmileApplication.run(SmileApplication.class, args); System.out.println(run.getBean(BeanB.class).toString()); System.out.println(run.getBean(BeanA.class).beanB().toString()); //BeanB&#123;content='hi. iam is beanB'&#125; //BeanB&#123;content='hi. iam is beanB'&#125; &#125;&#125; 12345678910111213141516171819202122/** * @Package: pig.boot.ioc.context * @Description: 获取参数 * @author: liuxin * @date: 2017/11/17 下午11:55 */@SmileComponentpublic class BeanA &#123; private String content; @InsertBean private BeanB beanb; public BeanA() &#123; &#125; public BeanA(String content) &#123; this.content = content; &#125; @SmileBean public BeanB beanB() &#123; return new BeanB(\"hi. iam is beanB\"); &#125;&#125; 4.可扩展性 定义上下文对象接口类,developer,可以定义自己的上下文类 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭 ApplicationContextInitialezer 初始化类执行,获取初始化条件和初始化方法,指定合适的上下文实现类 ​ 不要存在多于一个导致类变更的原因,通俗的说，即一个类只负责一项职责。 小编最喜欢的方法是抽象,即具有共同特征的方法,用抽象类去实现,具体的方法有继承类去实现 接口隔离,即依赖最小的接口,eg.A接口有五个方法 B此时要用3个,C要用2个,但是他们不得不全部实现.此时我们可以把A接口拆分为2个. 当D5个方法的时候,就继承2个接口,就可以 5.下篇预告定义@GetMapping,@PostMapping,注解,绑定处理逻辑handler. 放入SmileNettyTaskHandler中,交给Netty处理异步处理 附录好的代码就想一本书,读的书越多,思路就越广,想法就越多 每个开发人员要把自己当做一个工程师,而不是一个coding 的码农,工程师考虑问题要从顶层设计考虑,而不是为了单纯解决一个问题而code.","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"一致性hash","slug":"一致性hash","date":"2018-04-23T07:05:38.000Z","updated":"2018-04-23T07:17:48.330Z","comments":true,"path":"2018/04/23/一致性hash/","link":"","permalink":"https://blog.springlearn.cn/2018/04/23/一致性hash/","excerpt":"","text":"一致性hash问题在提出这个问题的时候,我们先解释下这题目,能解决的问题是什么？对此有一个了解 举一个简单的例子 如何维护一致性呢? 为什么要维护一致性呢? 目的,最大程度的减少数据的损失 我们的实现逻辑是: 对数据和数据保存的节点分别做hash映射,让数据找小于或者等于自己最近的数据保存节点 对 a b c 分别做哈希映射 当大于228都存203节点,于是就维护了一个圆形,即所有数据都能找到其节点了 当新加入节点d,可以算出d的hashnode d: 216 对数据进行迁移(其实只影响209~216之间的数,即达到了我们的目的) 但是这样就是最好的吗? 当然不是,可能会出现数据不平衡的情况,比如,ABC没有数据,但是D数据饱满的请情况.","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"HashMap底层原理","slug":"HashMap底层原理","date":"2018-04-23T07:04:54.000Z","updated":"2018-04-23T07:05:25.553Z","comments":true,"path":"2018/04/23/HashMap底层原理/","link":"","permalink":"https://blog.springlearn.cn/2018/04/23/HashMap底层原理/","excerpt":"","text":"HashMap底层原理HashMap数组每一个元素的初始值都是Null。 对于HashMap，我们最常使用的是两个方法：Get 和 Put。 1.Put方法的原理调用Put方法的时候发生了什么呢？ 比如调用 hashMap.put(“apple”, 0) ，插入一个Key为“apple”的元素。这时候我们需要利用一个哈希函数来确定Entry的插入位置（index）： 1index = Hash（“apple”） 假定最后计算出的index是2，那么结果如下： 但是，因为HashMap的长度是有限的，当插入的Entry越来越多时，再完美的Hash函数也难免会出现index冲突的情况。比如下面这样： 这时候该怎么办呢？我们可以利用链表来解决。 HashMap数组的每一个元素不止是一个Entry对象，也是一个链表的头节点。每一个Entry对象通过Next指针指向它的下一个Entry节点。当新来的Entry映射到冲突的数组位置时，只需要插入到对应的链表即可： 需要注意的是，新来的Entry节点插入链表时，使用的是“头插法”。至于为什么不插入链表尾部，后面会有解释。 2.Get方法的原理使用Get方法根据Key来查找Value的时候，发生了什么呢？ 首先会把输入的Key做一次Hash映射，得到对应的index：1index = Hash（“apple”） 由于刚才所说的Hash冲突，同一个位置有可能匹配到多个Entry，这时候就需要顺着对应链表的头节点，一个一个向下来查找。假设我们要查找的Key是“apple”： 第一步，我们查看的是头节点Entry6，Entry6的Key是banana，显然不是我们要找的结果。 第二步，我们查看的是Next节点Entry1，Entry1的Key是apple，正是我们要找的结果。 之所以把Entry6放在头节点，是因为HashMap的发明者认为，后插入的Entry被查找的可能性更大。这就是HashMap的底层原理。 HashMap线程不安全就是因为hashmap底层是个数组，数组中又存在链表，当多线程时，对数组操作所以是不安全的。","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://blog.springlearn.cn/tags/HashMap/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"SpringCloud集群负载均衡及全链路监控","slug":"SpringCloud集群负载均衡及全链路监控","date":"2018-04-22T09:35:02.000Z","updated":"2018-04-23T06:32:22.914Z","comments":true,"path":"2018/04/22/SpringCloud集群负载均衡及全链路监控/","link":"","permalink":"https://blog.springlearn.cn/2018/04/22/SpringCloud集群负载均衡及全链路监控/","excerpt":"","text":"SpringCloud集群负载均衡及全链路监控 东方既白是小编我的头条号，想获取到源码地主的童鞋，可以关注小编，私信发送，[SpringCloud架构]即可获取到GITHUB源码地址，最后谢谢您的阅读，小编会每天为你分享一点小知识，谢谢您的关注。 前言我们要从那些解读去考虑技术选型? 服务器(云服务提供商是否稳定) 代码层面(技术选型+代码质检Sonarqube) https://www.toutiao.com/i6501805549015794189/ 数据库(是否面临高并发或大数据问题) 解决的问题是什么?微服务错误及耗时定位分析困难 具体解决方案: 引入ZipKin进行抽样监控 微服务错误引发雪崩现象 具体解决方案: hystrix及时熔断 具体解决方案 : hystrix流量洪峰监控 微服务日志拆分导致查看异常困难 具体解决方案: ELK日志分析 具体解决方案: Sentry 日志异常通知 微服务配置变更 具体解决方案: eureka注册中心/ consul 紧急备用方案 快速部署 docker技术 目录 以集群的方式启动Eureka 注册服务 Ribbon目录做负载均衡,及熔断错误 提供测试DTO Hystrix演示 5.1 熔断聚合及监控 全链路追踪 6.1 如何在保证链路监控有效的情况下,对其进行监控! 注册中心比较及Consul使用 7.1 mac安装Consul 消息总线 Spring Cloud Bus 高可用分布式配置中心Spring Cloud Config 负载均衡策略 10.1 阿里云基础架构 框架目录 1.以集群的方式启动Eureka登录账号: blm 密码: blm123 Spring-learning-eureka-01 端口: 10001 注册实例名: eureka-service-01 应用名:eureka-service Spring-learning-eureka-01 端口: 10002 注册实例名: eureka-service-02 应用名:eureka-service 2.注册服务Spring-learning-service-01 端口: 20001 注册实例名: eureka-provider-service-01 应用名:eureka-provider-service Spring-learning-service-02 端口: 20002 注册实例名: eureka-provider-service-02 应用名:eureka-provider-service 注意: 当注册实例名都为eureka-provider-service时候就启动了负载均衡,从注册中查询服务 3.Ribbon目录做负载均衡,及熔断错误Spring-learning-ribbon-consume 端口: 30000 注册实例: eureka-ribbon 应用名: eureka-ribbon 建议注册名和应用名统一命名,ribbon会根据spring.application.name知道服务地址,也就是应用名 提供测试DTOSpring-learning-model 如果用idea导入,service-01和02依赖改模块,需要添加该模块 5.Hystrix演示 负载均衡操作均匀分散在 eureka-provider-service 暴路的地址 5.1 熔断聚合及监控Spring-learning-ribbon-consume加入熔断依赖, 启动类添加@EnableCircuitBreaker就可访问 如果要访问页面,要新添加依赖,并在启动类,添加@EnableHystrixDashboard 即可访问 关闭Spring-learning-service-01和-02然后调动https://blm:blm123@lxchinesszz:30000/ribbon/user,进行熔断 6. 全链路追踪Zipkin为分布式链路调用监控系统，聚合各业务系统调用延迟数据，达到链路调用监控跟踪。 追踪一次请求 基于微服务的链路追踪,当遇到请求第三方服务时候就无法,实现, 所以还有一种方法,就是给http请求做代理,拦截请求加上span,然后http发送给Zipkin服务器进行统计 spring-cloud-sleuth收集信息是有一定的比率的，默认的采样率是0.1，配置此值的方式在配置文件中增加spring.sleuth.sampler.percentage参数配置（如果不配置默认0.1），如果我们调大此值为1 参考文档: https://yq.aliyun.com/articles/78128?spm=5176.100239.blogcont78144.18.a7IIwu 其实，我们仔细想想也可以总结出这种方式的几种缺陷 缺陷1：zipkin客户端向zipkin-server程序发送数据使用的是http的方式通信，每次发送的时候涉及到连接和发送过程。 缺陷2：当我们的zipkin-server程序关闭或者重启过程中，因为客户端收集信息的发送采用http的方式会被丢失。 针对以上两个明显的缺陷，改进的办法是1、通信采用socket或者其他效率更高的通信方式。 2、客户端数据的发送尽量减少业务线程的时间消耗，采用异步等方式发送收集信息。 3、客户端与zipkin-server之间增加缓存类的中间件，例如redis、MQ等，在zipkin-server程序挂掉或重启过程中，客户端依旧可以正常的发送自己收集的信息。 相信采用以上三种方式会很大的提高我们的效率和可靠性。其实spring-cloud以及为我们提供采用MQ或redis等其他的采用socket方式通信，利用消息中间件或数据库缓存的实现方式。下一次我们再来测试spring-cloud-sleuth-zipkin-stream方式的实现。 6.1 如何在保证链路监控有效的情况下,对其进行监控! 引入spring-cloud-sleuth-zipkin-stream &amp; spring-cloud-starter-stream-rabbit 7. 网关转发模块Zuul正在完善，敬请期待，会有专篇，讲述！ 注册中心比较及Consul使用参考文档： https://www.consul.io/intro/vs/eureka.html 8.1 mac安装Consulbrew install consul https://127.0.0.1:8500/ui/#/dc1/services 9. 消息总线 Spring Cloud Bus在前面我们学习的文章中,我们学习了EventBus,从设计模式上来讲,是事件模式,原理即: 当服务引入bus组件,会将自动订阅,config-server-bus在rabbit或者kafka的队列,当向config-server-bus发起/bus/refresh更新事件的时候,会想所有订阅的服务,发起更新命令,即从新从config-server-bus中拉去配置信息。 这点可以参考小编之前的文章 10. 高可用分布式配置中心Spring Cloud Config参考文档：https://yq.aliyun.com/articles/169879?spm=5176.100239.blogcont173263.25.MgI7lF 创建config-server,和config-client并引入响应依赖,注意config-client一定要引入web模块,否则启动时候会自动注销 流程: config-server注册到eureka-1/2, config-client注册到eureka-1/2,并获取到config-server地址,从中读取配置信息,其中配置信息从git上面读取,可以配置用户信息 验证配置 启动config-server(端口号10003,启动顺序eureka-1 eureka-2 zipkin config-server config-client) 并 配置文件命名规则: 如何从config-server服务器,验证配置文件 https://localhost:10003/{applicationName}/{profile环境}/{lable分支} 负载均衡策略负载均衡（Server Load Balancer）是对多台云服务器进行流量分发的负载均衡服务。负载均衡可以通过流量分发扩展应用系统对外的服务能力，通过消除单点故障提升应用系统的可用性。 SLB通过购买云服务提供商的负载均衡服务(服务器根据供应商购买),然后配置 性能保障型实例的三个关键指标如下： 最大连接数-Max Connection 最大连接数定义了一个负载均衡实例能够承载的最大连接数量。当实例上的连接超过规格定义的最大连接数时，新建连接请求将被丢弃。 每秒新建连接数-Connection Per Second (CPS) 每秒新建连接数定义了新建连接的速率。当新建连接的速率超过规格定义的每秒新建连接数时，新建连接请求将被丢弃。 每秒查询数-Query Per Second (QPS) 每秒请求数是七层监听特有的概念，指的是每秒可以完成的HTTP/HTTPS的查询（请求）的数量。当请求速率超过规格所定义的每秒查询数时，新建连接请求将被丢弃。 11.1 阿里云基础架构负载均衡采用集群部署，可实现会话同步，以消除服务器单点故障，提升冗余，保证服务的稳定性。阿里云当前提供四层（TCP协议和UDP协议）和七层（HTTP和HTTPS协议）的负载均衡服务。 四层采用开源软件LVS（Linux Virtual Server）+ keepalived的方式实现负载均衡，并根据云计算需求对其进行了个性化定制。四层负载均衡实际上是由多台LVS机器部署成一个LVS集群来运行的。采用集群部署模式极大地保证了异常情况下负载均衡服务的可用性、稳定性与可扩展性。工作在TCP/IP协议的四层，其转发是依赖于四层协议的特征进行转发的，由于其转发要依赖于协议的特征进行转发，因此需要在内核的TCP/IP协议栈进行过滤筛选。 如果是四层监听，关注的重点是长连接的并发连接数，那么最大（并发）连接数应当作为一个关键指标来参考。根据不同的业务场景，您需要预估一个负载均衡实例需要承载的最大并发连接数，并选择相应的规格。 七层采用Tengine实现负载均衡。Tengine是由淘宝网发起的Web服务器项目，它在Nginx的基础上，针对有大访问量的网站需求，添加了很多高级功能和特性。七层负载均衡工作在OSI模型的应用层，因为它需要解析应用层流量，所以七层负载均衡在接到客户端的流量以后，还需要一个完整的TCP/IP协议栈。七层负载均衡会与客户端建立一条完整的连接并将应用层的请求流量解析出来，再按照调度算法选择一个应用服务器，并与应用服务器建立另外一条连接将请求发送过去，因此七层负载均衡的主要工作就是代理。 针对7层（HTTP协议和HTTPS协议）服务，负载均衡系统是基于Cookie的会话保持。负载均衡系统提供了两种Cookie处理方式: 植入Cookie: 此种方法下，您只需要指定cookie的过期时间。客户端第一次访问时，负载均衡服务在返回请求中植入cookie（即在HTTP/HTTPS响应报文中插入SERVERID字串），下次客户端携带此cookie访问，负载均衡服务会将请求定向转发给之前记录到的ECS实例上。 重写Cookie: 此种方式下，您可以根据需要指定HTTPS/HTTP响应中插入的cookie。您需要在后端ECS上维护该cookie的过期时间和生存时间。负载均衡服务发现用户自定义了cookie，将会对原来的cookie进行重写，下次客户端携带新的cookie访问，负载均衡服务会将请求定向转发给之前记录到的ECS实例上。 如果是七层监听，关注的重点是QPS的性能，QPS决定了一个七层应用系统的吞吐量。同样，您也需要根据经验对QPS进行预估。在初步选定一个规格后，在业务压测和实测过程中对规格进行微调。 12 .架构设计之高可用 服务层 nginx活性keepalive检测,域名连接代替ip连接 UI层到-服务层 静态资源cdn加速 服务层到-数据层 读写分离,连接关闭,数据库集群部署 多机房冗余 单机房无论多么冗余，多么牛逼，当施工队靠近，自然灾害发生，还是面临不可用，这时我们需要部署多机房高可用，服务多机房同活很容易，但是对于需要持久化的存储层则需要采用光纤直连，设置保证分布式多机房的情况，至少保证其中两个机房事务已经落盘，才返回给用户成功。当然会牺牲部分速度。 高可用是架构设计上必须考虑的问题，主要是指减少系统因为某些不可抗拒原因带来的不可用时间。方法论：冗余部署+自动故障转移+自动服务降级+自动服务隔离等","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.springlearn.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.springlearn.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.springlearn.cn/categories/Spring-Cloud/"}]},{"title":"JDK1.5-1.8各版本的新特性总结各版本的新特性总结","slug":"各版本的新特性总结","date":"2018-04-20T10:31:57.000Z","updated":"2018-04-23T06:32:31.460Z","comments":true,"path":"2018/04/20/各版本的新特性总结/","link":"","permalink":"https://blog.springlearn.cn/2018/04/20/各版本的新特性总结/","excerpt":"","text":"声明原文地址 以下介绍一下JDK1.5版本到JDK1.7版本的特性及JDK1.8主要部分特性。仅供参考。 JDK1.5新特性1：自动装箱与拆箱：自动装箱：每当需要一种类型的对象时，这种基本类型就自动地封装到与它相同类型的包装中。 自动拆箱：每当需要一个值时，被装箱对象中的值就被自动地提取出来，没必要再去调用intValue()和doubleValue()方法。 自动装箱，只需将该值赋给一个类型包装器引用，java会自动创建一个对象。 自动拆箱，只需将该对象值赋给一个基本类型即可。 java——类的包装器 类型包装器有：Double,Float,Long,Integer,Short,Character和Boolean 2：枚举把集合里的对象元素一个一个提取出来。枚举类型使代码更具可读性，理解清晰，易于维护。枚举类型是强类型的，从而保证了系统安全性。而以类的静态字段实现的类似替代模型，不具有枚举的简单性和类型安全性。 简单用法：JavaEnum简单的用法一般用于代表一组常用常量，可用来代表一类相同类型的常量值。 复杂用法：Java为枚举类型提供了一些内置的方法，同事枚举常量还可以有自己的方法。可以很方便的遍历枚举对象。 3：静态导入通过使用 import static，就可以不用指定 Constants 类名而直接使用静态成员，包括静态方法。 import xxxx 和 import static xxxx的区别是前者一般导入的是类文件如import java.util.Scanner;后者一般是导入静态的方法，import static java.lang.System.out。 4：可变参数（Varargs）可变参数的简单语法格式为： methodName([argumentList], dataType… argumentName); 5：内省（Introspector）内省是Java语言对Bean类属性、事件的一种缺省处理方法。例如类A中有属性name,那我们可以通过getName,setName来得到其值或者设置新 的值。通过getName/setName来访问name属性，这就是默认的规则。Java中提供了一套API用来访问某个属性的getter /setter方法，通过这些API可以使你不需要了解这个规则（但你最好还是要搞清楚），这些API存放于包java.beans中。 一 般的做法是通过类Introspector来获取某个对象的BeanInfo信息，然后通过BeanInfo来获取属性的描述器 （PropertyDescriptor），通过这个属性描述器就可以获取某个属性对应的getter/setter方法，然后我们就可以通过反射机制来 调用这些方法。 6：泛型(Generic)C++ 通过模板技术可以指定集合的元素类型，而Java在1.5之前一直没有相对应的功能。一个集合可以放任何类型的对象，相应地从集合里面拿对象的时候我们也不得不对他们进行强制得类型转换。猛虎引入了泛型，它允许指定集合里元素的类型，这样你可以得到强类型在编译时刻进行类型检查的好处。 7：For-Each循环For-Each循环得加入简化了集合的遍历。假设我们要遍历一个集合对其中的元素进行一些处理。 JDK 1.6新特性有关JDK1.6的新特性reamerit的博客文章已经说的很详细了。 1：Desktop类和SystemTray类在JDK6中 ,AWT新增加了两个类:Desktop和SystemTray。 前者可以用来打开系统默认浏览器浏览指定的URL,打开系统默认邮件客户端给指定的邮箱发邮件,用默认应用程序打开或编辑文件(比如,用记事本打开以txt为后缀名的文件),用系统默认的打印机打印文档;后者可以用来在系统托盘区创建一个托盘程序. 2：使用JAXB2来实现对象与XML之间的映射JAXB是Java Architecture for XML Binding的缩写，可以将一个Java对象转变成为XML格式，反之亦然。 我 们把对象与关系数据库之间的映射称为ORM, 其实也可以把对象与XML之间的映射称为OXM(Object XML Mapping). 原来JAXB是Java EE的一部分，在JDK6中，SUN将其放到了Java SE中，这也是SUN的一贯做法。JDK6中自带的这个JAXB版本是2.0, 比起1.0(JSR 31)来，JAXB2(JSR 222)用JDK5的新特性Annotation来标识要作绑定的类和属性等，这就极大简化了开发的工作量。 实 际上，在Java EE 5.0中，EJB和Web Services也通过Annotation来简化开发工作。另外,JAXB2在底层是用StAX(JSR 173)来处理XML文档。除了JAXB之外，我们还可以通过XMLBeans和Castor等来实现同样的功能。 3：理解StAXStAX(JSR 173)是JDK6.0中除了DOM和SAX之外的又一种处理XML文档的API。 StAX 的来历 ：在JAXP1.3(JSR 206)有两种处理XML文档的方法:DOM(Document Object Model)和SAX(Simple API for XML). 由 于JDK6.0中的JAXB2(JSR 222)和JAX-WS 2.0(JSR 224)都会用到StAX，所以Sun决定把StAX加入到JAXP家族当中来，并将JAXP的版本升级到1.4(JAXP1.4是JAXP1.3的维护版本). JDK6里面JAXP的版本就是1.4. 。 StAX是The Streaming API for XML的缩写，一种利用拉模式解析(pull-parsing)XML文档的API.StAX通过提供一种基于事件迭代器(Iterator)的API让 程序员去控制xml文档解析过程,程序遍历这个事件迭代器去处理每一个解析事件，解析事件可以看做是程序拉出来的，也就是程序促使解析器产生一个解析事件，然后处理该事件，之后又促使解析器产生下一个解析事件，如此循环直到碰到文档结束符； SAX也是基于事件处理xml文档，但却是用推模式解析，解析器解析完整个xml文档后，才产生解析事件，然后推给程序去处理这些事件；DOM 采用的方式是将整个xml文档映射到一颗内存树，这样就可以很容易地得到父节点和子结点以及兄弟节点的数据，但如果文档很大，将会严重影响性能。 4.使用Compiler API现在我们可以用JDK6 的Compiler API(JSR 199)去动态编译Java源文件，Compiler API结合反射功能就可以实现动态的产生Java代码并编译执行这些代码，有点动态语言的特征。 这个特性对于某些需要用到动态编译的应用程序相当有用，比如JSP Web Server，当我们手动修改JSP后，是不希望需要重启Web Server才可以看到效果的，这时候我们就可以用Compiler API来实现动态编译JSP文件，当然，现在的JSP Web Server也是支持JSP热部署的，现在的JSP Web Server通过在运行期间通过Runtime.exec或ProcessBuilder来调用javac来编译代码，这种方式需要我们产生另一个进程去 做编译工作，不够优雅而且容易使代码依赖与特定的操作系统；Compiler API通过一套易用的标准的API提供了更加丰富的方式去做动态编译,而且是跨平台的。 5：轻量级Http Server APIJDK6 提供了一个简单的Http Server API,据此我们可以构建自己的嵌入式Http Server,它支持Http和Https协议,提供了HTTP1.1的部分实现，没有被实现的那部分可以通过扩展已有的Http Server API来实现,程序员必须自己实现HttpHandler接口,HttpServer会调用HttpHandler实现类的回调方法来处理客户端请求,在 这里,我们把一个Http请求和它的响应称为一个交换,包装成HttpExchange类,HttpServer负责将HttpExchange传给 HttpHandler实现类的回调方法. 6：插入式注解处理API(Pluggable Annotation Processing API)插入式注解处理API(JSR 269)提供一套标准API来处理Annotations(JSR 175) 实 际上JSR 269不仅仅用来处理Annotation,我觉得更强大的功能是它建立了Java 语言本身的一个模型,它把method, package, constructor, type, variable, enum, annotation等Java语言元素映射为Types和Elements(两者有什么区别?), 从而将Java语言的语义映射成为对象, 我们可以在javax.lang.model包下面可以看到这些类. 所以我们可以利用JSR 269提供的API来构建一个功能丰富的元编程(metaprogramming)环境. JSR 269用Annotation Processor在编译期间而不是运行期间处理Annotation, Annotation Processor相当于编译器的一个插件,所以称为插入式注解处理.如果Annotation Processor处理Annotation时(执行process方法)产生了新的Java代码,编译器会再调用一次Annotation Processor,如果第二次处理还有新代码产生,就会接着调用Annotation Processor,直到没有新代码产生为止.每执行一次process()方法被称为一个”round”,这样整个Annotation processing过程可以看作是一个round的序列. JSR 269主要被设计成为针对Tools或者容器的API. 举个例子,我们想建立一套基于Annotation的单元测试框架(如TestNG),在测试类里面用Annotation来标识测试期间需要执行的测试方法。 7：用Console开发控制台程序JDK6 中提供了java.io.Console 类专用来访问基于字符的控制台设备. 你的程序如果要与Windows下的cmd或者Linux下的Terminal交互,就可以用Console类代劳. 但我们不总是能得到可用的Console, 一个JVM是否有可用的Console依赖于底层平台和JVM如何被调用. 如果JVM是在交互式命令行(比如Windows的cmd)中启动的,并且输入输出没有重定向到另外的地方,那么就可以得到一个可用的Console实例. 8：对脚本语言的支持如: ruby, groovy, javascript9：Common AnnotationsCommon annotations原本是Java EE 5.0(JSR 244)规范的一部分，现在SUN把它的一部分放到了Java SE 6.0中. 随 着Annotation元数据功能(JSR 175)加入到Java SE 5.0里面，很多Java 技术(比如EJB,Web Services)都会用Annotation部分代替XML文件来配置运行参数（或者说是支持声明式编程,如EJB的声明式事务）, 如果这些技术为通用目的都单独定义了自己的Annotations,显然有点重复建设, 所以,为其他相关的Java技术定义一套公共的Annotation是有价值的，可以避免重复建设的同时，也保证Java SE和Java EE 各种技术的一致性. 下面列举出Common Annotations 1.0里面的10个Annotations Common Annotations Annotation Retention Target Description Generated Source ANNOTATION_TYPE, CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE 用于标注生成的源代码 Resource Runtime TYPE, METHOD, FIELD 用于标注所依赖的资源,容器据此注入外部资源依赖，有基于字段的注入和基于setter方法的注入两种方式 Resources Runtime TYPE 同时标注多个外部依赖，容器会把所有这些外部依赖注入 PostConstruct Runtime METHOD 标注当容器注入所有依赖之后运行的方法，用来进行依赖注入后的初始化工作，只有一个方法可以标注为PostConstruct PreDestroy Runtime METHOD 当对象实例将要被从容器当中删掉之前，要执行的回调方法要标注为PreDestroy RunAs Runtime TYPE 用于标注用什么安全角色来执行被标注类的方法，这个安全角色必须和Container 的Security角色一致的。RolesAllowed Runtime TYPE, METHOD 用于标注允许执行被标注类或方法的安全角色，这个安全角色必须和Container 的Security角色一致的 PermitAll Runtime TYPE, METHOD 允许所有角色执行被标注的类或方法 DenyAll Runtime TYPE, METHOD 不允许任何角色执行被标注的类或方法，表明该类或方法不能在Java EE容器里面运行 DeclareRoles Runtime TYPE 用来定义可以被应用程序检验的安全角色，通常用isUserInRole来检验安全角色 注意: 1.RolesAllowed,PermitAll,DenyAll不能同时应用到一个类或方法上 2.标注在方法上的RolesAllowed,PermitAll,DenyAll会覆盖标注在类上的RolesAllowed,PermitAll,DenyAll 3.RunAs,RolesAllowed,PermitAll,DenyAll和DeclareRoles还没有加到Java SE 6.0上来 4.处理以上Annotations的工作是由Java EE容器来做, Java SE 6.0只是包含了上面表格的前五种Annotations的定义类,并没有包含处理这些Annotations的引擎,这个工作可以由Pluggable Annotation Processing API(JSR 269)来做 改动的地方最大的就是java GUI界面的显示了，JDK6.0（也就是JDK1.6）支持最新的windows vista系统的Windows Aero视窗效果，而JDK1.5不支持！！！ 你要在vista环境下编程的话最好装jdk6.0，否则它总是换到windows basic视窗效果. JDK 1.7 新特性1：switch中可以使用字串1234567891011String s = \"test\";switch (s) &#123; case \"test\" : System.out.println(\"test\");case \"test1\" : System.out.println(\"test1\");break ;default : System.out.println(\"break\");break ;&#125; 2：”&lt;&gt;”这个玩意儿的运用123456789101112131415161718192021222324List tempList = new ArrayList&lt;&gt;(); 即泛型实例化类型自动推断。public class JDK7GenericTest &#123; public static void main(String[] args) &#123; // Pre-JDK 7 List&lt;String&gt; lst1 = new ArrayList&lt;String&gt;(); // JDK 7 supports limited type inference for generic instance creation List&lt;String&gt; lst2 = new ArrayList&lt;&gt;(); lst1.add(\"Mon\"); lst1.add(\"Tue\"); lst2.add(\"Wed\"); lst2.add(\"Thu\"); for (String item: lst1) &#123; System.out.println(item); &#125; for (String item: lst2) &#123; System.out.println(item); &#125; &#125;&#125; 3：自定义自动关闭类以下是jdk7 api中的接口，（不过注释太长，删掉了close()方法的一部分注释）123456789101112131415/** * A resource that must be closed when it is no longer needed. * * @author Josh Bloch * @since 1.7 */public interface AutoCloseable &#123; /** * Closes this resource, relinquishing any underlying resources. * This method is invoked automatically on objects managed by the * &#123;@code try&#125;-with-resources statement. * */ void close() throws Exception;&#125; 只要实现该接口，在该类对象销毁时自动调用close方法，你可以在close方法关闭你想关闭的资源，例子如下12345678910111213141516171819class TryClose implements AutoCloseable &#123; @Override public void close() throw Exception &#123; System.out.println(\" Custom close method … close resources \"); &#125;&#125;//请看jdk自带类BufferedReader如何实现close方法（当然还有很多类似类型的类） public void close() throws IOException &#123; synchronized (lock) &#123; if (in == null) return; in.close(); in = null; cb = null; &#125; &#125; 4：新增一些取环境信息的工具方法1234567File System.getJavaIoTempDir() // IO临时文件夹File System.getJavaHomeDir() // JRE的安装目录File System.getUserHomeDir() // 当前用户目录File System.getUserDir() // 启动java进程时所在的目录 ……. 5：Boolean类型反转，空指针安全，参与位运算123456789101112131415Boolean Booleans.negate(Boolean booleanObj)True =&gt; False , False =&gt; True, Null =&gt; Nullboolean Booleans.and(boolean[] array)boolean Booleans.or(boolean[] array)boolean Booleans.xor(boolean[] array)boolean Booleans.and(Boolean[] array)boolean Booleans.or(Boolean[] array)boolean Booleans.xor(Boolean[] array) 6： 两个char间的equalsboolean Character.equalsIgnoreCase(char ch1, char ch2) 7：安全的加减乘除1234567891011121314151617181920212223int Math.safeToInt(long value)int Math.safeNegate(int value)long Math.safeSubtract(long value1, int value2)long Math.safeSubtract(long value1, long value2)int Math.safeMultiply(int value1, int value2)long Math.safeMultiply(long value1, int value2)long Math.safeMultiply(long value1, long value2)long Math.safeNegate(long value)int Math.safeAdd(int value1, int value2)long Math.safeAdd(long value1, int value2)long Math.safeAdd(long value1, long value2)int Math.safeSubtract(int value1, int value2) 8：对Java集合（Collections）的增强支持在JDK1.7之前的版本中，Java集合容器中存取元素的形式如下： 以List、Set、Map集合容器为例：12345678910111213//创建List接口对象List&lt;String&gt; list=new ArrayList&lt;String&gt;();list.add(\"item\"); //用add()方法获取对象String Item=list.get(0); //用get()方法获取对象//创建Set接口对象Set&lt;String&gt; set=new HashSet&lt;String&gt;();set.add(\"item\"); //用add()方法添加对象//创建Map接口对象Map&lt;String,Integer&gt; map=new HashMap&lt;String,Integer&gt;();map.put(\"key\",1); //用put()方法添加对象int value=map.get(\"key\"); 在JDK1.7中，摒弃了Java集合接口的实现类，如：ArrayList、HashSet和HashMap。而是直接采用[]、{}的形式存入对象，采用[]的形式按照索引、键值来获取集合中的对象，如下：123456List&lt;String&gt; list=[\"item\"]; //向List集合中添加元素 String item=list[0]; //从List集合中获取元素 Set&lt;String&gt; set=&#123;\"item\"&#125;; //向Set集合对象中添加元素 Map&lt;String,Integer&gt; map=&#123;\"key\":1&#125;; //向Map集合中添加对象 int value=map[\"key\"]; //从Map集合中获取对象 9：数值可加下划线例如：int one_million = 1_000_000; 10：支持二进制文字例如：int binary = 0b1001_1001; 11：简化了可变参数方法的调用当程序员试图使用一个不可具体化的可变参数并调用一个varargs （可变）方法时，编辑器会生成一个“非安全操作”的警告。 12：在try catch异常扑捉中，一个catch可以写多个异常类型，用”|”隔开jdk7之前：1234567try &#123; ......&#125; catch(ClassNotFoundException ex) &#123; ex.printStackTrace();&#125; catch(SQLException ex) &#123; ex.printStackTrace();&#125; jdk7例子如下12345try &#123; ......&#125; catch(ClassNotFoundException|SQLException ex) &#123; ex.printStackTrace();&#125; 13：jdk7之前，你必须用try{}finally{}在try内使用资源，在finally中关闭资源，不管try中的代码是否正常退出或者异常退出。jdk7之后，你可以不必要写finally语句来关闭资源，只要你在try()的括号内部定义要使用的资源jdk7之前：123456789101112131415161718192021222324252627282930313233import java.io.*;// Copy from one file to another file character by character.// Pre-JDK 7 requires you to close the resources using a finally block.public class FileCopyPreJDK7 &#123; public static void main(String[] args) &#123; BufferedReader in = null; BufferedWriter out = null; try &#123; in = new BufferedReader(new FileReader(\"in.txt\")); out = new BufferedWriter(new FileWriter(\"out.txt\")); int charRead; while ((charRead = in.read()) != -1) &#123; System.out.printf(\"%c \", (char)charRead); out.write(charRead); &#125; &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; finally &#123; // always close the streams try &#123; if (in != null) in.close(); if (out != null) out.close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; try &#123; in.read(); // Trigger IOException: Stream closed &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125;&#125; jdk7之后123456789101112131415161718import java.io.*;// Copy from one file to another file character by character.// JDK 7 has a try-with-resources statement, which ensures that// each resource opened in try() is closed at the end of the statement.public class FileCopyJDK7 &#123; public static void main(String[] args) &#123; try (BufferedReader in = new BufferedReader(new FileReader(\"in.txt\")); BufferedWriter out = new BufferedWriter(new FileWriter(\"out.txt\"))) &#123; int charRead; while ((charRead = in.read()) != -1) &#123; System.out.printf(\"%c \", (char)charRead); out.write(charRead); &#125; &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125;&#125; JAVA8 十大新特性1：接口的默认方法Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用 default关键字即可，这个特征又叫做扩展方法，示例如下： 代码如下:123456interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123; return Math.sqrt(a); &#125;&#125; Formula接口在拥有calculate方法之外同时还定义了sqrt方法，实现了Formula接口的子类只需要实现一个calculate方法，默认方法sqrt将在子类上可以直接使用。 代码如下:123456789Formula formula = new Formula() &#123; @Override public double calculate(int a) &#123; return sqrt(a * 100); &#125;&#125;;formula.calculate(100); // 100.0formula.sqrt(16); // 4.0 文中的formula被实现为一个匿名类的实例，该代码非常容易理解，6行代码实现了计算 sqrt(a * 100)。在下一节中，我们将会看到实现单方法接口的更简单的做法。 译者注： 在Java中只有单继承，如果要让一个类赋予新的特性，通常是使用接口来实现，在C++中支持多继承，允许一个子类同时具有多个父类的接口与功能，在其他 语言中，让一个类同时具有其他的可复用代码的方法叫做mixin。新的Java 8 的这个特新在编译器实现的角度上来说更加接近Scala的trait。 在C#中也有名为扩展方法的概念，允许给已存在的类型扩展方法，和Java 8的这个在语义上有差别。 2：Lambda 表达式首先看看在老版本的Java中是如何排列字符串的：1234567List&lt;String&gt; names = Arrays.asList(\"peter\", \"anna\", \"mike\", \"xenia\");Collections.sort(names, new Comparator&lt;String&gt;() &#123; @Override public int compare(String a, String b) &#123; return b.compareTo(a); &#125;&#125;); 只需要给静态方法 Collections.sort 传入一个List对象以及一个比较器来按指定顺序排列。通常做法都是创建一个匿名的比较器对象然后将其传递给sort方法。 在Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8提供了更简洁的语法，lambda表达式：123Collections.sort(names, (String a, String b) -&gt; &#123; return b.compareTo(a);&#125;); 看到了吧，代码变得更段且更具有可读性，但是实际上还可以写得更短： Collections.sort(names, (String a, String b) -&gt; b.compareTo(a));对于函数体只有一行代码的，你可以去掉大括号{}以及return关键字，但是你还可以写得更短点： Collections.sort(names, (a, b) -&gt; b.compareTo(a));nava编译器可以自动推导出参数类型，所以你可以不用再写一次类型。接下来我们看看lambda表达式还能作出什么更方便的东西来 3：函数式接口Lambda 表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的 接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为 默认方法 不算抽象方法，所以你也可以给你的函数式接口添加默认方法。 我们可以将lambda表达式当作任意只包含一个抽象方法的接口类型，确保你的接口一定达到这个要求，你只需要给你的接口添加 @FunctionalInterface 注解，编译器如果发现你标注了这个注解的接口有多于一个抽象方法的时候会报错的。 示例如下：1234567@FunctionalInterfaceinterface Converter&lt;F, T&gt; &#123; T convert(F from);&#125;Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert(\"123\");System.out.println(converted); // 123 需要注意如果@FunctionalInterface如果没有指定，上面的代码也是对的。 译者注 将lambda表达式映射到一个单方法的接口上，这种做法在Java 8之前就有别的语言实现，比如Rhino JavaScript解释器，如果一个函数参数接收一个单方法的接口而你传递的是一个function，Rhino 解释器会自动做一个单接口的实例到function的适配器，典型的应用场景有 org.w3c.dom.events.EventTarget 的addEventListener 第二个参数 EventListener。 4：方法与构造函数引用前一节中的代码还可以通过静态方法引用来表示：123Converter&lt;String, Integer&gt; converter = Integer::valueOf;Integer converted = converter.convert(\"123\");System.out.println(converted); // 123 Java 8 允许你使用 :: 关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法：123converter = something::startsWith;String converted = converter.convert(\"Java\");System.out.println(converted); // \"J\" 接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类：12345678910class Person &#123; String firstName; String lastName; Person() &#123;&#125; Person(String firstName, String lastName) &#123; this.firstName = firstName; this.lastName = lastName; &#125;&#125; 接下来我们指定一个用来创建Person对象的对象工厂接口：123interface PersonFactory&lt;P extends Person&gt; &#123; P create(String firstName, String lastName);&#125; 这里我们使用构造函数引用来将他们关联起来，而不是实现一个完整的工厂：12PersonFactory&lt;Person&gt; personFactory = Person::new;Person person = personFactory.create(\"Peter\", \"Parker\"); 我们只需要使用 Person::new 来获取Person类构造函数的引用，Java编译器会自动根据PersonFactory.create方法的签名来选择合适的构造函数。 5：Lambda 作用域在lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。你可以直接访问标记了final的外层局部变量，或者实例的字段以及静态变量。 6：访问局部变量我们可以直接在lambda表达式中访问外层的局部变量：1234567891011121314151617final int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); // 3但是和匿名对象不同的是，这里的变量num可以不用声明为final，该代码同样正确：int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);stringConverter.convert(2); // 3不过这里的num必须不可被后面的代码修改（即隐性的具有final的语义），例如下面的就无法编译：int num = 1;Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num);num = 3;在lambda表达式中试图修改num同样是不允许的。 7：访问对象字段与静态变量和本地变量不同的是，lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的：123456789101112131415class Lambda4 &#123; static int outerStaticNum; int outerNum; void testScopes() &#123; Converter&lt;Integer, String&gt; stringConverter1 = (from) -&gt; &#123; outerNum = 23; return String.valueOf(from); &#125;; Converter&lt;Integer, String&gt; stringConverter2 = (from) -&gt; &#123; outerStaticNum = 72; return String.valueOf(from); &#125;; &#125;&#125; 8：访问接口的默认方法还记得第一节中的formula例子么，接口Formula定义了一个默认方法sqrt可以直接被formula的实例包括匿名对象访问到，但是在lambda表达式中这个是不行的。Lambda表达式中是无法访问到默认方法的，以下代码将无法编译：12345Formula formula = (a) -&gt; sqrt( a * 100);Built-in Functional Interfaces### JDK 1.8 API包含了很多内建的函数式接口，在老Java中常用到的比如Comparator或者Runnable接口，这些接口都增加了@FunctionalInterface注解以便能用在lambda上。Java 8 API同样还提供了很多全新的函数式接口来让工作更加方便，有一些接口是来自Google Guava库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到lambda上使用的。 Predicate接口1234567891011Predicate 接口只有一个参数，返回boolean类型。该接口包含多种默认方法来将Predicate组合成其他复杂的逻辑（比如：与，或，非）：Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;predicate.test(\"foo\"); // truepredicate.negate().test(\"foo\"); // falsePredicate&lt;Boolean&gt; nonNull = Objects::nonNull;Predicate&lt;Boolean&gt; isNull = Objects::isNull;Predicate&lt;String&gt; isEmpty = String::isEmpty;Predicate&lt;String&gt; isNotEmpty = isEmpty.negate(); Function 接口12345Function 接口有一个参数并且返回一个结果，并附带了一些可以和其他函数组合的默认方法（compose, andThen）：Function&lt;String, Integer&gt; toInteger = Integer::valueOf;Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);backToString.apply(\"123\"); // \"123\" Supplier 接口1234Supplier 接口返回一个任意范型的值，和Function接口不同的是该接口没有任何参数Supplier&lt;Person&gt; personSupplier = Person::new;personSupplier.get(); // new Person Consumer 接口Consumer 接口表示执行在单个参数上的操作。12345678910Consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println(\"Hello, \" + p.firstName);greeter.accept(new Person(\"Luke\", \"Skywalker\"));Comparator 接口Comparator 是老Java中的经典接口， Java 8在此之上添加了多种默认方法：Comparator&lt;Person&gt; comparator = (p1, p2) -&gt; p1.firstName.compareTo(p2.firstName);Person p1 = new Person(\"John\", \"Doe\");Person p2 = new Person(\"Alice\", \"Wonderland\");comparator.compare(p1, p2); // &gt; 0comparator.reversed().compare(p1, p2); // &lt; 0 Optional 接口Optional 不是函数是接口，这是个用来防止NullPointerException异常的辅助类型，这是下一届中将要用到的重要概念，现在先简单的看看这个接口能干什么： Optional 被定义为一个简单的容器，其值可能是null或者不是null。在Java 8之前一般某个函数应该返回非空对象但是偶尔却可能返回了null，而在Java 8中，不推荐你返回null而是返回Optional。123456Optional&lt;String&gt; optional = Optional.of(\"bam\");optional.isPresent(); // trueoptional.get(); // \"bam\"optional.orElse(\"fallback\"); // \"bam\"optional.ifPresent((s) -&gt; System.out.println(s.charAt(0))); // \"b\" Stream 接口java.util.Stream 表示能应用在一组元素上一次执行的操作序列。Stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回Stream本身，这样你就可以将多个操作依次串起来。 Stream 的创建需要指定一个数据源，比如 java.util.Collection的子类，List或者Set， Map不支持。Stream的操作可以串行执行或者并行执行。 首先看看Stream是怎么用，首先创建实例代码的用到的数据List：12345678910List&lt;String&gt; stringCollection = new ArrayList&lt;&gt;();stringCollection.add(\"ddd2\");stringCollection.add(\"aaa2\");stringCollection.add(\"bbb1\");stringCollection.add(\"aaa1\");stringCollection.add(\"bbb3\");stringCollection.add(\"ccc\");stringCollection.add(\"bbb2\");stringCollection.add(\"ddd1\");Java 8扩展了集合类，可以通过 Collection.stream() 或者 Collection.parallelStream() 来创建一个Stream。下面几节将详细解释常用的Stream操作： Filter 过滤过滤通过一个predicate接口来过滤并只保留符合条件的元素，该操作属于中间操作，所以我们可以在过滤后的结果来应用其他Stream操作 （比如forEach）。forEach需要一个函数来对过滤后的元素依次执行。forEach是一个最终操作，所以我们不能在forEach之后来执行 其他Stream操作。12345stringCollection .stream() .filter((s) -&gt; s.startsWith(\"a\")) .forEach(System.out::println);// \"aaa2\", \"aaa1\" Sort 排序排序是一个中间操作，返回的是排序好后的Stream。如果你不指定一个自定义的Comparator则会使用默认排序。12345678910stringCollection .stream() .sorted() .filter((s) -&gt; s.startsWith(\"a\")) .forEach(System.out::println);// \"aaa1\", \"aaa2\"需要注意的是，排序只创建了一个排列好后的Stream，而不会影响原有的数据源，排序之后原数据stringCollection是不会被修改的：System.out.println(stringCollection);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1 Map 映射中间操作map会将元素根据指定的Function接口来依次将元素转成另外的对象，下面的示例展示了将字符串转换为大写字符串。你也可以通过map来讲对象转换成其他类型，map返回的Stream类型是根据你map传递进去的函数的返回值决定的。123456stringCollection .stream() .map(String::toUpperCase) .sorted((a, b) -&gt; b.compareTo(a)) .forEach(System.out::println);// \"DDD2\", \"DDD1\", \"CCC\", \"BBB3\", \"BBB2\", \"AAA2\", \"AAA1\" Match 匹配Stream提供了多种匹配操作，允许检测指定的Predicate是否匹配整个Stream。所有的匹配操作都是最终操作，并返回一个boolean类型的值。12345678910111213141516171819boolean anyStartsWithA = stringCollection .stream() .anyMatch((s) -&gt; s.startsWith(\"a\"));System.out.println(anyStartsWithA); // trueboolean allStartsWithA = stringCollection .stream() .allMatch((s) -&gt; s.startsWith(\"a\"));System.out.println(allStartsWithA); // falseboolean noneStartsWithZ = stringCollection .stream() .noneMatch((s) -&gt; s.startsWith(\"z\"));System.out.println(noneStartsWithZ); // true Count 计数计数是一个最终操作，返回Stream中元素的个数，返回值类型是long。123456long startsWithB = stringCollection .stream() .filter((s) -&gt; s.startsWith(\"b\")) .count();System.out.println(startsWithB); // 3 Reduce 规约这是一个最终操作，允许通过指定的函数来讲stream中的多个元素规约为一个元素，规越后的结果是通过Optional接口表示的：12345678Optional&lt;String&gt; reduced = stringCollection .stream() .sorted() .reduce((s1, s2) -&gt; s1 + \"#\" + s2);reduced.ifPresent(System.out::println);// \"aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2\"并行Streams 前面提到过Stream有串行和并行两种，串行Stream上的操作是在一个线程中依次完成，而并行Stream则是在多个线程上同时执行。 下面的例子展示了是如何通过并行Stream来提升性能： 首先我们创建一个没有重复元素的大表：123456int max = 1000000;List&lt;String&gt; values = new ArrayList&lt;&gt;(max);for (int i = 0; i &lt; max; i++) &#123; UUID uuid = UUID.randomUUID(); values.add(uuid.toString());&#125; 然后我们计算一下排序这个Stream要耗时多久， 串行排序：12345678910111213141516171819202122long t0 = System.nanoTime();long count = values.stream().sorted().count();System.out.println(count);long t1 = System.nanoTime();long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);System.out.println(String.format(\"sequential sort took: %d ms\", millis));// 串行耗时: 899 ms并行排序：long t0 = System.nanoTime();long count = values.parallelStream().sorted().count();System.out.println(count);long t1 = System.nanoTime();long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);System.out.println(String.format(\"parallel sort took: %d ms\", millis));// 并行排序耗时: 472 ms上面两个代码几乎是一样的，但是并行版的快了50%之多，唯一需要做的改动就是将stream()改为parallelStream()。 Map 前面提到过，Map类型不支持stream，不过Map提供了一些新的有用的方法来处理一些日常任务。12345Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;();for (int i = 0; i &lt; 10; i++) &#123; map.putIfAbsent(i, \"val\" + i);&#125;map.forEach((id, val) -&gt; System.out.println(val)); 以上代码很容易理解， putIfAbsent 不需要我们做额外的存在性检查，而forEach则接收一个Consumer接口来对map里的每一个键值对进行操作。 下面的例子展示了map上的其他有用的函数：1234567891011121314151617181920212223242526map.computeIfPresent(3, (num, val) -&gt; val + num);map.get(3); // val33map.computeIfPresent(9, (num, val) -&gt; null);map.containsKey(9); // falsemap.computeIfAbsent(23, num -&gt; \"val\" + num);map.containsKey(23); // truemap.computeIfAbsent(3, num -&gt; \"bam\");map.get(3); // val33接下来展示如何在Map里删除一个键值全都匹配的项：map.remove(3, \"val3\");map.get(3); // val33map.remove(3, \"val33\");map.get(3); // null另外一个有用的方法：map.getOrDefault(42, \"not found\"); // not found对Map的元素做合并也变得很容易了：map.merge(9, \"val9\", (value, newValue) -&gt; value.concat(newValue));map.get(9); // val9map.merge(9, \"concat\", (value, newValue) -&gt; value.concat(newValue));map.get(9); // val9concatMerge做的事情是如果键名不存在则插入，否则则对原键对应的值做合并操作并重新插入到map中。 9：Date APIJava 8 在包java.time下包含了一组全新的时间日期API。新的日期API和开源的Joda-Time库差不多，但又不完全一样，下面的例子展示了这组新API里最重要的一些部分：Clock 时钟 Clock类提供了访问当前日期和时间的方法，Clock是时区敏感的，可以用来取代 System.currentTimeMillis() 来获取当前的微秒数。某一个特定的时间点也可以使用Instant类来表示，Instant类也可以用来创建老的java.util.Date对象。1234Clock clock = Clock.systemDefaultZone();long millis = clock.millis();Instant instant = clock.instant();Date legacyDate = Date.from(instant); // legacy java.util.Date Timezones 时区 在新API中时区使用ZoneId来表示。时区可以很方便的使用静态方法of来获取到。 时区定义了到UTS时间的时间差，在Instant时间点对象到本地日期对象之间转换的时候是极其重要的。12345678System.out.println(ZoneId.getAvailableZoneIds());// prints all available timezone idsZoneId zone1 = ZoneId.of(\"Europe/Berlin\");ZoneId zone2 = ZoneId.of(\"Brazil/East\");System.out.println(zone1.getRules());System.out.println(zone2.getRules());// ZoneRules[currentStandardOffset=+01:00]// ZoneRules[currentStandardOffset=-03:00] LocalTime 本地时间LocalTime 定义了一个没有时区信息的时间，例如 晚上10点，或者 17:30:15。下面的例子使用前面代码创建的时区创建了两个本地时间。之后比较时间并以小时和分钟为单位计算两个时间的时间差： 123456789LocalTime now1 = LocalTime.now(zone1);LocalTime now2 = LocalTime.now(zone2);System.out.println(now1.isBefore(now2)); // falselong hoursBetween = ChronoUnit.HOURS.between(now1, now2);long minutesBetween = ChronoUnit.MINUTES.between(now1, now2);System.out.println(hoursBetween); // -3System.out.println(minutesBetween); // -239 LocalTime 提供了多种工厂方法来简化对象的创建，包括解析时间字符串。12345678910LocalTime late = LocalTime.of(23, 59, 59);System.out.println(late); // 23:59:59DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedTime(FormatStyle.SHORT) .withLocale(Locale.GERMAN);LocalTime leetTime = LocalTime.parse(\"13:37\", germanFormatter);System.out.println(leetTime); // 13:37LocalDate 本地日期 LocalDate 表示了一个确切的日期，比如 2014-03-11。该对象值是不可变的，用起来和LocalTime基本一致。下面的例子展示了如何给Date对象加减天/月/年。另外要注意的是这些对象是不可变的，操作返回的总是一个新实例。12345678LocalDate today = LocalDate.now();LocalDate tomorrow = today.plus(1, ChronoUnit.DAYS);LocalDate yesterday = tomorrow.minusDays(2);LocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4);DayOfWeek dayOfWeek = independenceDay.getDayOfWeek();System.out.println(dayOfWeek); // FRIDAY 从字符串解析一个LocalDate类型和解析LocalTime一样简单：1234567DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedDate(FormatStyle.MEDIUM) .withLocale(Locale.GERMAN);LocalDate xmas = LocalDate.parse(\"24.12.2014\", germanFormatter);System.out.println(xmas); // 2014-12-24LocalDateTime 本地日期时间 LocalDateTime 同时表示了时间和日期，相当于前两节内容合并到一个对象上了。LocalDateTime和LocalTime还有LocalDate一样，都是不可变的。LocalDateTime提供了一些能访问具体字段的方法。123456789LocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59);DayOfWeek dayOfWeek = sylvester.getDayOfWeek();System.out.println(dayOfWeek); // WEDNESDAYMonth month = sylvester.getMonth();System.out.println(month); // DECEMBERlong minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY);System.out.println(minuteOfDay); // 1439 只要附加上时区信息，就可以将其转换为一个时间点Instant对象，Instant时间点对象可以很容易的转换为老式的java.util.Date。12345Instant instant = sylvester .atZone(ZoneId.systemDefault()) .toInstant();Date legacyDate = Date.from(instant);System.out.println(legacyDate); // Wed Dec 31 23:59:59 CET 2014 格式化LocalDateTime和格式化时间和日期一样的，除了使用预定义好的格式外，我们也可以自己定义格式：123456DateTimeFormatter formatter = DateTimeFormatter .ofPattern(\"MMM dd, yyyy - HH:mm\");LocalDateTime parsed = LocalDateTime.parse(\"Nov 03, 2014 - 07:13\", formatter);String string = formatter.format(parsed);System.out.println(string); // Nov 03, 2014 - 07:13 和java.text.NumberFormat不一样的是新版的DateTimeFormatter是不可变的，所以它是线程安全的。关于时间日期格式的详细信息：https://download.java.net/jdk8/docs/api/java/time/format/DateTimeFormatter.html 10：Annotation 注解在Java 8中支持多重注解了，先看个例子来理解一下是什么意思。首先定义一个包装类Hints注解用来放置一组具体的Hint注解：1234567@interface Hints &#123; Hint[] value();&#125;@Repeatable(Hints.class)@interface Hint &#123; String value();&#125; Java 8允许我们把同一个类型的注解使用多次，只需要给该注解标注一下@Repeatable即可。 例 1: 使用包装类当容器来存多个注解（老方法） @Hints({@Hint(“hint1”), @Hint(“hint2”)})class Person {}例 2：使用多重注解（新方法）123@Hint(\"hint1\")@Hint(\"hint2\")class Person &#123;&#125; 第二个例子里java编译器会隐性的帮你定义好@Hints注解，了解这一点有助于你用反射来获取这些信息：123456Hint hint = Person.class.getAnnotation(Hint.class);System.out.println(hint); // nullHints hints1 = Person.class.getAnnotation(Hints.class);System.out.println(hints1.value().length); // 2Hint[] hints2 = Person.class.getAnnotationsByType(Hint.class);System.out.println(hints2.length); // 2 即便我们没有在Person类上定义@Hints注解，我们还是可以通过 getAnnotation(Hints.class) 来获取 @Hints注解，更加方便的方法是使用 getAnnotationsByType 可以直接获取到所有的@Hint注解。另外Java 8的注解还增加到两种新的target上了：12@Target(&#123;ElementType.TYPE_PARAMETER, ElementType.TYPE_USE&#125;)@interface MyAnnotation &#123;&#125; 关于Java 8的新特性就写到这了，肯定还有更多的特性等待发掘。JDK 1.8里还有很多很有用的东西，比如Arrays.parallelSort, StampedLock和CompletableFuture等等。","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://blog.springlearn.cn/tags/JDK/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"SpringBoot2.0之WebFlux解析及实战","slug":"SpringBoot2-0之WebFlux解析及实战","date":"2018-04-18T12:10:31.000Z","updated":"2018-04-23T06:32:36.544Z","comments":true,"path":"2018/04/18/SpringBoot2-0之WebFlux解析及实战/","link":"","permalink":"https://blog.springlearn.cn/2018/04/18/SpringBoot2-0之WebFlux解析及实战/","excerpt":"","text":"SpringBoot我是从1.2开始用的，我仿佛停留在1.5刚出来,支持了动态修改日志级别的时候,可突然之间2.0就出来了，貌似只有短短一年半的时间，突然感觉到了危机感，仿佛自己马上就要被淘汰了,在经过学习之后，将自己的项目demo和我对SpringBoot2.0的理解，分享给大家！ 如果有错误的地方,欢迎留言指出，最后谢谢各位，观看！ 小编学习的途径是先直接到官网看看，于是看到了最明显的区别就是下图图先放这里,先不着急，先看下，有一个印象，后面会说到。 先说一下官方的SpringBoot2.0新特性描述 SpringBoot2.0新特性 编程语言Java8+,和当前火爆的Kotlin 底层框架Spring Framwork 5.0.x 全新特性Web Flux（小编认为我们学习SpringBoot2.0就是学习这个） 我们分析下2.0的新特性为什么编程语言要从Java8开始呢？ 一个重要的原因就是使用Java8的Lambda表达式和Stream流处理 包括Spring Framwork 5.0.x也是要用到Java8的新特性. 当我们对SpringBoot2.0的新特性有一个认识的时候，再来看开头的第一张图片上面开篇截取Spring.io官网的图片。我们就能对SpringBoot1.0和2.0在心里有一个判断 SpringBoot1.0是仅支持Servlet Containers-&gt;Servlet API属于传统方式 SpringBoot2.0在支持1.0的特性上,同时添加了一个新特性就是WebFlux,可以使用Netty及Servlet3.1作为容器,基于 Reactive Streams 流处理。 当读到这里可能就有点懵了,Netty和Servlet3.1是一个什么鬼？ Netty是什么先不介绍，先说Servlet3.1在举例的时候，会提到Netty。 那么我们在分析Servlet3.0之前和3.0的区别？ 3.0之前Servlet 线程会一直阻塞，只有当业务处理完成并返回后时结束 Servlet线程。 3.0规范其中一个新特性是异步处理支持,即是在接收到请求之后，Servlet 线程可以将耗时的操作委派给另一个线程来完成，在不生成响应的情况下返回至容器 这样说可能大家还不太容易理解，我们来举一个例子 eg： 我们假设,设置tomcat最大线程为200,遇到200个非常耗时的请求 那么当有200个线程同时并发在处理,那么当来201个请求的时候,就已经处理不了，因为所有的线程都阻塞了。这是3.0之前的处理情况 而3.0之后异步处理是怎样处理呢？学过Netty通信框架的同学会比较容易理解一点，Servlet3.0类似于Netty一样就一个boss线程池和work线程池，boss线程只负责接收请求,work线程只负责处理逻辑。那么servlet3.0规范中，这200个线程只负责接收请求，然后每个线程将收到的请求，转发到work线程去处理。因为这200个线程只负责接收请求，并不负责处理逻辑，故不会被阻塞，而影响通信，就算处理非常耗时，也只是对work线程形成阻塞，所以当再来请求，同样可以处理,其主要应用场景是针对业务处理较耗时的情况可以减少服务器资源的占用，并且提高并发处理速度。 好了，当你已经读到这里，相信已经对SpringBoot1.0和SpringBoot2.0有一个比较清晰的认识了(当用过Netty通信框架类的童鞋一定是非常清晰的,如果还不清晰,就要补补课了)，所以我们不得不说SpringBoot2.0的性能一定是比1.0有所提升的。不过各有所爱，企业具体技术选型还要看业务需求，不能盲目追求新技术，毕竟新技术还不太稳定，没有被大规模的实践。好了，理论的知识就先讲到这里，开始实战编码吧。 项目实战通过上面的讲解，我们对其有了一个简单的认识，现在开始跟着我实战吧 ！SpringBoot2.0之WebFlux解析及实战请点击此处输入图片描述 在做项目实战的时候，我们要对下面两个问题有所了解！当这两个问题清楚后，实战就异常简单了 1. 我们知道SpringMVC是通过@Controller和@RequestMapping来定义路由的那么WebFlux是怎么定义路由的？ 我们看上图(下面的这两个区别要注意，项目中会遇到) 基于 Spring MVC 注解 @Controller 等 基于 Functional 函数式路由是 RouterFunctions 2. Flux和Mono分别是什么，在小编看来Flux和Mono都是一个数据的载体,不同的是 Flux 一种集合(0,n) Mono 一个实体包装(0,1) 为了代码的美观，小编在这里直接上图,因为头条不支持markdown，所以就直接看图吧启动时候添加测试数据 编写业务处理层 编写路由层 如果想获取源码的同学，请点击关注小编，并私信发送 SpringBoot2.0 获取项目地址，最后再次谢谢您的阅读，小编会每天分享一点小知识，及项目实战笔记，欢迎您的关注 ！","categories":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/categories/Spring-Boot2-0/"}],"tags":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/tags/Spring-Boot2-0/"}],"keywords":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://blog.springlearn.cn/categories/Spring-Boot2-0/"}]},{"title":"Rabbitmq业务流程包含容错排查","slug":"Rabbitmq业务流程包含容错排查","date":"2018-04-17T09:47:47.000Z","updated":"2018-04-23T06:32:33.465Z","comments":true,"path":"2018/04/17/Rabbitmq业务流程包含容错排查/","link":"","permalink":"https://blog.springlearn.cn/2018/04/17/Rabbitmq业务流程包含容错排查/","excerpt":"","text":"流程是这样的，订阅者，发送消息到test交换机，通过route key 分发到绑定的队列，这里涉及到交换机的类型，可以看我上一篇文章。如果没有匹配到这个routeKey就默认发送到AE交换机(fanout模式)，这个交换机要设置internal:true意为内部交换机 。AE交换机再把错误的消息，发送到其绑定的队列中，如果test交换机，发送消息被匹配到的队里中，而处理该队列的订阅者，拒绝了或者超时了处理，test交换机就将该消息发送到就死信交换机，然后到死信队列中 一、 进入死信队列(进入死信的三种方式) 1.消息被拒绝（basic.reject or basic.nack）并且requeue=false 2.消息TTL过期 3.队列达到最大长度 代码演示 123- channel.basicReject(message.getMessageProperties().getDeliveryTag(), true); // 拒绝消息 - true 发送给下一个消费者 - false 谁都不接受，从队列中删除 Rabbit设置 1.设置AE交换机 设置为内部交换机，模式为fanout当发送到正常交换机消息，没有被匹配到route key的消息对进到改交换机 12 FanoutExchange fanoutExchange=new FanoutExchange(\"alter\");fanoutExchange.setInternal(true);//设置为内部交换机，作为处理了非法的消息,无法匹配到route key的消息 - 为AE交换机绑定队列 `alter_message` 2.设置处理正常的交换机 test 绑定参数,设置没有匹配 route key 的消息发送到AE交换机 alternate-exchange 3.添加正常的队列 hello 测试处理正常逻辑 task_queue 模拟被拒绝的消息添加超时时间和死信交换机和rk x-dead-letter-exchange: dead_letter_exchange x-dead-letter-routing-key: task_queue.fail x-message-ttl: 600 4.设置死信交换机 dead_letter_exchange 另外创建死信队列 dead 绑定 route key task_queue.fail 代码实例 Python123456789101112131415161718192021222324252627282930import pika#认证，生产者credentials = pika.PlainCredentials('guest', 'guest')#链接rabbit服务器（localhost是本机，如果是其他服务器请修改为ip地址）connection = pika.BlockingConnection(pika.ConnectionParameters('127.0.0.1',5672,'/',credentials))#通过tcp协议获取一个连接channel = connection.channel()#声明一个对下列和贾环加#channel.queue_declare(queue='hello')#被hello接受了channel.basic_publish(exchange='test', routing_key='hello', body='Hello World!')#发送了一个没有匹配的消息，匹配到了alter_messagechannel.basic_publish(exchange='test', routing_key='hello12312', body='Hello World!')#模拟一条虽然能被匹配到，但是无法消费的消息，然后被发送到死信队列消息channel.basic_publish(exchange='test', routing_key='task_queue', body='Hello World!') 正常队列 没有匹配到的到 被拒绝或者超时进入私信队列的 使用代码去创建队列和交换机 Java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Beanpublic ConnectionFactory connectionFactory() throws Exception &#123; CachingConnectionFactory connectionFactory = new CachingConnectionFactory(\"127.0.0.1\", 5672); connectionFactory.setUsername(\"liuxin\"); connectionFactory.setPassword(\"930914lx\"); connectionFactory.setVirtualHost(\"az\"); connectionFactory.setPublisherConfirms(true); // 必须要设置回调 Channel channel = connectionFactory.createConnection().createChannel(false); //String exchange, String type, boolean durable, boolean autoDelete, Map&lt;String, Object&gt; arguments Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(\"internal\",true); //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments //设置AE交换机 channel.exchangeDeclare(\"alter\", \"fanout\", false, false, false, arguments); channel.queueDeclare(\"alter_message\", false, false, false, null); channel.queueBind(\"alter_message\", \"alter\", \"\"); //声明死信交换机并绑定 channel.exchangeDeclare(\"dead_letter_exchange\", \"direct\", false, false, null); channel.queueDeclare(\"dead\", false, false, false, null); channel.queueBind(\"dead\", \"dead_letter_exchange\", \"task_queue.fail\"); arguments = new HashMap&lt;&gt;(); arguments.put(\"alternate-exchange\", \"alter\");//指定AE交换机 channel.exchangeDeclare(\"test\", \"direct\", false, false, arguments); //声明接受正式的队列，不需要参数 channel.queueDeclare(\"hello\", false, false, false, null); channel.queueBind(\"hello\", \"test\", \"hello\"); arguments = new HashMap&lt;&gt;(); arguments.put(\"x-dead-letter-exchange\", \"dead_letter_exchange\"); arguments.put(\"x-dead-letter-routing-key\", \"task_queue.fail\"); arguments.put(\"x-message-ttl\",6000);//6s没有被处理，就死了 //设置测试死信队列的task_queue，推送该队列里面，被拒绝会到dead_letter_exchange，并最终到dead，routeKey，task_queue.fail 为并设置死信队列参数 channel.queueDeclare(\"task_queue\", false, false, false, arguments); channel.queueBind(\"task_queue\", \"test\", \"task_queue\"); return connectionFactory;&#125; /** * 接受消息的监听，这个监听客户交易流水的消息 * 针对消费者配置 * * @return */@Beanpublic SimpleMessageListenerContainer messageContainer1(ConnectionFactory connectionFactory, PayMentConsumeImpl transactionConsume) &#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); container.addQueueNames(\"hello\"); container.setExposeListenerChannel(true); container.setMaxConcurrentConsumers(8); container.setConcurrentConsumers(4); container.setAcknowledgeMode(AcknowledgeMode.MANUAL); //设置确认模式手工确认,当设置了此模式，必须返回ACK，否则会进入死信队列 container.setMessageListener(transactionConsume); container.setPrefetchCount(1000); return container;&#125;","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://blog.springlearn.cn/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}]},{"title":"Rabbitmq之事务模式及confirm确认模式","slug":"Rabbitmq之事务模式及confirm确认模式","date":"2018-04-17T09:47:06.000Z","updated":"2018-04-17T09:47:31.546Z","comments":true,"path":"2018/04/17/Rabbitmq之事务模式及confirm确认模式/","link":"","permalink":"https://blog.springlearn.cn/2018/04/17/Rabbitmq之事务模式及confirm确认模式/","excerpt":"","text":"事务模式 RabbitMQ中与事务机制有关的方法有三个，分别是Channel里面的txSelect()，txCommit()以及txRollback()，txSelect用于将当前Channel设置成是transaction模式，txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，如果txCommit提交成功了，则消息一定是到达broker了，如果在txCommit执行之前broker异常奔溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务了；然后重新发送 实际中使用事务会带来很大的性能损失，那么有没有更好的方法既能保证发布者知道消息已经正确到达，又能基本上不带来性能上的损失呢？从AMQP协议的层面看是没有更好的方法的，但是RabbitMQ提供了一个更好的方案，即将channel信道设置成confirm模式 1234567891011121314151617181920212223242526272829303132333435363738 public void run() &#123; Channel channel = null; try &#123; Connection connection = factory.newConnection(); channel = connection.createChannel(); //创建exchange channel.exchangeDeclare(exchangeName, \"direct\", true, false, null); //创建队列 channel.queueDeclare(queueName, true, false, false, null); //绑定exchange和queue channel.queueBind(queueName, exchangeName, bindingKey); //发送持久化消息 for(int i = 0;i &lt; count;i++) &#123; //第一个参数是exchangeName(默认情况下代理服务器端是存在一个\"\"名字的exchange的, //因此如果不创建exchange的话我们可以直接将该参数设置成\"\",如果创建了exchange的话 //我们需要将该参数设置成创建的exchange的名字),第二个参数是路由键 //开启事务 channel.txSelect(); channel.basicPublish(exchangeName, routingKey, true, MessageProperties.PERSISTENT_BASIC, (\"第\"+(i+1)+\"条消息\").getBytes()); if(i == 1) &#123; int result = 1/0; &#125; //提交事务 channel.txCommit(); &#125; &#125; catch (Exception e) &#123; try &#123; //回滚操作 channel.txRollback(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; e.printStackTrace(); &#125; &#125; &#125;","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://blog.springlearn.cn/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}]},{"title":"Rabbitmq用户权限配置","slug":"Rabbitmq用户权限配置","date":"2018-04-17T09:46:30.000Z","updated":"2018-04-17T09:46:53.379Z","comments":true,"path":"2018/04/17/Rabbitmq用户权限配置/","link":"","permalink":"https://blog.springlearn.cn/2018/04/17/Rabbitmq用户权限配置/","excerpt":"","text":"由于账号guest具有所有的操作权限，并且又是默认账号，出于安全因素的考虑，guest用户只能通过localhost登陆使用，并建议修改guest用户的密码以及新建其他账号管理使用rabbitmq(该功能是在3.3.0版本引入的)。 用户管理 用户管理包括增加用户，删除用户，查看用户列表，修改用户密码。 相应的命令 (1) 新增一个用户 rabbitmqctl add_user Username Password (2) 删除一个用户 rabbitmqctl delete_user Username (3) 修改用户的密码 rabbitmqctl change_password Username Newpassword (4) 查看当前用户列表 rabbitmqctl list_users 用户角色 按照个人理解，用户角色可分为五类，超级管理员, 监控者, 策略制定者, 普通管理者以及其他。 (1) 超级管理员(administrator) 可登陆管理控制台(启用management plugin的情况下)，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 (2) 监控者(monitoring) 可登陆管理控制台(启用management plugin的情况下)，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) (3) 策略制定者(policymaker) 可登陆管理控制台(启用management plugin的情况下), 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 与administrator的对比，administrator能看到这些内容 (4) 普通管理者(management) 仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对策略进行管理。 (5) 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 了解了这些后，就可以根据需要给不同的用户设置不同的角色，以便按需管理。 设置用户角色的命令为： rabbitmqctl set_user_tags User Tag User为用户名， Tag为角色名(对应于上面的administrator，monitoring，policymaker，management，或其他自定义名称)。 也可以给同一用户设置多个角色，例如 rabbitmqctl set_user_tags hncscwc monitoring policymaker 用户权限 用户权限指的是用户对exchange，queue的操作权限，包括配置权限，读写权限。配置权限会影响到exchange，queue的声明和删除。读写权限影响到从queue里取消息，向exchange发送消息以及queue和exchange的绑定(bind)操作。 例如： 将queue绑定到某exchange上，需要具有queue的可写权限，以及exchange的可读权限；向exchange发送消息需要具有exchange的可写权限；从queue里取数据需要具有queue的可读权限。详细请参考官方文档中”How permissions work”部分。 相关命令为： (1) 设置用户权限 rabbitmqctl set_permissions -p VHostPath User ConfP WriteP ReadP (2) 查看(指定hostpath)所有用户的权限信息 rabbitmqctl list_permissions [-p VHostPath] (3) 查看指定用户的权限信息 rabbitmqctl list_user_permissions User (4) 清除用户的权限信息 rabbitmqctl clear_permissions [-p VHostPath] User 123456789101112liuxin@MacBook-Pro  ~  rabbitmqctl add_user liuxin 950914lxCreating user \"liuxin\" ... liuxin@MacBook-Pro  ~  rabbitmqctl list_usersListing users ...liuxin []guest [administrator] liuxin@MacBook-Pro  ~  rabbitmqctl set_user_tags liuxin administratorSetting tags for user \"liuxin\" to [administrator] ... liuxin@MacBook-Pro  ~  rabbitmqctl list_usersListing users ...liuxin [administrator]guest [administrator] 2.删除用户rabbitmqctl delete_user username 3.修改密码rabbitmqctl change_password usernamenewpassword 4.列出所有用户rabbitmqctl list_users权限控制1.创建虚拟主机rabbitmqctl add_vhost vhostpath 2.删除虚拟主机rabbitmqctl delete_vhost vhostpath 3.列出所有虚拟主机rabbitmqctl list_vhosts 4.设置用户权限 rabbitmqctl set_permissions [-pvhostpath] username regexp regexp regexp 5.清除用户权限 rabbitmqctl clear_permissions [-pvhostpath] username 6.列出虚拟主机上的所有权限 rabbitmqctl list_permissions [-pvhostpath] 7.列出用户权限 rabbitmqctl list_user_permissionsusername 123456789101112131415161718192021222324#添加虚拟端口 liuxin@MacBook-Pro  ~  rabbitmqctl add_vhost azCreating vhost \"az\" ... liuxin@MacBook-Pro  ~  rabbitmqctl add_user liuxin liuxinCreating user \"liuxin\" ...Error: user_already_exists: liuxin#为用户设置权限策略 ✘ liuxin@MacBook-Pro  ~  rabbitmqctl set_user_tags User administratorSetting tags for user \"User\" to [administrator] ...Error: no_such_user: User ✘ liuxin@MacBook-Pro  ~  rabbitmqctl set_user_tags liuxin administratorSetting tags for user \"liuxin\" to [administrator] ... liuxin@MacBook-Pro  ~  rabbitmqctl set_permissions -p az User ConfP WriteP ReadPSetting permissions for user \"User\" in vhost \"az\" ...Error: no_such_user: User#为用户设置虚拟端口 ✘ liuxin@MacBook-Pro  ~  rabbitmqctl set_permissions -p az liuxin ConfP WriteP ReadPSetting permissions for user \"liuxin\" in vhost \"az\" ...#匹配所有的队列和交换机#若果是liuxin-.* ,就是指匹配liuxin-开头的交换机或者队列rabbitmqctl set_permissions -p az liuxin \".*\" \".*\" \".*\"然后重新登录","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://blog.springlearn.cn/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}]},{"title":"Rabbitmq之Topic和Direct、Fanout匹配解析","slug":"Rabbitmq之Topic和Direct、Fanout匹配解析","date":"2018-04-17T09:45:01.000Z","updated":"2018-04-23T06:32:29.654Z","comments":true,"path":"2018/04/17/Rabbitmq之Topic和Direct、Fanout匹配解析/","link":"","permalink":"https://blog.springlearn.cn/2018/04/17/Rabbitmq之Topic和Direct、Fanout匹配解析/","excerpt":"","text":"RabbitMQ详解 MQ常用概念快速入门使用 推荐查看 &lt;&lt;SpringBoot集成Rabbit使用TopicRabbit指定发送集合&gt;&gt; 目录 交换机(Exchange) 1.Direct Exchange 根据route key 直接找到队列 2.Topic Exchange 根据route key 匹配队列 3.Fanout Exchange 不处理route key 全网发送，所有绑定的队列都发送 交换机(Exchange)1. Direct Exchange Direct Exchange是RabbitMQ默认的交换机模式，也是最简单的模式，根据key全文匹配去寻找队列。 Q1 绑定了一个 binding key 名字为 orange； Q2 就有 2 个 binding key，名字为black和 green。 当消息中的 路由键 和 这个 binding key 对应上的时候，那么就知道了该消息去到哪一个队列中。 代码演示 A 12345678910111213@Beanpublic Queue helloQueue() &#123; return new Queue(\"retry_payment\");&#125;@BeanDirectExchange exchange() &#123; return new DirectExchange(\"retry_payment\");&#125;//绑定一个key，当消息匹配到就会放到这个队列中@BeanBinding bindingExchangeMessage(Queue queueMessage, DirectExchange exchange) &#123; return BindingBuilder.bind(queueMessage).to(exchange).with(\"retry_payment\");&#125; 12//向指定routingKey中推送，推送到指定队列rabbitTemplate.convertAndSend(exchange:\"retry_payment\", routingKey:\"retry_payment\", message:message); 代码演示 B 123456789101112Channel channel = connection.createChannel(); channel.exchangeDeclare(\"retry_payment\", \"direct\"); //声明一个交换机,direct 可以换位topic或者是fannoutchannel.queueDeclare(\"retry_payment\"); //声明一个队列channel.queueBind(\"queueName\", \"exchangeName\", \"routingKey\"); //绑定路由键 //需要绑定路由键,发送消息byte[] messageBodyBytes = \"hello world\".getBytes(); channel.basicPublish(\"exchangeName\", \"routingKey\", MessageProperties.PERSISTENT_TEXT_PLAIN, messageBodyBytes); 2.Topic Exchange Topic Exchange 转发消息主要是根据通配符。 在这种交换机下，队列和交换机的绑定会定义一种路由模式，那么，通配符就要在这种路由模式和路由键之间匹配后交换机才能转发消息。 在这种交换机模式下： 路由键必须是一串字符，用句号（.） 隔开，比如说 agreements.us，或者 agreements.eu.stockholm 等。 路由模式必须包含一个 星号（*），主要用于匹配路由键指定位置的一个单词，比如说，一个路由模式是这样子：agreements..b.*，那么就只能匹配路由键是这样子的：第一个单词是 agreements，第四个单词是 b。 井号（#）就表示相当于一个或者多个单词，例如一个匹配模式是agreements.eu.berlin.#，那么，以agreements.eu.berlin开头的路由键都是可以的。 具体代码发送的时候还是一样，第一个参数表示交换机，第二个参数表示routing key，第三个参数即消息。如下： 1rabbitTemplate.convertAndSend(\"testTopicExchange\",\"key1.a.c.key2\", \" this is RabbitMQ!\"); topic 和 direct 类似, 只是匹配上支持了”模式”, 在”点分”的 routing_key 形式中, 可以使用两个通配符: *表示一个词. #表示零个或多个词. 3.Fanout Exchange 不处理路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。 发送消息，只需要指定交换机，route key 可以为空 给消息设置属性值123设置请求头或者编码 MessageProperties messageProperties= message.getMessageProperties();","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://blog.springlearn.cn/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://blog.springlearn.cn/categories/数据处理/"}]},{"title":"Linux目录详细介绍","slug":"Linux目录详细介绍","date":"2018-04-16T17:14:47.000Z","updated":"2018-04-16T17:15:50.900Z","comments":true,"path":"2018/04/17/Linux目录详细介绍/","link":"","permalink":"https://blog.springlearn.cn/2018/04/17/Linux目录详细介绍/","excerpt":"","text":"平时开发中难免会经常操作服务器,而大部分服务器都是Linux,作为程序员我们经常会被linux服务器众多的目录所吓倒, 小编我之前也是这样,所以就收集了很多的linux常用的操作命令和linux目录的介绍，今天就把我笔记里面的linux目录这快的笔记，分享给大家，如果各位发现有问题，请及时指出哈,最后谢谢各位阅读，每天学习一点小知识。 文件目录 缩写 解释 /bin User Binaries 用户二进制文件 /sbin System Binaries 系统二进制文件 /etc Configuration Files 配置文件 /dev Device Files 设备文件 /proc Process Information 处理器信息 /var Variable Files 变量文件 /tmp Temporary Files 临时文件 /usr User Programs 用户程序 /home Home Directories 用户目录 /boot Boot Loader Files 系统引导文件 /lib System Libraries 系统依赖库 /opt Optional add-on Apps 附加应用 /mnt Mount Directory 临时挂载目录 /media Removable Devices 可移动设备文件 /srv Service Data 服务数据 / - 根 每个文件和目录都从根目录开始。 只有root用户拥有这个目录下的写权限。 请注意/ root是root用户的主目录，与/不一样。 / bin - 用户二进制文件 包含二进制可执行文件。 您需要在单用户模式下使用的常用linux命令位于此目录下。 系统的所有用户使用的命令位于此处。 例如：ps，ls，ping，grep，cp。 / sbin - 系统二进制文件 就像/ bin一样，/ sbin也包含二进制可执行文件。 但是，位于此目录下的linux命令通常由系统aministrator使用，用于系统维护目的。 例如：iptables，reboot，fdisk，ifconfig，swapon / etc - 配置文件 包含所有程序所需的配置文件。 这还包含用于启动/停止单个程序的启动和关闭shell脚本。 例如：/etc/resolv.conf，/etc/logrotate.conf / dev - 设备文件 包含设备文件。 这些包括终端设备，USB或连接到系统的任何设备。 例如：/ dev / tty1，/ dev / usbmon0 / proc - 进程信息 包含有关系统进程的信息。 这是一个包含运行进程信息的伪文件系统。例如：/ proc / {pid}目录包含有关该特定pid进程的信息。 这是一个具有关于系统资源的文本信息的虚拟文件系统。例如：/ proc / uptime / var - 变量文件 var代表可变文件。 预期会增长的文件内容可以在这个目录下找到。 这包括 - 系统日志文件（/ var / log）; 包和数据库文件（/ var / lib）; 电子邮件（/ var / mail）; 打印队列（/ var / spool）; 锁定文件（/ var / lock）; 重新启动时需要临时文件（/ var / tmp）; / tmp - 临时文件 包含由系统和用户创建的临时文件的目录。 系统重新启动时，此目录下的文件将被删除。 / usr - 用户程序 包含二进制文件，库，文档和二级程序的源代码。 / usr / bin包含用户程序的二进制文件。如果在/ bin下找不到用户二进制文件，请查看/ usr / bin。例如：at，awk，cc，less，scp / usr / sbin包含系统管理员的二进制文件。如果在/ sbin下找不到系统二进制文件，请查看/ usr / sbin。例如：atd，cron，sshd，useradd，userdel / usr / lib包含/ usr / bin和/ usr / sbin的库 / usr / local包含您从源代码安装的用户程序。例如，当您从源代码安装apache时，它将在/ usr / local / apache2下 / home - 主页目录 所有用户的主目录存储他们的个人文件。 例如：/ home / john，/ home / nikita / boot - 引导加载程序文件 包含启动加载器相关的文件。 内核initrd，vmlinux，grub文件位于/ boot下 例如：initrd.img-2.6.32-24-generic，vmlinuz-2.6.32-24-generic / lib - 系统库 包含支持位于/ bin和/ sbin下的二进制文件的库文件 库文件名是ld 或lib .so。* 例如：ld-2.11.1.so，libncurses.so.5.7 / opt - 可选的附加应用程序 opt代表可选。 包含来自各个供应商的附加应用程序。 附加应用程序应安装在/ opt /或/ opt /子目录下。 / mnt - 挂载目录 系统管理员可以挂载文件系统的临时挂载目录。 /媒体 - 可移动媒体设备 临时安装目录的可移动设备。 例如，用于CD-ROM的/ media / cdrom; /媒体/软盘软驱; / media / cdrecorder for CD writer / srv - 服务数据 srv代表服务。 包含服务器特定的服务相关数据。 例如，/ srv / cvs包含CVS相关数据。","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"Linux服务器","slug":"Linux服务器","permalink":"https://blog.springlearn.cn/tags/Linux服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"Java开发之深浅拷贝","slug":"Java开发之深浅拷贝","date":"2018-04-15T17:06:59.000Z","updated":"2018-04-23T06:32:30.446Z","comments":true,"path":"2018/04/16/Java开发之深浅拷贝/","link":"","permalink":"https://blog.springlearn.cn/2018/04/16/Java开发之深浅拷贝/","excerpt":"","text":"什么是深复制呢？什么是浅复制呢？作为一名合格的coder的你是否清楚呢？ 小编我最近看到一张图,可以说完美的以可视化的方式，解释清楚了这个问题，请看下图 浅复制浅复制,也就是说是引用复制,是将堆里面的zhang内存地址值0xx1的复制了,给了 p和p1 ,p和p1里面的name都是指向内存值0xx1的位置，这个地址的值是zhang, 此时当p改变了0xx1这个地址的zhang为liu,那么也会影响到p1,因为p1的name也是指向0xx1 深复制深复制,就是值复制,此时p和p1里面的name分别是0xx1和0xx2,这个时候当其中任何一个被修改,并不影响另外一个的值 如此一来是不是非常清晰了呢？ 如果感觉到有用，请点击关注，支持下小编，小编会持续为您分享更多干货内容.","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"深浅拷贝","slug":"深浅拷贝","permalink":"https://blog.springlearn.cn/tags/深浅拷贝/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"看懂一行GC日志","slug":"看懂一行GC日志","date":"2018-04-14T16:37:53.000Z","updated":"2018-04-23T06:32:40.752Z","comments":true,"path":"2018/04/15/看懂一行GC日志/","link":"","permalink":"https://blog.springlearn.cn/2018/04/15/看懂一行GC日志/","excerpt":"","text":"PSYoungGen 表示垃圾收集类型年轻代使用了Parallel Scavenge中括号里面数字: 5632K: 年轻代收集前大小 496K: 年轻代收集后大小 6144K: 年轻代总大小 5632K: 表示年轻代收集前,占堆大小 2931K: 表示年轻代收集后,占堆大小 19968K: 表示年轻代总大小 user: 用户耗时 sys: 系统耗时 (指的是cpu耗时,在多核的情况下,会大于real耗时) real: 真实耗时(包括,真实等待时间,eg: 磁盘io等待,线程等待)","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://blog.springlearn.cn/tags/GC/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"忘掉那些所谓的真理，请继续重复发明好轮子","slug":"忘掉那些所谓的真理，请继续重复发明好轮子","date":"2018-04-13T09:39:58.000Z","updated":"2018-04-14T04:40:54.809Z","comments":true,"path":"2018/04/13/忘掉那些所谓的真理，请继续重复发明好轮子/","link":"","permalink":"https://blog.springlearn.cn/2018/04/13/忘掉那些所谓的真理，请继续重复发明好轮子/","excerpt":"","text":"忘掉那些所谓的真理，请继续重复发明好轮子 作者｜George 编辑｜无明 “重复发明轮子”这句话原本用于比喻无谓的重复劳动，但这个比喻似乎也不那么恰当，因为在人类的历史长河中，轮子已经被重复发明了无数次。 制作轮子的材料在变化，从石头、木头到金属合金、碳纤维。轮子的组成和比例在变化，从厚实饱满、粗糙到精细镂空、带有数百个轮辐。轮胎和轮轴在变化，所以轮子也得重新设计。轮子滚动的路面和使用轮子的机械装置在变化，所以轮子也跟着变。即使是轮子的形状也难逃改变的命运，甚至出现了方形的轮子。 人们之所以如此不厌其烦地重复发明轮子，是因为轮子的用途一直在变。轮子的作用从最开始的节省劳动力到让飞机安全着陆，再到运载具有超级杀伤力的武器。现如今，轮子既可以小到人类感觉不到它们的存在，也可以大到载着巨型坦克在任意路面上行驶，既可以坚固到载着时速 500 公里的高速列车飞驰，也可以智能到让机器人在外星球上行走探险。 重复发明轮子与编程如果把“重复发明轮子”这个比喻放到计算机领域，也不见得太恰当，因为有很多广泛流传的软件本身就是被重复发明的“轮子”，不能说它们是无谓的重复劳动。 Linux 是对 Unix 的重新发明，MariaDB 是对 MySQL（MySQL 是对 PostgreSQL 和 Oracle 的重新发明，而 PostgreSQL 是对 Oracle 的重新发明）的重新发明，现代 C++ 是对老版 C++ 的重新发明，C++ 是对 C 语言（C 语言是对 B 语言的重新发明，而 B 语言是对 BCPL 的重新发明）的重新发明，Rust 是对 C++ 和 C 语言的重新发明，Clojure 是对 LISP 的重新发明，LISP 是对 IPL 和 Lambda Calculus 的重新发明，Haskell 是对 System FC 的重新发明，System FC 是对 System F 的重新发明，System F 是对 Labmda Calculus 的重新发明，DOT 是对 OO 的重新发明，Kotlin 是对 Java 的重新发明……我可以举无数个这样的例子。Vim 是对 Vi 的重新发明，Wayland 是对 Xorg 的重新发明，Ubuntu 是对 Debian 的重新发明。 很多优秀的软件并不只是简单地往已有代码库中添加新特性而已，而是通过不断迭代，创造出比以往更好的东西。GitHub 上很多流行的代码库都有数百个分支，而对于每一类软件工具，我们又有很多不同的选择。 人们经常说“不要重复发明轮子”，但他们忽略了这样的一个事实：大部分优秀的计算机软件实际上就是被重复发明的轮子，而并非是全新的东西。 这些变化是循序渐进的，我们基于已有的概念逐步迭代，慢慢修改它们，让它们变得更好。这是个无穷尽的过程，甚至我们忘记了自己是从哪里出发的，也不知道终点在哪里。我们唯一要付出的是时间，也许这就是计算机编程的神奇之处。在这里，没有所谓的资源短缺，也不管我们如何疯狂，我们总能创造出一些东西。 重复发明轮子不是罪，只是我们要知道在何时以及如何重复发明轮子。 当没有合适的轮子可用时在找不到可用的工具时，就自己开发一个，而不是基于已有的库开发一个不那么好用的“次品”。或许其他人也有同样的需求，那么就可以把你开发的工具分享给他们。自己开发可能需要更长时间，但会更有趣，而且开发出来的工具可能更好用。 当然，具体要怎么做，完全取决于你自己。你可以“勤快”得像某些 C 语言开发者一样，连 list 和 vector 都要自己实现，也可以“懒惰”得像某些 JavaScript 开发者一样，连最简单的判断奇数的函数都要从网上下载（比如日下载量超过十万的“is_odd”包，地址如下： https://www.npmjs.com/package/is-odd。 以 Julia 为例，Julia 是一门与 Python 非常像的编程语言，只是它更容易部署，不需要虚拟环境就可以运行，它运行更快，而且支持大规模的并发。Julia 就是一个被重复发明的轮子，因为从理论上说，它所能做的事情，Cython 也能做到，只要使用恰当的 C/C++ 库，修改一点代码，再加上一点耐心就可以。但 Julia 与生俱来就提供了便利性，为开发人员节省了大量时间，还让开发变得更有趣。或许，它会是 21 世纪最让人瞩目的编程语言之一。 当现有的轮子停滞不前时当很久没有人重复发明轮子，就可以考虑重新发明一个。出现这种情况，可能是因为现在的轮子已经够好了，没必要做出大的改进，但更有可能是因为大多数人希望有更好的轮子，只是他们没有时间去做。比如，有些问题虽然暂时得到了解决，但并不完美，因为当前的技术或框架无法提供更好的解决方案。这就留有余地，等待更好的时机出现。数年之后，或许技术发展到可以更好地解决这些问题。 以图像识别为例，图像识别属于经典的分类器问题。人们在分类器问题上不断努力改进，直到 2010 年，通过使用 Fisher Kernel 这类算法才让分类器得到了非常精确的结果。当然，这些成果还不足以用于检测癌症肿瘤或汽车自动驾驶，从精确度和训练时间方面来看，它们的水平还只是处在鹦鹉和大象之间。直到有人重新发明了并不太流行的卷积神经网络，还使用了现代的 GPU 来训练那些早在 90 年代就开发出来的图像识别模型。2012 年出现了著名的 AlexNet&amp;Co，而几年之后，图像识别技术发展到令人惊诧的地步，在中型数据集上训练出来的分类器甚至可以打败人类。 当轮子受到所有权限制时比如 Linux、GCC 和 Git，它们都是对已有版权软件系统的重新发明。在某些方面，它们比版权软件更好，而且它们是开源的。这意味着有更多的人在使用，有更多的人参与开发，这让它们能够以惊人的速度发展演化。 当你觉得这样做很有趣时对一个已经很完美的软件来一次重新发明，这样做也没什么错。你可能会失败，但你会从中学到很多。尽管别人已经解决了大部分问题，但你仍然能够从解决同样的问题中获得有趣的体验。数百万人想证明勾股定理或重新发明新的 LISP，虽说他们最终不过是在重复发明相似的轮子，但他们所做的并没有什么错，只要他们能够从中获得乐趣。而如果你重新发明的轮子哪怕只是比原先的好那么一点点，都算是在造福人类。 写在后面尽管放手去做吧，重复发明轮子不是罪。如果有人说重复发明轮子是无用功，那就告诉他们，你所做的其实是领域发展的基石。还记得那位在 31 岁就成为硅谷亿万富豪的马斯克吗，他对天体物理学和数学也只是懂点皮毛，却凭着数千万美金就让多国的航天局“颜面扫地”。要知道，这些航天局动不动就有数千亿的资金预算，还有数不清的博士和工程师为他们工作。 马斯克发明了一个更便宜、更强大、更安全、更简便、更快的“轮子”。或许，你也可以开发出一个更直观、更优雅的 JavaScript 库，或者一个更快的 Python 编译器，或者一个更便宜的计算单元，或者一个更好的 Spotify，或者一个更高效的查找表……谁知道呢，一切皆有可能！ 英文原文","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"Netty组件介绍","slug":"Netty组件介绍","date":"2018-04-11T09:39:03.000Z","updated":"2018-04-23T06:32:22.203Z","comments":true,"path":"2018/04/11/Netty组件介绍/","link":"","permalink":"https://blog.springlearn.cn/2018/04/11/Netty组件介绍/","excerpt":"","text":"在学习Netty之前，建议首先学习一个NIO，对关键的NIO组件有一个清醒认识 Buffer Selector 总览 Bootstrap or ServerBootstrap EventLoop EventLoopGroup ChannelPipeline Future or ChannelFuture ChannelInitializer ChannelHandler ByteToMessageDecoder MessageToByteEncoder ChannelPipline Channel ChannelHandlerContext ServerBootstrap一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。 option() 针对boss线程,用于连接 childOption() 针对work线程,用于处理数据 BootStrap123456789101112131415161718192021222324252627EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .remoteAddress(new InetSocketAddress(host, port)) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new SimpleChannelInboundHandler&lt;ByteBuf&gt;() &#123; //在连接的时候将数据发送给 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.channel().writeAndFlush(request); &#125; //接受信息 @Override protected void messageReceived(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf) throws Exception &#123; result = new byte[byteBuf.readableBytes()]; byteBuf.readBytes(result); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect().sync(); future.addListener(ChannelFutureListener.CLOSE).sync(); EventLoop一个EventLoop可以为多个Channel服务。 EventLoopGroup会包含多个EventLoop ChannelPipeline,ChannelHandler从PipeLine这个单词中可以看出来，是一个管道，处理连接。我们的业务代码handler一般都是放在这个管道中的 那么疑问来了，这个管道中的处理顺序是什么样呢？ 1234ChannelPipeline cp = channel.pipeline(); cp.addLast(\"encoder\", new HttpResponseEncoder());//1.负责输出cp.addLast(\"decoder\", new HttpRequestDecoder());//2.负责把客户端的数据解码cp.addLast(\"handler\", new HttpDispatchServerHandler());//3.自定义的业务处理器 按照我们执行顺序肯定不是根据添加顺序来处理的，应该是:2,把客户端的数据解码-&gt;3.对解码数据处理-&gt;1.加密返回给客户端。 那么 Netty 是怎么处理的呢？ ChannelHandler有两个子类ChannelInboundHandler和ChannelOutboundHandler，这两个类对应了两个数据流向，如果数据是从外部流入我们的应用程序，我们就看做是inbound，相反便是outbound ChannelInitializer顾名思义,这个就是channel初始化的容器，在这个里面设置处理器 123456789101112131415161718192021222324ServerBootstrap bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup();//负责绑定channel到selector workerGroup = new NioEventLoopGroup();//负责从selector中读取事件 bootstrap.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) .localAddress(6969).option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000) .childOption(ChannelOption.SO_KEEPALIVE, true).childHandler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel channel) throws Exception &#123; ChannelPipeline cp = channel.pipeline(); cp.addLast(\"idleStateHandler\", new IdleStateHandler(5, 5, 5, TimeUnit.SECONDS)); cp.addLast(\"decoder\", new HttpRequestDecoder()); cp.addLast(\"encoder\", new HttpResponseEncoder()); cp.addLast(\"aggregator\", new HttpObjectAggregator(1048576)); cp.addLast(\"deflater\", new HttpContentCompressor()); cp.addLast(\"handler\", new HttpDispatchServerHandler()); cp.addLast(\"out\", new AcceptorIdleStateTrigger()); &#125; &#125;).option(ChannelOption.SO_BACKLOG, 128); try &#123; channel = bootstrap.bind().awaitUninterruptibly().channel(); showBanner(6969); &#125; catch (Exception ie) &#123; throw new RuntimeException(ie); &#125; ###ChannelFuture Netty中的连接都可以是异步的，但是也可以设置为非异步 ChannelFutureChannel 每个操作都会返回一个 ChannelFutrue 因为是异步的，所以我们为每个异步的结果，添加一个监听,比如: 12345678# 当完成关闭动作，就执行监听器内容f = f.channel().closeFuture().await(); f.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; System.out.println(\"success complete!!ok!!\"); &#125; &#125;); 当然还有一种方法， 就是await()，此返回会等待上一个操作完成，在进行下一个操作。但是推荐使用第一种。 ByteToMessageDecoder解密器，可以自定义协议，通过集成改接口，重写 decode 方法把二进制，转换为我们系统可以处理的对象 12345678910111213141516171819202122import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.handler.codec.ByteToMessageDecoder;import java.util.List;/** * 把字节转换为int * 继承抽象类ByteToMessageDecoder实现解码器 */public class ByteToIntegerDecoder extends ByteToMessageDecoder &#123; @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; if (in.readableBytes() &gt;= 4) &#123; // Check if there are at least 4 bytes readable int n = in.readInt(); System.err.println(\"ByteToIntegerDecoder decode msg is \" + n); out.add(n); //Read integer from inbound ByteBuf, add to the List of decodec messages &#125; &#125;&#125; 编码器将我们系统处理完的信息，编码成，二进制，传出，给调用者 123456789101112import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.handler.codec.MessageToByteEncoder;public class IntegerToByteEncoder extends MessageToByteEncoder&lt;Integer&gt; &#123; @Override public void encode(ChannelHandlerContext ctx, Integer msg, ByteBuf out) throws Exception &#123; System.err.println(\"IntegerToByteEncoder encode msg is \" + msg); out.writeInt(msg); &#125;&#125; 解码后的数据怎么使用对于加密后的数据，可以直接强制转换为我们解码的对象 123456789public class BusinessHandler extends ChannelInboundHandlerAdapter &#123;trueprivate Logger logger = LoggerFactory.getLogger(BusinessHandler.class);true@Overridetruepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;true//因为我们的解码其中指定是Int类型，所以我们就可以，强制转换为Int，这里为了好理解，假如我们的解码器，中是转换了Person，那么在我们的处理器中就，可以强制换换为PersontruetruePerson person = (Person) msg;truetruelogger.info(\"BusinessHandler read msg from client :\" + person);true&#125; ChannelPipline 管道 管道中包括(ChannleInBoundHandler)入栈的和(ChannelOutBoundHandler)出栈的当连接发生,由ChannelPipline协调将消息给ChannelHandler处理 当一个ChannelHandler被绑定在了多个ChannelPipeline实例上,为了线程安全会报错.要使用@Sharable注解 Channel 消息的传载实体ChannelHandlerContext ChannelHandlerContext将Channel和ChannelHandler做一个关联因为一个Channel可能与多个ChannelHandler绑定 注意ChannelHandler与下一个ChannelHandler…的交互并不是他们直接产生的,而是有ChannelHandlerContext调用的 从中学习到一个编程技巧,就是当一个实体与多个处理器产生关系的时候,可以定义一个上下文,用来管理关系","categories":[{"name":"通信","slug":"通信","permalink":"https://blog.springlearn.cn/categories/通信/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://blog.springlearn.cn/tags/Netty/"}],"keywords":[{"name":"通信","slug":"通信","permalink":"https://blog.springlearn.cn/categories/通信/"}]},{"title":"SpringBoot整合Data-Jpa","slug":"SpringBoot整合Data-Jpa","date":"2018-01-12T08:00:43.000Z","updated":"2018-04-14T04:38:53.464Z","comments":true,"path":"2018/01/12/SpringBoot整合Data-Jpa/","link":"","permalink":"https://blog.springlearn.cn/2018/01/12/SpringBoot整合Data-Jpa/","excerpt":"","text":"最近开辟了一个新项目,因为初期考虑到可能会调整数据库的风险,所以orm,在设计之初就考虑为Spring Data Jpa, 以下是工程data层数据,整体是参照配置多数据源的方案,进行配置的 目录 因为阿里数据源Druid 整合数据源及其他事务配置 pom依赖 整合QueryDSl 整合事务123456789@EnableAutoConfiguration@SpringBootApplication@EnableTransactionManagement@ComponentScan(basePackages = &#123;\"com.inn.developer\"&#125;)public class CodeApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder().web(true).sources(CodeApplication.class).run(args); &#125;&#125; 创建DruidProperties配置123456@Data@AllArgsConstructor@NoArgsConstructor@ConfigurationProperties(prefix = \"druid\")public class DruidProperties &#123;... 数据库参数可以参考: 参数 默认值 解释 initialSize 3 初始化配置 minIdle 3 最小连接数 maxActive 15 最大连接数 maxWait 5000 获取连接超时时间（单位：ms） timeBetweenEvictionRunsMillis 90000 连接有效性检测时间(单位:ms) testOnBorrow false 获取连接检测 testOnReturn false 归还连接检测 minEvictableIdleTimeMillis 1800000 最大空闲时间(单位ms) testWhileIdle true 在获取连接后，确定是否要进行连接空间时间的检查 配置说明： 1：minEvictableIdleTimeMillis(最大空闲时间)：默认为30分钟，配置里面不进行设置。 2：testOnBorrow ,testOnReturn 默认为关闭，可以设置为不配置。 3：testWhileIdle(在获取连接后，确定是否要进行连接空闲时间的检查)。默认为true。配置里面不再进行设置。 流程说明： 1：在第一次调用connection的时候，才会进行 initialSize的初始化。 2：心跳检测时间线程，会休眠timeBetweenEvictionRunsMillis时间，然后只对(没有borrow的线程 减去 minIdle)的线程进行检查，如果空闲时间大于minEvictableIdleTimeMillis则进行close。 3：testWhileIdle必须设置为true，在获取到连接后，先检查testOnBorrow，然后再判定testwhileIdle，如果连接空闲时间大于timeBetweenEvictionRunsMillis，则会进行心跳检测。 4：不需要配置validationQuery，如果不配置的情况下会走ping命令，性能更高。 5：连接保存在数组里面，获取连接的时候，获取数组的最后一位。在imeBetweenEvictionRunsMillis时是从前往后进行检查连接的有效性。 配置数据源及hibernate适配数据源对象创建还是和之前一样,笔者不太喜欢xml的方式,所以还是采用配置类 DruidAutoJpaConfiguration 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Configuration@EnableConfigurationProperties(DruidProperties.class)//开启属性注入,通过@autowired注入@ConditionalOnClass(DruidDataSource.class)//表示对应的类在classpath目录下存在时，才会去解析对应的配置文件@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@EnableJpaRepositories(basePackages = \"com.inn.developer.model.dao\",transactionManagerRef = \"jpaTransactionManager\", entityManagerFactoryRef = \"localContainerEntityManagerFactoryBean\")public class DruidAutoJpaConfiguration &#123; @Autowired private DruidProperties properties; @Bean(name = \"druidDataSource\") @Primary public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); dataSource.setValidationQuery(\"select version()\"); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125; /** * hibernate 适配器,定制方言为mysql,并打印sql * * @return */ @Bean(name = \"hibernateJpaVendorAdapter\") @Primary public HibernateJpaVendorAdapter hibernateJpaVendorAdapter() &#123; HibernateJpaVendorAdapter hibernateJpaVendorAdapter = new HibernateJpaVendorAdapter(); hibernateJpaVendorAdapter.setShowSql(true); hibernateJpaVendorAdapter.setDatabasePlatform(\"org.hibernate.dialect.MySQL5Dialect\"); return hibernateJpaVendorAdapter; &#125; @Bean(name = \"localContainerEntityManagerFactoryBean\") @Primary public LocalContainerEntityManagerFactoryBean entityManagerFactoryBean(@Qualifier(\"druidDataSource\") DataSource dataSource ,@Qualifier(\"hibernateJpaVendorAdapter\") HibernateJpaVendorAdapter hibernateJpaVendorAdapter) &#123; LocalContainerEntityManagerFactoryBean local = new LocalContainerEntityManagerFactoryBean(); local.setDataSource(dataSource); local.setJpaVendorAdapter(hibernateJpaVendorAdapter); local.setPackagesToScan(\"com.inn.developer.model.domain\"); Properties properties = new Properties(); properties.put(\"hibernate.format_sql\", true); properties.put(\"hibernate.hbm2ddl.auto\", \"update\"); local.setJpaProperties(properties); return local; &#125; @Bean(name = \"jpaTransactionManager\") @Primary public JpaTransactionManager jpaTransactionManager(@Qualifier(\"localContainerEntityManagerFactoryBean\") LocalContainerEntityManagerFactoryBean entityManagerFactoryBean) &#123; JpaTransactionManager jpaTransactionManager = new JpaTransactionManager(); EntityManagerFactory object = entityManagerFactoryBean.getObject(); jpaTransactionManager.setEntityManagerFactory(object); return jpaTransactionManager; &#125; pom依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.11&lt;/version&gt; &lt;/dependency&gt; &lt;!--依赖Spring 4.3.6之core、context、aop、beans、tx、orm和spring data commons --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.11.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--hibernate 实现JPA的框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;5.2.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;5.2.11.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-annotations --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-annotations&lt;/artifactId&gt; &lt;version&gt;3.5.6-Final&lt;/version&gt; &lt;/dependency&gt; 整合QueryDSLpom依赖1234567891011&lt;!--引入query-dsl--&gt; &lt;dependency&gt; &lt;groupId&gt;com.querydsl&lt;/groupId&gt; &lt;artifactId&gt;querydsl-apt&lt;/artifactId&gt; &lt;version&gt;$&#123;querydsl.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.querydsl&lt;/groupId&gt; &lt;artifactId&gt;querydsl-jpa&lt;/artifactId&gt; &lt;version&gt;$&#123;querydsl.version&#125;&lt;/version&gt; &lt;/dependency&gt; 插件 123456789101112131415161718&lt;!--引入queryDsl:https://spring.io/blog/2011/04/26/advanced-spring-data-jpa-specifications-and-querydsl/--&gt; &lt;plugin&gt; &lt;groupId&gt;com.mysema.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-apt-plugin&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;process&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;target/generated-sources&lt;/outputDirectory&gt; &lt;processor&gt;com.querydsl.apt.jpa.JPAAnnotationProcessor&lt;/processor&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 使用方法,继承JpaSpecificationExecutor或QueryDslPredicateExecutor123@Repositorypublic interface IUserJpaDslReponsitory extends CrudRepository&lt;User, Long&gt;, JpaSpecificationExecutor&lt;User&gt;,QueryDslPredicateExecutor&lt;User&gt; &#123;&#125; 注意点:使用插件后,要mvn compile编译生成Q+entityName,不需要移动到项目","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"StringBoot集成Rabbit根据业务返回ACK","slug":"StringBoot集成Rabbit根据业务返回ACK","date":"2018-01-12T07:56:28.000Z","updated":"2018-04-14T04:40:17.647Z","comments":true,"path":"2018/01/12/StringBoot集成Rabbit根据业务返回ACK/","link":"","permalink":"https://blog.springlearn.cn/2018/01/12/StringBoot集成Rabbit根据业务返回ACK/","excerpt":"","text":"为了维护消息的有效性，当消费消息时候处理失败时候，不进行消费，需要我们根据业务区返回ACK，本项目我使用Redis和ack机制双重保险,保障消息一定能够正确的消费 首先,接着上部分内容，使用Topic,机制(不明白的,可以回顾上部分内容) 上部分内容，我们使用SpringBoot注解,去实现，但是控制权不完全账务，当进行大规模项目时候，不太建议使用 1234567891011@RabbitListener(queues = TopicRabbitConfig.USER_QUEUE) @RabbitHandler public void processUser(String message) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; logger.info(\"用户侧流水:&#123;&#125;\",message); &#125; &#125;); &#125; 根据源码分析，当然这里不分析源码，有兴趣的可以多失败几次就ok明白了 在配置类中定义监听器，监听这个序列（AcknowledgeMode.MANUAL是必须的哦） 1234567891011121314151617/** * 接受消息的监听，这个监听客户交易流水的消息 * 针对消费者配置 * @return */@Beanpublic SimpleMessageListenerContainer messageContainer1(ConnectionFactory connectionFactory, TransactionConsumeImpl transactionConsume) &#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); container.setQueues(queueMessage()); container.setExposeListenerChannel(true); container.setMaxConcurrentConsumers(1); container.setConcurrentConsumers(1); container.setAcknowledgeMode(AcknowledgeMode.MANUAL); //设置确认模式手工确认 container.setMessageListener(transactionConsume); return container;&#125; 这个 TransactionConsumeImpl 要继承ChannelAwareMessageListener，主要说的手动返回ACK就是channel。调用 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class TransactionConsumeImpl implements ChannelAwareMessageListener &#123; private static final Logger logger = LoggerFactory.getLogger(TransactionConsumeImpl.class); private static final Gson gson = new Gson(); @Autowired JedisShardInfo jedisShardInfo; @Autowired ExecutorService threadPool; @Autowired BoluomeFlowService boluomeFlowService; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; String boby = new String(message.getBody(), \"utf-8\");//转换消息，我们是使用json数据格式 threadPool.execute(new Runnable() &#123; //多线程处理 @Override public void run() &#123; Jedis jedis = jedisShardInfo.createResource(); jedis.sadd(TopicRabbitConfig.TRANSACTION_QUEUE, boby);//添加到key为当前消息类型的集合里面，防止丢失消息 BoluomeFlow flow = gson.fromJson(boby, BoluomeFlow.class); String json = gson.toJson(flow); if (boluomeFlowService.insert(flow)) &#123; //当添加成功时候返回成功 logger.info(\"客户交易流水添加1条记录:&#123;&#125;\", json); jedis.srem(TopicRabbitConfig.TRANSACTION_QUEUE, boby);//从当前消息类型集合中移除已经消费过的消息 try &#123; channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);//手工返回ACK，通知此消息已经争取消费 &#125; catch (IOException ie) &#123; logger.error(\"消费成功回调成功，io操作异常\"); &#125; &#125; else &#123; logger.info(\"客户交易流水添加失败记录:&#123;&#125;\", json); &#125; &#125; &#125;); &#125;&#125; 12channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); // 消息的标识，false只确认当前一个消息收到，true确认所有consumer获得的消息channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true); // ack返回false，并重新回到队列，api里面解释得很清楚 channel.basicReject(message.getMessageProperties().getDeliveryTag(), true); // 拒绝消息 true 发送给下一个消费者 false 谁都不接受，从队列中删除","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot整合Sentry监控项目日志","slug":"SpringBoot整合Sentry监控项目日志","date":"2018-01-12T07:47:41.000Z","updated":"2018-04-23T06:32:32.709Z","comments":true,"path":"2018/01/12/SpringBoot整合Sentry监控项目日志/","link":"","permalink":"https://blog.springlearn.cn/2018/01/12/SpringBoot整合Sentry监控项目日志/","excerpt":"","text":"Sentry Java版使用简介基本概念Sentry是什么Sentry 是一个开源的实时错误报告工具，支持 web 前后端、移动应用以及游戏，支持 Python、OC、Java、Go、Node、Django、RoR 等主流编程语言和框架 ，还提供了 GitHub、Slack、Trello 等常见开发工具的集成。 DSN（Data Source Name）Sentry 服务支持多用户、多团队、多应用管理，每个应用都对应一个 PROJECT_ID，以及用于身份认证的 PUBLIC_KEY 和 SECRET_KEY。由此组成一个这样的 DSN： ‘{PROTOCOL}://{PUBLIC_KEY}:{SECRET_KEY}@{HOST}/{PATH}{PROJECT_ID}’ PROTOCOL 通常会是 http 或者 https，HOST 为 Sentry 服务的主机名和端口，PATH 通常为空。为方便管理，每个应用生成一个 DSN，具体可咨询虎大师 或者 我。 使用 Sentry SDKSentry 的 SDK 通常在各语言的包管理器中成为 Raven，使用起来也非常简单。以 Java版本为例（使用SpringBoot框架）： 1.首先项目中pom文件安装 Raven 1234567 &lt;!--导入Sentry--&gt; &lt;dependency&gt; &lt;groupId&gt;com.getsentry.raven&lt;/groupId&gt; &lt;artifactId&gt;raven-logback&lt;/artifactId&gt; &lt;version&gt;8.0.2&lt;/version&gt;&lt;/dependency&gt; 2.在项目配置文件中建立logback.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;configuration&gt; &lt;!-- 彩色日志 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(--)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt;/&gt; &lt;appender name=\"Console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--&lt;pattern&gt; %d&#123;YYYY-MM-dd HH:mm:ss.SSS&#125; [%-5level] -&amp;#45;&amp;#45; %logger&#123;36&#125; [%thread] \\t- %msg%n%nopex&lt;/pattern&gt;--&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"Sentry\" class=\"com.getsentry.raven.logback.SentryAppender\"&gt; &lt;!--每个项目生成不通的key--&gt; &lt;dsn&gt;https://d73b23c481654b9ca0e4e8a9db310169:daaf5dc2edef462690791ef324316738@sentry.boluome.com/7&lt;/dsn&gt; &lt;!-- 设置拦截的最低级别为warn 警告--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;logger name=\"logback.SentryAppenderIT\" level=\"INFO\"&gt; &lt;appender-ref ref=\"Sentry\"/&gt; &lt;/logger&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"Console\"/&gt; &lt;appender-ref ref=\"Sentry\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 3.application.propertes中添加导入日志配置【主要要提前在pom文件中添加包含*.xml，否则会报错,not found file】 logging.config=classpath:logback.xml 4.接口层,正常使用logger等方法。Raven会自动把warn级别通过tcp发送到日志中心，并通知相关人员查看信息 12345@RequestMapping(value = \"/testlog\", method = RequestMethod.GET) public void testLog() &#123; logger.info(\"test接口\");//最低拦截级别为warn，所以info不会输出发送到日志中心 logger.error(\"error\"); //会显示在日志中心，并邮件通知相关联系人 &#125; 这样就可以使用 Raven 对象向 Sentry 服务器中提交日志信息了。 使用 Sentry web 服务主要是登录后台查看，后续有时间更新此部分文档。开通账号可找虎大师。 附录sentry 官方文档 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!-- scan=\"true\" 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 --&gt;&lt;!-- scanPeriod=\"30 seconds\" 设置每30秒自动扫描,若没有指定具体单位则以milliseconds为标准(单位:milliseconds, seconds, minutes or hours) --&gt;&lt;!-- debug=\"false\"当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;&lt;configuration scan=\"true\" scanPeriod=\"30 seconds\"&gt; &lt;!-- 上下文名称 --&gt; &lt;contextName&gt;test&lt;/contextName&gt; &lt;!-- 存放日志文件路径 --&gt; &lt;property name=\"Log_Home\" value=\"mylogs/test\"/&gt; &lt;!-- ch.qos.logback.core.ConsoleAppender 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 --&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- DEBUG级别 --&gt; &lt;appender name=\"FILE_DEBUG\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/debug/debug.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/debug/debug.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- INFO级别 --&gt; &lt;appender name=\"FILE_INFO\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/info/info.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/info/info.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- WARN级别 --&gt; &lt;appender name=\"FILE_WARN\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/warn/warn.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/warn/warn.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- ERROR级别 --&gt; &lt;appender name=\"FILE_ERROR\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/error/error.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/error/error.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 控制java下面包的打印,没设置等级,将继承上级root的等级 --&gt; &lt;logger name=\"rattlesnake.callback\"/&gt; &lt;!-- 当前日志总级别为TRACE、DEBUG、INFO、 WARN、ERROR、ALL和 OF --&gt; &lt;!-- the level of the root level is set to DEBUG by default. --&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"STDOUT\"/&gt; &lt;appender-ref ref=\"FILE_DEBUG\"/&gt; &lt;appender-ref ref=\"FILE_INFO\"/&gt; &lt;appender-ref ref=\"FILE_WARN\"/&gt; &lt;appender-ref ref=\"FILE_ERROR\"/&gt; &lt;/root&gt;&lt;/configuration&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot定义事件和监听器","slug":"SpringBoot定义事件和监听器","date":"2017-09-12T07:58:43.000Z","updated":"2018-04-14T04:38:47.621Z","comments":true,"path":"2017/09/12/SpringBoot定义事件和监听器/","link":"","permalink":"https://blog.springlearn.cn/2017/09/12/SpringBoot定义事件和监听器/","excerpt":"","text":"继承事件 ApplicationEvent 定义监听 ApplicationListener 继承事件 ApplicationEvent1234567891011121314151617181920212223public class EmailEvent extends ApplicationEvent &#123; /** * &lt;p&gt;Description：&lt;/p&gt; */ private static final long serialVersionUID = 1L; public String address; public String text; public EmailEvent(Object source) &#123; super(source); &#125; public EmailEvent(Object source, String address, String text) &#123; super(source); this.address = address; this.text = text; &#125; public void print()&#123; System.out.println(\"hello spring event!\"); &#125;&#125; 定义监听 ApplicationListener123456789101112131415@Componentpublic class EmailListener implements ApplicationListener&#123; public void onApplicationEvent(ApplicationEvent event) &#123; if(event instanceof EmailEvent)&#123; EmailEvent emailEvent = (EmailEvent)event; emailEvent.print(); System.out.println(\"the source is:\"+emailEvent.getSource()); System.out.println(\"the address is:\"+emailEvent.address); System.out.println(\"the email's context is:\"+emailEvent.text); &#125; &#125;&#125; 代码测试12345public static void main(String[] args) &#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(Application.class, args); EmailEvent emailEvent=new EmailEvent(\"hello\",\"lxchinesszz@163.com\",\"this is a email text\"); applicationContext.publishEvent(emailEvent); &#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot之自定义Servlet","slug":"SpringBoot之自定义Servlet","date":"2017-07-12T07:56:57.000Z","updated":"2018-04-14T04:38:14.337Z","comments":true,"path":"2017/07/12/SpringBoot之自定义Servlet/","link":"","permalink":"https://blog.springlearn.cn/2017/07/12/SpringBoot之自定义Servlet/","excerpt":"","text":"生产中我们有时候需要自定义servlet比如,对一些特定的资源路径进来的请求,做一些特殊处理，本文，介绍两种自定义的方法。 目录 @WebServlet 注解方式 注册ServletRegistrationBean 1.@WebServlet 注解方式使用该方式注意一点，就是要与 @ServletComponentScan 配合使用 123456789101112131415161718@WebServlet(urlPatterns = \"/api\", description = \"api进来的通过该servlet\")public class ApiGateWayServlet extends HttpServlet &#123; private ApplicationContext applicationContext; private ApiGateWayHandler apiGateWayHandler; @Override public void init() throws ServletException &#123; super.init(); applicationContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); apiGateWayHandler = applicationContext.getBean(ApiGateWayHandler.class); &#125; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; apiGateWayHandler.handle(req,resp); &#125;&#125; 在启动类，添加ServeltComponentScan 123456789@ServletComponentScan@SpringBootApplicationpublic class SpringBootSampleApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext configurableApplicationContext = SpringApplication.run(SpringBootSampleApplication.class, args); SpringContextUtils.setApplicationContext(configurableApplicationContext); &#125;&#125; 2. 注册ServletRegistrationBean1234567891011@SpringBootApplicationpublic class SpringBootSampleApplication &#123; @Bean public ServletRegistrationBean servletRegistrationBean() &#123; return new ServletRegistrationBean(new ApiGateWayServlet(), \"/*\"); &#125; public static void main(String[] args) &#123; ConfigurableApplicationContext configurableApplicationContext = SpringApplication.run(SpringBootSampleApplication.class, args); SpringContextUtils.setApplicationContext(configurableApplicationContext); &#125;&#125; 3.check是否配置成功122017-09-19 10:44:28.313 INFO 6761 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: 'apiGateWayServlet' to [/*]2017-09-19 10:44:28.315 INFO 6761 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot中JMX-RPC-JNDI关键字解释","slug":"SpringBoot中JMX-RPC-JNDI关键字解释","date":"2017-06-12T07:59:48.000Z","updated":"2018-04-23T06:32:42.586Z","comments":true,"path":"2017/06/12/SpringBoot中JMX-RPC-JNDI关键字解释/","link":"","permalink":"https://blog.springlearn.cn/2017/06/12/SpringBoot中JMX-RPC-JNDI关键字解释/","excerpt":"","text":"SpringBoot中JMX监控 SpringBoot自带调用JMX监控 rpc协议 rmi 远程方法调用 JMX Jndi rpc（Remote Procedure Call ProtocolRPC（Remote Procedure Call Protocol）——远程过程调用协议 rmi (Remote Method Invocation)RMI:远程方法调用(Remote Method Invocation)。能够让在某个java虚拟机上的对象像调用本地对象一样调用另一个java 虚拟机中的对象上的方法。 JMX （Java Management）JMX是“Java管理扩展的（Java Management Extensions）”的缩写，是一种类似J2EE的规范，这样就可以灵活的扩展系统的监控、管理功能。实时监控RPC服务器线程池任务的执行情况，具体JMX监控度量线程池关键指标代码 比如jndi (Java Naming and Directory Interface）JNDI(Java Naming and Directory Interface,Java命名和目录接口)是SUN公司提供的一种标准的Java命名系统接口，JNDI提供统一的客户端API，通过不同的访问提供者接口 通过目录，定义到接口比如，com.mysql.jdbc.Driver这个是一个约束性的 在JBoss的 D:/jboss420GA/docs/examples/jca 文件夹下面，有很多不同数据库引用的数据源定义模板 Get Ready在BookPub应用的pom文件中添加jolokia-core依赖 12345&lt;!-- JMX monitor --&gt;&lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot多数据源配置事务","slug":"SpringBoot多数据源配置事务","date":"2017-06-12T07:55:09.000Z","updated":"2018-04-14T04:38:44.226Z","comments":true,"path":"2017/06/12/SpringBoot多数据源配置事务/","link":"","permalink":"https://blog.springlearn.cn/2017/06/12/SpringBoot多数据源配置事务/","excerpt":"","text":"在多数据源中配置事务，其实对于SpringBoot来很简单，当然这个的前提是首先把多数据源都配好的情况下，如果不会多数据源配置，请看该系列 SpringBoot整合多数据源 首先在启动类配置 12345678@SpringBootApplication@EnableTransactionManagementpublic class AccountApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AccountApplication.class, args); &#125;&#125; 当配置了这个事务注解，会自动去加载我们的事务Bean。 配置多个事务 事务1 123456@Bean(name = \"accountTransactionManager\") @Primary public PlatformTransactionManager testTransactionManager(@Qualifier(\"accountDataSource\") DataSource dataSource) &#123; DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(dataSource); return dataSourceTransactionManager; &#125; 事务2 12345@Bean(name = \"otoSaaSTransactionManager\")public PlatformTransactionManager testTransactionManager(@Qualifier(\"otoSaaSDataSource\") DataSource dataSource) &#123; DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(dataSource); return dataSourceTransactionManager;&#125; 这个是时候就可以指定用哪个事务处理 使用事务1 12345@Override@Transactional(value = \"accountTransactionManager\",rollbackFor = Exception.class)public boolean insertAddMoney(String account, String quota) &#123; ...&#125; 使用事务2 12345@Override@Transactional(value = \"otoSaaSTransactionManager\",rollbackFor = Exception.class)public boolean insertAddMoney(String account, String quota) &#123; ...&#125; 那么此时就产生了一个疑惑，在多数据源和事务管理器中，如果不指定默认返回的事务呢？怎么配置默认事务处理器呢？很简。添加一个配置类，实现 TransactionManagementConfigurer重写 annotationDrivenTransactionManager 方法 返回默认返回的处理器，就OK 12345678910111213141516171819202122232425262728293031@Configuration // 开启注解事务管理，等同于xml配置文件中的 &lt;tx:annotation-driven /&gt;public class AccountApplication implements TransactionManagementConfigurer &#123; @Resource(name=\"txManager2\") private PlatformTransactionManager txManager2; // 创建事务管理器1 @Bean(name = \"txManager1\") public PlatformTransactionManager txManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; // 创建事务管理器2 @Bean(name = \"txManager2\") public PlatformTransactionManager txManager2(EntityManagerFactory factory) &#123; return new JpaTransactionManager(factory); &#125; // 实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器 @Override public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return txManager2; &#125; public static void main(String[] args) &#123; SpringApplication.run(AccountApplication.class, args); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot动态修改日志级别","slug":"SpringBoot动态修改日志级别","date":"2017-06-12T07:51:05.000Z","updated":"2018-04-23T06:32:29.914Z","comments":true,"path":"2017/06/12/SpringBoot动态修改日志级别/","link":"","permalink":"https://blog.springlearn.cn/2017/06/12/SpringBoot动态修改日志级别/","excerpt":"","text":"SpringBoot1.5新特性目录 安装依赖 测试显示日志级别 测试修改日志级别 1.在pom中添加依赖1234567891011121314151617&lt;parent&gt;true&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;true&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;true&lt;version&gt;1.5.1.RELEASE&lt;/version&gt;true&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt;true&lt;dependency&gt;truetrue&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;truetrue&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;true&lt;/dependency&gt;true&lt;dependency&gt;truetrue&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;truetrue&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;true&lt;/dependency&gt;&lt;/dependencies&gt; 2.开始测试https://localhost:8080/loggers 服务: 1s.b.a.e.m.MvcEndpointSecurityInterceptor : Full authentication is required to access actuator endpoints. Consider adding Spring Security or set 'management.security.enabled' to false. 需要手动设置management.security.enabled=false 继续测试 https://localhost:8080/loggers 服务返回: 12345678910111213141516171819&#123;levels: [\"OFF\",\"ERROR\",\"WARN\",\"INFO\",\"DEBUG\",\"TRACE\"],loggers: &#123;ROOT: &#123;configuredLevel: \"INFO\",effectiveLevel: \"INFO\"&#125;,elephant: &#123;configuredLevel: \"DEBUG\",effectiveLevel: \"DEBUG\"&#125;,... 3.修改日志级别POST请求https://localhost:8080/loggers/{elephant} {}中根据/loggers方法返回的目录级别添加 eg: 我要修改elephant.zybank.rest目录下级别 就使用下面请求方法 https://localhost:8080/loggers/elephant.zybank.rest 请求体中使用json 123&#123; \"configuredLevel\": \"DEBUG\"&#125; 登录服务器1234567curl -H \"Content-Type: application/json\" -X POST --data '&#123; \"configuredLevel\": \"DEBUG\"&#125;' https://localhost:8080/loggers/elephant.zybank.rest","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot使用Async实现异步调用","slug":"SpringBoot中使用-Async实现异步调用","date":"2017-06-12T07:27:59.000Z","updated":"2018-04-23T06:32:22.193Z","comments":true,"path":"2017/06/12/SpringBoot中使用-Async实现异步调用/","link":"","permalink":"https://blog.springlearn.cn/2017/06/12/SpringBoot中使用-Async实现异步调用/","excerpt":"","text":"本文引用地址大神程序员DD link 什么是“异步调用”？ “异步调用”对应的是“同步调用”，同步调用指程序按照定义顺序依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用指程序在顺序执行时，不等待异步调用的语句返回结果就执行后面的程序。 同步调用下面通过一个简单示例来直观的理解什么是同步调用： 定义Task类，创建三个处理函数分别模拟三个执行任务的操作，操作消耗时间随机取（10秒内） 12345678910111213141516171819202122232425@Componentpublic class Task &#123; public static Random random =new Random(); public void doTaskOne() throws Exception &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务一，耗时：\" + (end - start) + \"毫秒\"); &#125; public void doTaskTwo() throws Exception &#123; System.out.println(\"开始做任务二\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：\" + (end - start) + \"毫秒\"); &#125; public void doTaskThree() throws Exception &#123; System.out.println(\"开始做任务三\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务三，耗时：\" + (end - start) + \"毫秒\"); &#125;&#125; 在单元测试用例中，注入Task对象，并在测试用例中执行doTaskOne、doTaskTwo、doTaskThree三个函数 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = Application.class)public class ApplicationTests &#123;true@Autowiredtrueprivate Task task;true@Testtruepublic void test() throws Exception &#123;truetruetask.doTaskOne();truetruetask.doTaskTwo();truetruetask.doTaskThree();true&#125;&#125; 执行单元测试，可以看到类似如下输出： 123456开始做任务一完成任务一，耗时：4256毫秒开始做任务二完成任务二，耗时：4957毫秒开始做任务三完成任务三，耗时：7173毫秒 任务一、任务二、任务三顺序的执行完了，换言之doTaskOne、doTaskTwo、doTaskThree三个函数顺序的执行完成。 异步调用上述的同步调用虽然顺利的执行完了三个任务，但是可以看到执行时间比较长，若这三个任务本身之间不存在依赖关系，可以并发执行的话，同步调用在执行效率方面就比较差，可以考虑通过异步调用的方式来并发执行。 在Spring Boot中，我们只需要通过使用@Async注解就能简单的将原来的同步函数变为异步函数，Task类改在为如下模式： 123456789101112131415@Componentpublic class Task &#123; @Async public void doTaskOne() throws Exception &#123; // 同上内容，省略 &#125; @Async public void doTaskTwo() throws Exception &#123; // 同上内容，省略 &#125; @Async public void doTaskThree() throws Exception &#123; // 同上内容，省略 &#125;&#125; 为了让@Async注解能够生效，还需要在Spring Boot的主程序中配置@EnableAsync，如下所示： 1234567@SpringBootApplication@EnableAsyncpublic class Application &#123;truepublic static void main(String[] args) &#123;truetrueSpringApplication.run(Application.class, args);true&#125;&#125; 此时可以反复执行单元测试，您可能会遇到各种不同的结果，比如： 没有任何任务相关的输出 有部分任务相关的输出 乱序的任务相关的输出原因是目前doTaskOne、doTaskTwo、doTaskThree三个函数的时候已经是异步执行了。主程序在异步调用之后，主程序并不会理会这三个函数是否执行完成了，由于没有其他需要执行的内容，所以程序就自动结束了，导致了不完整或是没有输出任务相关内容的情况。 注： @Async所修饰的函数不要定义为static类型，这样异步调用不会生效异步回调为了让doTaskOne、doTaskTwo、doTaskThree能正常结束，假设我们需要统计一下三个任务并发执行共耗时多少，这就需要等到上述三个函数都完成调动之后记录时间，并计算结果。 那么我们如何判断上述三个异步调用是否已经执行完成呢？我们需要使用Future来返回异步调用的结果，就像如下方式改造doTaskOne函数： 123456789@Asyncpublic Future&lt;String&gt; doTaskOne() throws Exception &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务一，耗时：\" + (end - start) + \"毫秒\"); return new AsyncResult&lt;&gt;(\"任务一完成\");&#125; 按照如上方式改造一下其他两个异步函数之后，下面我们改造一下测试用例，让测试在等待完成三个异步调用之后来做一些其他事情。 12345678910111213141516@Testpublic void test() throws Exception &#123;truelong start = System.currentTimeMillis();trueFuture&lt;String&gt; task1 = task.doTaskOne();trueFuture&lt;String&gt; task2 = task.doTaskTwo();trueFuture&lt;String&gt; task3 = task.doTaskThree();truewhile(true) &#123;truetrueif(task1.isDone() &amp;&amp; task2.isDone() &amp;&amp; task3.isDone()) &#123;truetruetrue// 三个任务都调用完成，退出循环等待truetruetruebreak;truetrue&#125;truetrueThread.sleep(1000);true&#125;truelong end = System.currentTimeMillis();trueSystem.out.println(\"任务全部完成，总耗时：\" + (end - start) + \"毫秒\");&#125; 看看我们做了哪些改变： 在测试用例一开始记录开始时间 在调用三个异步函数的时候，返回Future类型的结果对象 在调用完三个异步函数之后，开启一个循环，根据返回的Future对象来判断三个异步函数是否都结束了。若都结束，就结束循环；若没有都结束，就等1秒后再判断。 跳出循环之后，根据结束时间 - 开始时间，计算出三个任务并发执行的总耗时。执行一下上述的单元测试，可以看到如下结果： 执行一下上述的单元测试，可以看到如下结果： 1234567开始做任务一开始做任务二开始做任务三完成任务三，耗时：37毫秒完成任务二，耗时：3661毫秒完成任务一，耗时：7149毫秒任务全部完成，总耗时：8025毫秒 异步调用的异常处理 在异步方法中，如果出现异常，对于调用者caller而言，是无法感知的。如果确实需要进行异常处理，则按照如下方法来进行处理： 1. 自定义实现AsyncTaskExecutor的任务执行器 在这里定义处理具体异常的逻辑和方式。 2. 配置由自定义的TaskExecutor替代内置的任务执行器 示例步骤1，自定义的TaskExecutor 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ExceptionHandlingAsyncTaskExecutor implements AsyncTaskExecutor &#123; private AsyncTaskExecutor executor; public ExceptionHandlingAsyncTaskExecutor(AsyncTaskExecutor executor) &#123; this.executor = executor; &#125; ////用独立的线程来包装，@Async其本质就是如此 public void execute(Runnable task) &#123; executor.execute(createWrappedRunnable(task)); &#125; public void execute(Runnable task, long startTimeout) &#123; /用独立的线程来包装，@Async其本质就是如此 executor.execute(createWrappedRunnable(task), startTimeout); &#125; public Future submit(Runnable task) &#123; return executor.submit(createWrappedRunnable(task)); //用独立的线程来包装，@Async其本质就是如此。 &#125; public Future submit(final Callable task) &#123; //用独立的线程来包装，@Async其本质就是如此。 return executor.submit(createCallable(task)); &#125; private Callable createCallable(final Callable task) &#123; return new Callable() &#123; public T call() throws Exception &#123; try &#123; return task.call(); &#125; catch (Exception ex) &#123; handle(ex); throw ex; &#125; &#125; &#125;; &#125; private Runnable createWrappedRunnable(final Runnable task) &#123; return new Runnable() &#123; public void run() &#123; try &#123; task.run(); &#125; catch (Exception ex) &#123; handle(ex); &#125; &#125; &#125;; &#125; private void handle(Exception ex) &#123; //具体的异常逻辑处理的地方 System.err.println(\"Error during @Async execution: \" + ex); &#125; &#125; 分析： 可以发现其是实现了AsyncTaskExecutor, 用独立的线程来执行具体的每个方法操作。在createCallable和createWrapperRunnable中，定义了异常的处理方式和机制。handle()就是未来我们需要关注的异常处理的地方。 @Async调用中的事务处理机制 在@Async标注的方法，同时也适用了@Transactional进行了标注；在其调用数据库操作之时，将无法产生事务管理的控制，原因就在于其是基于异步处理的操作。 那该如何给这些操作添加事务管理呢？可以将需要事务管理操作的方法放置到异步方法内部，在内部被调用的方法上添加@Transactional. 例如： 方法A，使用了@Async/@Transactional来标注，但是无法产生事务控制的目的。 方法B，使用了@Async来标注， B中调用了C、D，C/D分别使用@Transactional做了标注，则可实现事务控制的目的。","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot第三方配置绑定","slug":"SpringBoot第三方配置绑定","date":"2017-05-22T05:53:53.000Z","updated":"2018-04-14T04:39:23.398Z","comments":true,"path":"2017/05/22/SpringBoot第三方配置绑定/","link":"","permalink":"https://blog.springlearn.cn/2017/05/22/SpringBoot第三方配置绑定/","excerpt":"","text":"使用@ConfigurationProperties注释类，还可以在公共@Bean方法上使用它。当您想要将属性绑定到控件之外的第三方组件时，这可能特别有用。 首先要导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 要从属性配置bean Environment 1234567891011121314@ConfigurationProperties（prefix =“person.info”） public class OwnerProperties &#123; private String firstName;//会自动从配置中绑定 public String getFirstName（）&#123; return this .firstName; &#125;&#125; public void setFirstName（String firstName）&#123; this .firstName = firstName; &#125;&#125;&#125;&#125; application.properties1person.info.firstName=name Spring Boot使用一些放松的规则来绑定 eg: 例如context-path绑定到contextPath） 大写（例如PORT绑定到port ConfigurationProperties验证 为了验证嵌套属性的值，必须注释相关字段@Validated以触发其验证 - @NotNull - @NotEmpty","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot整合Rabbitmq设置消息请求头","slug":"SpringBoot整合Rabbitmq设置消息请求头","date":"2017-04-12T07:55:59.000Z","updated":"2018-04-14T04:39:07.933Z","comments":true,"path":"2017/04/12/SpringBoot整合Rabbitmq设置消息请求头/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot整合Rabbitmq设置消息请求头/","excerpt":"","text":"设置请求头，编码，唯一id 12345678Message message = MessageBuilder.withBody(context.getBytes()).setContentType(MessageProperties.CONTENT_TYPE_JSON).setContentEncoding(\"utf-8\").setMessageId(UUID.randomUUID()+\"\").build();this.rabbitTemplate.convertAndSend(\"retry_payment\", \"retry_payment\", message);","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot集成Rabbit使用TopicRabbit指定发送集合","slug":"SpringBoot集成Rabbit使用TopicRabbit指定发送集合","date":"2017-04-12T07:47:07.000Z","updated":"2018-04-14T04:39:56.756Z","comments":true,"path":"2017/04/12/SpringBoot集成Rabbit使用TopicRabbit指定发送集合/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot集成Rabbit使用TopicRabbit指定发送集合/","excerpt":"","text":"Rabbitmq中绑定exchange:flow routing-key:user bind-queue:flow_user 白话文就是,把user绑定到flow_user序列 发送方使用routing-key推送： 12//把routing-key发送给名为flow的exchenge，然后exchenge负责向绑定的这个Queue推送 amqpTemplate.convertAndSend(\"flow\",\"user\", context); Rabbit配置 添加exchange（这里类型type应该是topic,截图时候没有注意） 添加Queue 添加这个User 到exchange(注意routing-key) SpringBoot集成Rabbitmq 注册配置bean 12345678910111213141516171819202122@Configurablepublic class TopicRabbitConfig &#123; public final static String FLOW = \"flow\"; public final static String USER = \"user\"; public final static String USER_QUEUE = \"flow_user\"; @Bean public Queue queueMessages3() &#123; return new Queue(USER_QUEUE); &#125; @Bean TopicExchange exchange() &#123; return new TopicExchange(FLOW); &#125; @Bean Binding bindingExchangeMessages3(Queue queueMessages3, TopicExchange exchange) &#123; return BindingBuilder.bind(queueMessages3).to(exchange).with(FLOW); &#125;&#125; 发送方代码 123456789101112131415161718192021222324252627/** * @Package: pterosaur.account.service.impl * @Description: 模拟发送消息,测试使用 * @author: liuxin * @date: 17/4/19 下午3:17 */@Componentpublic class AccountSentImpl &#123; @Autowired private AmqpTemplate amqpTemplate; private ExecutorService threadPool = Executors.newFixedThreadPool(8); public void send() &#123; for (int i=0;i&lt;10;i++)&#123; String context = \"hello :\" + DateUtil.formatDatetime(System.currentTimeMillis())+\",当前线程:\"+Thread.currentThread().getName(); System.out.println(\"Sender : \" + context); threadPool.execute(new Runnable() &#123; @Override public void run() &#123; amqpTemplate.convertAndSend(TopicRabbitConfig.FLOW,TopicRabbitConfig.USER, context); &#125; &#125;); &#125; &#125;&#125; 接受方代码 1234567891011121314151617181920212223242526272829303132/** * @Package: pterosaur.account.service.impl * @Description: mq信息处理实现类 * @author: liuxin * @date: 17/4/19 下午2:55 */@Componentpublic class AccountReceiverImpl implements AccountReceiver &#123; private static final Logger logger = LoggerFactory.getLogger(AccountReceiverImpl.class); @Autowired ExecutorService threadPool; /** * 用户流水 * * @param message */ @RabbitListener(queues = TopicRabbitConfig.USER_QUEUE) @RabbitHandler public void processUser(String message) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; logger.info(\"用户侧流水:&#123;&#125;\",message); &#125; &#125;); &#125;&#125; 测试代码 123456789101112Sender : hello :2017-04-25 17:44:15,当前线程:mainSender : hello :2017-04-25 17:44:20,当前线程:main2017-04-25 17:44:25.754 INFO 67685 --- [pool-1-thread-1] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:20,当前线程:mainSender : hello :2017-04-25 17:44:25,当前线程:mainSender : hello :2017-04-25 17:44:30,当前线程:main2017-04-25 17:44:32.048 INFO 67685 --- [pool-1-thread-2] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:30,当前线程:mainSender : hello :2017-04-25 17:44:32,当前线程:mainSender : hello :2017-04-25 17:44:33,当前线程:main2017-04-25 17:44:35.556 INFO 67685 --- [pool-1-thread-3] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:33,当前线程:mainSender : hello :2017-04-25 17:44:35,当前线程:mainSender : hello :2017-04-25 17:44:37,当前线程:main2017-04-25 17:44:38.797 INFO 67685 --- [pool-1-thread-1] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:37,当前线程:main","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot整合多数据源xml方式","slug":"SpringBoot整合多数据源xml方式","date":"2017-04-12T07:46:23.000Z","updated":"2018-04-23T06:32:32.807Z","comments":true,"path":"2017/04/12/SpringBoot整合多数据源xml方式/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot整合多数据源xml方式/","excerpt":"","text":"项目中遇到需要连接多个数据库，本来使用SpringBoot默认配置连接是非常简单的，但是由于涉及多个数据库，不得不再自定义配置了，一次性整明白，下次就之间copy使用。 1.首先学习一个注解@ConfigurationProperties(prefix = &quot;druid&quot;) 默认注入，配置文件中druid开头的属性。eg: druid.url=jdbc:postgresql://139.198.x.x:1x020/account druid.url2=jdbc:postgresql://139.198.x.x:1x020/oto_saas druid.driver-class=org.postgresql.Driver druid.username=root druid.password=Boluome123 druid.initial-size=1 druid.min-idle=1 druid.max-active=20 druid.test-on-borrow=true druid.timeBetweenEvictionRunsMillis=9000 /** * * @author liuxin * @since 2017/4/19 */ @ConfigurationProperties(prefix = &quot;druid&quot;) public class DruidProperties { private String url; private String url2; private String username; private String password; private String driverClass; private int maxActive;//最大连接数 private int minIdle;//最小连接数 private int initialSize;//初始化数量和 private boolean testOnBorrow; private Long timeBetweenEvictionRunsMillis;//心跳 2.添加数据源配置A 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * @Package: pterosaur.account.config.druid * @Description: account 数据源1 * @author: liuxin * @date: 17/4/21 下午7:11 */@Configuration@EnableConfigurationProperties(DruidProperties.class) //开启属性注入,通过@autowired注入 //注入DruidProerties,就是根据第一个注解，创建的配置类@ConditionalOnClass(DruidDataSource.class)//判断这个类是否在classpath中存在@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@MapperScan(basePackages = \"pterosaur.account.mapper.account\", sqlSessionTemplateRef = \"accountSqlSessionTemplate\")//配置实体类包public class DruidAutoConfiguration1 &#123; @Autowired private DruidProperties properties; @Bean(name = \"accountDataSource\") @Primary //DataSource 是一个接口，因为是两个数据源，所以用Primary标记其中一个，防止报错 public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125; @Bean(name = \"accountSqlSessionFactory\") @Primary //同上 public SqlSessionFactory testSqlSessionFactory(@Qualifier(\"accountDataSource\") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\"classpath:mapper/account/*.xml\")); return bean.getObject(); //配置映射文件地址 &#125; @Bean(name = \"accountTransactionManager\") @Primary public DataSourceTransactionManager testTransactionManager(@Qualifier(\"accountDataSource\") DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = \"accountSqlSessionTemplate\") @Primary public SqlSessionTemplate testSqlSessionTemplate(@Qualifier(\"accountSqlSessionFactory\") SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 3.添加数据源配置B 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package pterosaur.account.config.druid;import com.alibaba.druid.pool.DruidDataSource;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.SqlSessionTemplate;import org.mybatis.spring.annotation.MapperScan;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.autoconfigure.AutoConfigureBefore;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import javax.sql.DataSource;import java.sql.SQLException;/** * @Package: pterosaur.account.config.druid * @Description: otosaas 数据源2 * @author: liuxin * @date: 17/4/21 下午7:11 */@Configuration@EnableConfigurationProperties(DruidProperties.class)@ConditionalOnClass(DruidDataSource.class)@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@MapperScan(basePackages = \"pterosaur.account.mapper.otosaas\", sqlSessionTemplateRef = \"otoSaaSSqlSessionTemplate\")public class DruidAutoConfiguration2 &#123; @Autowired private DruidProperties properties; @Bean(name = \"otoSaaSDataSource\") public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl2()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125; @Bean(name = \"otoSaaSSqlSessionFactory\") public SqlSessionFactory testSqlSessionFactory(@Qualifier(\"otoSaaSDataSource\") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\"classpath:mapper/otosaas/*.xml\")); return bean.getObject(); &#125; @Bean(name = \"accountTransactionManager\") public DataSourceTransactionManager testTransactionManager(@Qualifier(\"otoSaaSDataSource\") DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = \"otoSaaSSqlSessionTemplate\") public SqlSessionTemplate testSqlSessionTemplate(@Qualifier(\"otoSaaSSqlSessionFactory\") SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 参考地址代码地址 @ConditionalOnBean（仅仅在当前上下文中存在某个对象时，才会实例化一个Bean）@ConditionalOnClass（某个class位于类路径上，才会实例化一个Bean）@ConditionalOnExpression（当表达式为true的时候，才会实例化一个Bean）@ConditionalOnMissingBean（仅仅在当前上下文中不存在某个对象时，才会实例化一个Bean）@ConditionalOnMissingClass（某个class类路径上不存在的时候，才会实例化一个Bean）","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot自动生成Mapper映射","slug":"SpringBoot自动生成Mapper映射","date":"2017-04-12T07:45:42.000Z","updated":"2018-04-23T06:32:33.557Z","comments":true,"path":"2017/04/12/SpringBoot自动生成Mapper映射/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot自动生成Mapper映射/","excerpt":"","text":"项目结构 项目中如果使用关系型数据库，配合ibatis使用，只需要建立数据库表就ok，其他的就交给插件去做了。 1.pom文件中添加 12345678910111213&lt;build&gt;truetruetrue&lt;plugin&gt;truetruetruetrue&lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;truetruetruetrue&lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;truetruetruetrue&lt;version&gt;1.3.2&lt;/version&gt;truetruetruetrue&lt;configuration&gt;truetruetruetruetrue&lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt;truetruetruetruetrue&lt;overwrite&gt;true&lt;/overwrite&gt;truetruetruetruetrue&lt;verbose&gt;true&lt;/verbose&gt;truetruetruetrue&lt;/configuration&gt;truetruetrue&lt;/plugin&gt;truetrue&lt;/plugins&gt;true&lt;/build&gt; 2.在resources中添加配置文件 123resource|____generator| |____generatorConfig.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"https://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\" &gt;&lt;!--使用方法:mvn mybatis-generator:generate--&gt;&lt;generatorConfiguration&gt;&lt;!--读取配置文件地址--&gt; &lt;properties resource=\"application-test.properties\"/&gt; &lt;!--连接驱动要确定地址--&gt; &lt;classPathEntry location=\"/Users/liuxin/Desktop/postgresql-42.0.0.jre6 2.jar\"/&gt; &lt;context id=\"context1\" targetRuntime=\"MyBatis3Simple\" defaultModelType=\"flat\"&gt; &lt;property name=\"beginningDelimiter\" value=\"`\"/&gt; &lt;property name=\"endingDelimiter\" value=\"`\"/&gt; &lt;jdbcConnection driverClass=\"org.postgresql.Driver\" connectionURL=\"$&#123;druid.url&#125;\" userId=\"$&#123;druid.username&#125;\" password=\"$&#123;druid.password&#125;\"&gt; &lt;/jdbcConnection&gt; &lt;!--实体类也不用提前，建立，会自动根据数据库生成，对应数据库中字段--&gt; &lt;javaModelGenerator targetPackage=\"pterosaur.account.domain\" targetProject=\"src/main/java\"/&gt; &lt;!--映射的mapper.xml文件--&gt; &lt;sqlMapGenerator targetPackage=\"mapper\" targetProject=\"src/main/resources\"/&gt; &lt;!--映射文件，目标不必提前生成，会自动生成--&gt; &lt;javaClientGenerator targetPackage=\"pterosaur.account.mapper\" targetProject=\"src/main/java\" type=\"XMLMAPPER\"/&gt; &lt;!--输入表明，表名不用对应实体，会自动判断--&gt; &lt;table tableName=\"boluome_flow\" &gt;&lt;/table&gt; &lt;table tableName=\"boluome_refund_flow\"&gt;&lt;/table&gt; &lt;table tableName=\"boluome_refund_seettlement\"&gt;&lt;/table&gt; &lt;table tableName=\"boluome_settlement\"&gt;&lt;/table&gt; &lt;table tableName=\"boss_settlement_account\"&gt;&lt;/table&gt; &lt;table tableName=\"boss_transaction_flow\"&gt;&lt;/table&gt; &lt;table tableName=\"settlement_account\"&gt;&lt;/table&gt; &lt;table tableName=\"user_settlement_account\"&gt;&lt;/table&gt; &lt;table tableName=\"user_transcation_flow\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot整合druid数据源及添加Druid监控页面","slug":"SpringBoot整合druid数据源及添加Druid监控页面","date":"2017-04-12T07:45:13.000Z","updated":"2018-04-23T06:32:38.445Z","comments":true,"path":"2017/04/12/SpringBoot整合druid数据源及添加Druid监控页面/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot整合druid数据源及添加Druid监控页面/","excerpt":"","text":"不是不会，只是没见过，代码只是一种工具，首先要会用，应用中使用druid连接池，并添加监控 1.首先引入druid坐标 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.11&lt;/version&gt;&lt;/dependency&gt; 2.添加druid配置参数 参考: 数据库连接池优化配置(druid,dbcp,c3p0) 参数 默认值 解释 initialSize 3 初始化配置 minIdle 3 最小连接数 maxActive 15 最大连接数 maxWait 5000 获取连接超时时间（单位：ms） timeBetweenEvictionRunsMillis 90000 连接有效性检测时间(单位:ms) testOnBorrow false 获取连接检测 testOnReturn false 归还连接检测 minEvictableIdleTimeMillis 1800000 最大空闲时间(单位ms) testWhileIdle true 在获取连接后，确定是否要进行连接空间时间的检查 配置说明： 1：minEvictableIdleTimeMillis(最大空闲时间)：默认为30分钟，配置里面不进行设置。 2：testOnBorrow ,testOnReturn 默认为关闭，可以设置为不配置。 3：testWhileIdle(在获取连接后，确定是否要进行连接空闲时间的检查)。默认为true。配置里面不再进行设置。 流程说明： 1：在第一次调用connection的时候，才会进行 initialSize的初始化。 2：心跳检测时间线程，会休眠timeBetweenEvictionRunsMillis时间，然后只对(没有borrow的线程 减去 minIdle)的线程进行检查，如果空闲时间大于minEvictableIdleTimeMillis则进行close。 3：testWhileIdle必须设置为true，在获取到连接后，先检查testOnBorrow，然后再判定testwhileIdle，如果连接空闲时间大于timeBetweenEvictionRunsMillis，则会进行心跳检测。 4：不需要配置validationQuery，如果不配置的情况下会走ping命令，性能更高。 5：连接保存在数组里面，获取连接的时候，获取数组的最后一位。在imeBetweenEvictionRunsMillis时是从前往后进行检查连接的有效性。 在applicatioin.properties中添加配置 123456789druid.url=jdbc:postgresql://139.198.1.168:11020/accountdruid.driver-class=org.postgresql.Driverdruid.username=rootdruid.password=Boluome123druid.initial-size=1druid.min-idle=1druid.max-active=20druid.test-on-borrow=truedruid.timeBetweenEvictionRunsMillis=9000 3.定义配置类，启动读取druid开头的参数 driver-class有和driverClass是不一样的，所以要引入，参数容错坐标 123456&lt;!--配置命名容错处理--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 123456789101112@ConfigurationProperties(prefix = \"druid\")public class DruidProperties &#123; private String url; private String username; private String password; private String driverClass; private int maxActive;//最大连接数 private int minIdle;//最小连接数 private int initialSize;//初始化数量和 private boolean testOnBorrow; private Long timeBetweenEvictionRunsMillis;//心跳&#125; 4.注入 1234567891011121314151617181920212223242526272829303132333435@Configuration@EnableConfigurationProperties(DruidProperties.class)@ConditionalOnClass(DruidDataSource.class)@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@AutoConfigureBefore(DataSourceAutoConfiguration.class)public class DruidAutoConfiguration &#123; @Autowired private DruidProperties properties; @Bean public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125;&#125; 5.添加拦截器，拦截器druid性能监控 12345678910111213141516171819202122232425262728293031/** * @Package: pterosaur.account.config.druid * @Description: 监控数据库性能 * @author: liuxin * @date: 17/4/21 上午11:23 */@SuppressWarnings(\"serial\")@WebServlet(urlPatterns = \"/druid/*\", initParams=&#123; @WebInitParam(name=\"allow\",value=\"192.168.16.110,127.0.0.1\"),// IP白名单 (没有配置或者为空，则允许所有访问) @WebInitParam(name=\"deny\",value=\"192.168.16.111\"),// IP黑名单 (存在共同时，deny优先于allow) @WebInitParam(name=\"loginUsername\",value=\"test\"),// 用户名 @WebInitParam(name=\"loginPassword\",value=\"test\"),// 密码 @WebInitParam(name=\"resetEnable\",value=\"false\")// 禁用HTML页面上的“Reset All”功能 &#125;)public class DruidStatViewServlet extends StatViewServlet&#123;&#125;/** * @Package: pterosaur.account.config.filter * @Description: 拦截druid监控请求 * @author: liuxin * @date: 17/4/21 上午11:24 */@WebFilter(filterName=\"druidWebStatFilter\",urlPatterns=\"/*\", initParams=&#123; @WebInitParam(name=\"exclusions\",value=\"*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*\")// 忽略资源 &#125;)public class DruidStatFilter extends WebStatFilter&#123;&#125; 6.最终要一步，启动扫描Servlet 12345678910@SpringBootApplication@MapperScan(basePackages = \"pterosaur.account.mapper\")@EnableCaching@ServletComponentScan //这个public class AccountApplication &#123;truepublic static void main(String[] args) &#123;truetrueSpringApplication.run(AccountApplication.class, args);true&#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot序列化名称自定义","slug":"SpringBoot序列化名称自定义","date":"2017-04-12T07:40:35.000Z","updated":"2018-04-14T04:38:50.498Z","comments":true,"path":"2017/04/12/SpringBoot序列化名称自定义/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot序列化名称自定义/","excerpt":"","text":"SpringBoot 序列化名称自定义 有时候在使用序列化的时候，因为JavaBean中,已经定义好的名称，但是在接口返回的时候，可能需要不是这个，比如： 1234567891011public class User &#123; public final String name; public final String des; public final String age; public User(String name, String age) &#123; this.name = name; this.age = age; this.des = \"\"; &#125;&#125; 在生成json时候是这样的12345&#123; name: \"liuxin\", des: \"\", age: \"23\"&#125; 但是可能我需要的不是这样的json，比如需求是，name换成userName,des换成Password，那么如何在不改变JavaBean,不自定义序列化器的时候，就能实现呢，其实很简单，就是一个注解。撸代码一起看。 12345678@JsonProperty(\"userName\")public void setName(String name) &#123; this.name = name;&#125;@JsonProperty(\"Password\")public void setDes(String des) &#123; this.des = des;&#125; 12345&#123; age: \"23\", userName: \"SpringBoot\", Password: \"\"&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot项目中自定义注解的使用","slug":"SpringBoot项目中自定义注解的使用","date":"2017-04-12T07:39:34.000Z","updated":"2018-04-23T06:32:32.812Z","comments":true,"path":"2017/04/12/SpringBoot项目中自定义注解的使用/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot项目中自定义注解的使用/","excerpt":"","text":"Spring Boot项目中自定义注解的使用 项目中常常要打印日志，尤其是在做接口开发中，因为要面临着对前台数据的检查，在这种情况下，如果还是只使用普通的日志方式，如果配置为INFO 那么明显打印的东西是在太多了，在无奈的压迫下，小编我最终还是选择自己使用Aop的方式去记录日志信息，以下是实战演练。 作者：@lxchinesszz 本文为作者原创，转载请注明出处 1.定义注解接口123456789101112/** * @Package: com.example.config * @Description: 定制一个接口 * @author: liuxin * @date: 17/2/23 下午4:20 */@Documented@Retention(RUNTIME)@Target(METHOD)public @interface MyLog &#123; String value() default \"日志注解\";&#125; [^Documented 注解]: Documented 注解表明这个注解应该被 javadoc工具记录. 默认情况下,javadoc是不包括注解的. 但如果声明注解时指定了 @Documented,则它会被 javadoc 之类的工具处理, 所以注解类型信息也会被包括在生成的文档中[^Inherited 注解]: 它指明被注解的类会自动继承. 更具体地说,如果定义注解时使用了 @Inherited 标记,然后用定义的注解来标注另一个父类, 父类又有一个子类(subclass),则父类的所有属性将被继承到它的子类中[^Target注解]: 注解的作用目标 @Target(ElementType.TYPE) //接口、类、枚举、注解 @Target(ElementType.FIELD) //字段、枚举的常量 @Target(ElementType.METHOD) //方法 @Target(ElementType.PARAMETER) //方法参数 @Target(ElementType.CONSTRUCTOR) //构造函数 @Target(ElementType.LOCAL_VARIABLE)//局部变量 @Target(ElementType.ANNOTATION_TYPE)//注解 @Target(ElementType.PACKAGE) ///包 1.RetentionPolicy.SOURCE —— 这种类型的Annotations只在源代码级别保留,编译时就会被忽略 2.RetentionPolicy.CLASS —— 这种类型的Annotations编译时被保留,在class文件中存在,但JVM将会忽略 3.RetentionPolicy.RUNTIME —— 这种类型的Annotations将被JVM保留,所以他们能在运行时被JVM或其他使用反射机制的代码所读取和使用. 2.通过切面来实现注解1234567891011121314151617181920212223242526272829303132333435363738/** * @Package: com.example.config * @Description: MyLog的实现类 * @author: liuxin * @date: 17/2/23 下午4:22 */@Component@Aspectpublic class LogAspect &#123; @Pointcut(\"@annotation(com.example.config.MyLog)\") private void cut() &#123; &#125; /** * 定制一个环绕通知 * @param joinPoint */ @Around(\"cut()\") public void advice(ProceedingJoinPoint joinPoint)&#123; System.out.println(\"环绕通知之开始\"); try &#123; joinPoint.proceed(); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; System.out.println(\"环绕通知之结束\"); &#125; //当想获得注解里面的属性，可以直接注入改注解 @Before(\"cut()&amp;&amp;@annotation(myLog)\") public void record(JoinPoint joinPoint, MyLog myLog) &#123; System.out.println(myLog.value()); &#125; @After(\"recordLog()\") public void after() &#123; this.printLog(\"已经记录下操作日志@After 方法执行后\"); &#125;&#125; 因为Aspect作用在bean上，所以先用Component把这个类添加到容器中 @Pointcut 定义要拦截的注解 至于切面表达式，不需要你记住，小编我也记不住，用的时候查一下就可以了 切面表达式link @After @Before @Around 就不用解释了。 2.1 获得注解中的变量12345//当想获得注解里面的属性，可以直接注入改注解 @Before(\"cut()&amp;&amp;@annotation(myLog)\") public void record(JoinPoint joinPoint, MyLog myLog) &#123; System.out.println(myLog.value()); &#125; 2.2 注解中的ProceedingJoinPoint和JoinPoint说明 AspectJ使用org.aspectj.lang.JoinPoint接口表示目标类连接点对象，如果是环绕增强时，使用org.aspectj.lang.ProceedingJoinPoint表示连接点对象，该类是JoinPoint的子接口。任何一个增强方法都可以通过将第一个入参声明为JoinPoint访问到连接点上下文的信息。我们先来了解一下这两个接口的主要方法： 1.JoinPoint  java.lang.Object[] getArgs()：获取连接点方法运行时的入参列表；  Signature getSignature() ：获取连接点的方法签名对象；  java.lang.Object getTarget() ：获取连接点所在的目标对象；  java.lang.Object getThis() ：获取代理对象本身； 2.ProceedingJoinPoint ProceedingJoinPoint继承JoinPoint子接口，它新增了两个用于执行连接点方法的方法：  java.lang.Object proceed() throws java.lang.Throwable：通过反射执行目标对象的连接点处的方法；  java.lang.Object proceed(java.lang.Object[] args) throws java.lang.Throwable：通过反射执行目标对象连接点处的方法，不过使用新的入参替换原来的入参。 3.演示123456789101112@RestControllerpublic class JsonRest &#123; @MyLog @RequestMapping(\"/log\") public String getLog()&#123; return \"&lt;h1&gt;Hello World&lt;/h1&gt;\"; &#125;&#125;当访问的时候会打印出：[因为小编只用了环绕通知] 环绕通知之开始 环绕通知之结束","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot配置拦截器","slug":"SpringBoot配置拦截器","date":"2017-04-12T07:38:40.000Z","updated":"2018-04-14T04:39:47.451Z","comments":true,"path":"2017/04/12/SpringBoot配置拦截器/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot配置拦截器/","excerpt":"","text":"SpringBoot拦截器 最近项目中有一个需求，对来访的请求，进行计算，记录下业务处理时间。Spring Boot项目中使用拦截器，超级简单，再次说明一下用法。相信大家一看便懂。 1.继承 HandlerInterceptor 实现具体的处理逻辑1234567public interface HandlerInterceptor &#123; boolean preHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; //是否放行 void postHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3, ModelAndView var4) throws Exception; //处理结束 void afterCompletion(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4) throws Exception; //在处理结束后执行，最后执行的方法&#125; 以下是我的处理逻辑 12345678910111213141516171819202122232425262728293031/** * @Package: foxlife.base.interceptor * @Description: 处理时间拦截器，记录下，接口处理时间 * @author: liuxin * @date: 17/2/22 上午10:58 */@Componentpublic class ChanelInterceptor implements HandlerInterceptor &#123; private static Logger logger = LoggerFactory.getLogger(ChanelInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object o) throws Exception &#123; logger.info(\"============================拦截器启动==============================\"); request.setAttribute(\"starttime\",System.currentTimeMillis()); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object o, ModelAndView modelAndView) throws Exception &#123; logger.info(\"===========================执行处理完毕=============================\"); long starttime = (long) request.getAttribute(\"starttime\"); request.removeAttribute(\"starttime\"); long endtime = System.currentTimeMillis(); logger.info(\"============请求地址：\"+request.getRequestURI()+\"：处理时间：&#123;&#125;\",(endtime-starttime)+\"ms\"); &#125; @Override public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception &#123; logger.info(\"============================拦截器关闭==============================\"); &#125;&#125; 2.配置拦截器到应用中12345678910111213/** * @Package: foxlife.base.config * @Description: 配置拦截器 * @author: liuxin * @date: 17/2/22 上午11:04 */@Configurationpublic class MyInterceptorConfig extends WebMvcConfigurerAdapter&#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new ChanelInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; [^注解]: Spring Boot的项目建议使用配置类,addPathPatterns(&quot;/**&quot;) 3.演示12342017-02-23 15:40:43.619 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ============================拦截器启动==============================2017-02-23 15:40:43.621 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ===========================执行处理完毕=============================2017-02-23 15:40:43.621 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ============请求地址：/error：处理时间：2ms2017-02-23 15:40:43.621 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ============================拦截器关闭==============================","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot创建maven多模块项目","slug":"SpringBoot创建maven多模块项目","date":"2017-04-12T07:38:11.000Z","updated":"2018-04-23T06:32:31.035Z","comments":true,"path":"2017/04/12/SpringBoot创建maven多模块项目/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot创建maven多模块项目/","excerpt":"","text":"SpringBoot创建maven多模块项目(实战) 工作中一直都是一个人奋战一人一个项目，使用maven管理，看这个也挺好，但是总感觉没有充分发挥maven的功能，于是研究了一下这个，网上关于这个的文章很多，虽然不是很好，但我从中收获了很多，在这集百家所长，写一份实战记录，大家跟着我一块做吧！ 声明：构建多模块不是最难的，难点是如果把多模块打包成一个执行jar。SpringBoot官方推崇的是富jar，也就是jar文件启动项目，所以如果在这里打war包我不具体介绍，如果需要的朋友可以给我留言，我回复。 建议clone项目后，在看教程（有不足的地方希望大家保函，指出来，我们一起学习改进） github：https://github.com/lxchinesszz/multi-boluome.git 构建工程 1.首先第一步，在github上创建一个公共项目项目名 multi-boluome 2.把仓库同步到本地，使用Intellij idea打开，把普通项目转换为maven项目【右键：Add Frameworks Support】 3.删除除了pom文件之外的文件也就是src删除 4.然后新建File-&gt;New-&gt;module以此创建（此时会看到pom文件的变化） web dao domain service ==提示：一定要把外面的pom文件中的pom== 5.引入SpringBoot依赖 这个我在外面写的（这个根据个人） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111true外面的pom文件内容true&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"https://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"https://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;blm.server&lt;/groupId&gt; &lt;artifactId&gt;multi-boluome&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;web&lt;/module&gt; &lt;module&gt;service&lt;/module&gt; &lt;module&gt;dao&lt;/module&gt; &lt;module&gt;domain&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;kotlin.version&gt;1.0.6&lt;/kotlin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!--引入mock框架--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-core&lt;/artifactId&gt; &lt;version&gt;1.10.19&lt;/version&gt; &lt;/dependency&gt; &lt;!--rabbitmq--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- The plugin rewrites your manifest --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;configuration&gt;&lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;iflyer.IflyerApplication&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;!--可以生成不含依赖包的不可执行Jar包--&gt; &lt;!-- configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;/configuration&gt; --&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 6.开始编写domain层（这里我用mongodb数据库） 7.dao层我要用到数据库，所以在resource中添加配置信息 8.service层中我有用到freemarker的模板引擎，所以添加配置信息 9.web层编写启动类，main方法，main方法要放到目录外层，根据约定哦！ 10.每个层及都有自己的依赖 123456eg： dao层依赖domain service依赖dao和domain web层依赖service、dao、domain这个关系层次一定要告诉，编辑器，如下设置 右键：Open Module Settings打开 idea修改依赖 ![](https://raw.githubusercontent.com/lxchinesszz/multi-boluome/master/web/src/main/resources/static/image/6.web%E5%B1%82%E4%BE%9D%E8%B5%963%E4%B8%AA.png) 11.run一下启动类吧！工程可以启动了 如果出现一下错误Error:java: Annotation processing is not supported for module cycles. Please ensure that all modules说明依赖关系错了，继续看第10步骤吧。 打包发布jar文件 1.在启动类中修改pom文件(也就是web层的) 1234567891011&lt;build&gt; &lt;!-- 为jar包取名 --&gt; &lt;finalName&gt;blm-start&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2.在外层pom中构建插件 12345678910111213141516171819202122232425&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- The plugin rewrites your manifest --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;configuration&gt;&lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;com.Application&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;!--可以生成不含依赖包的不可执行Jar包--&gt; &lt;!-- configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;/configuration&gt; --&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 3.打包吧，mvn package —Dmaven.test.skip=true 跳过测试 12345678910111213141516[INFO] multi-boluome ...................................... SUCCESS [ 1.707 s][INFO] domain ............................................. SUCCESS [ 2.463 s][INFO] dao ................................................ SUCCESS [ 0.592 s][INFO] service ............................................ SUCCESS [ 0.606 s][INFO] web ................................................ SUCCESS [ 1.135 s][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 7.290 s[INFO] Finished at: 2017-01-20T17:05:14+08:00[INFO] Final Memory: 42M/265M[INFO] ------------------------------------------------------------------------KK-MINI:multi-boluome liuxin$ INFO] Building jar: /Users/liuxin/git/模仿项目/multi-boluome/web/target/blm-start.jar构建文件在这个目录下 very Good！开始飞吧==提醒：所有模块里面的父节点都是一样的哦，不然会报错 unknow.version== WARNING] ‘parent.relativePath’ of POM blm.server:domain:[unknown-version] 类似","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot使用日志接口UI","slug":"SpringBoot使用日志接口UI","date":"2017-04-12T07:37:39.000Z","updated":"2018-04-23T06:32:35.395Z","comments":true,"path":"2017/04/12/SpringBoot使用日志接口UI/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot使用日志接口UI/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 &lt;!--加入Swagger2的依赖实现api文档--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt;package butterfly.shjf;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Scope;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;/** * Created by liuxin on 16/12/9. * 创建api文档访问信息 * url：https://localhost:8080/swagger-ui.html */@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.shjf\")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(\"shjf-Api文档\") .description(\"blm付费通项目api文档\") .contact(\"liuxin\") .version(\"1.0\") .build(); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot配置异常处理类","slug":"SpringBoot配置异常处理类","date":"2017-04-12T07:36:39.000Z","updated":"2018-04-23T06:32:25.707Z","comments":true,"path":"2017/04/12/SpringBoot配置异常处理类/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot配置异常处理类/","excerpt":"","text":"首先定义一个异常12345public class MyException extends Exception &#123; public MyException(String message) &#123; super(message); &#125;&#125; 当在control类中throw此异常1234567@Controllerpublic class HelloController &#123; @RequestMapping(\"/json\") public String json() throws MyException &#123; throw new MyException(\"发生错误2\"); &#125;&#125; 处理该异常12345678910111213141516171819202122@ControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(value = MyException.class) //这个注解，接受异常 @ResponseBody //返回json public ErrorInfo&lt;String&gt; jsonErrorHandler(HttpServletRequest req, MyException e) throws Exception &#123; ErrorInfo&lt;String&gt; r = new ErrorInfo&lt;&gt;(); r.setMessage(e.getMessage()); r.setCode(ErrorInfo.ERROR); r.setData(\"Some Data\"); r.setUrl(req.getRequestURL().toString()); return r; &#125;&#125;应用启动：响应&#123; code: 100， data: \"Some Data\"， message: \"发生错误2\"， url: \"https://localhost:8080/json\"&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot配置多套环境","slug":"SpringBoot配置多套环境","date":"2017-04-12T07:36:12.000Z","updated":"2018-04-14T04:39:40.483Z","comments":true,"path":"2017/04/12/SpringBoot配置多套环境/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot配置多套环境/","excerpt":"","text":"生产中会经历，开发，测试，到上线。三个阶段 这个三个阶段，都有各自的配置文件，如果只是一个配置文件来回改 会很容易出现错误的，那么springboot提供了很简答的解决办法 使用spring.profiles.active=test 定义一个application.properties 里面写上 spring.profiles.active=test 默认启动test文件 定义application-dev.properties 定义application-test.properties 定义application-prod.properties 使用java -jar mm.jar –spring.profiles.active=dev 运行启动dev环境 可以看到启动的是dev122017-01-04 18:54:11.095 INFO 43026 --- [ restartedMain] dragonfly.DragonflyApplication : Starting DragonflyApplication on KK-MINI.local with PID 43026 (/Users/liuxin/git/oto_saas_mybosc_pay/target/classes started by liuxin in /Users/liuxin/git/oto_saas_mybosc_pay)2017-01-04 18:54:11.100 INFO 43026 --- [ restartedMain] dragonfly.DragonflyApplication : The following profiles are active: dev","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot在启动类配置端口号","slug":"SpringBoot在启动类配置端口号","date":"2017-04-12T07:35:40.000Z","updated":"2018-04-14T04:38:41.199Z","comments":true,"path":"2017/04/12/SpringBoot在启动类配置端口号/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot在启动类配置端口号/","excerpt":"","text":"1234567891011@SpringBootApplicationpublic class DragonflyApplication extends SpringBootServletInitializer implements EmbeddedServletContainerCustomizer &#123; public static void main(String[] args) &#123; SpringApplication.run(DragonflyApplication.class, args); &#125; @Override public void customize(ConfigurableEmbeddedServletContainer configurableEmbeddedServletContainer) &#123; configurableEmbeddedServletContainer.setPort(10087); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot联调日志输出","slug":"SpringBoot联调日志输出","date":"2017-04-12T07:35:12.000Z","updated":"2018-04-23T06:32:32.646Z","comments":true,"path":"2017/04/12/SpringBoot联调日志输出/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot联调日志输出/","excerpt":"","text":"在日常生产中，在和前端联合调试的时候，可能会遇到很多情况，在出现问题时候，很不容易找到，那么如果能够检测前后台的交互数据，应该就很容易快速解决问题，哪么可以使用Aop去解析。 首先因为aop包 123456 &lt;!--aop依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;version&gt;1.3.3.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置切面类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 @Aspect@Componentpublic class WebLogAspect &#123; private final static Logger logger = LoggerFactory.getLogger(WebLogAspect.class); private final static ThreadLocal&lt;Long&gt; prcoessTimeList = new ThreadLocal&lt;&gt;(); /** * rest包和子包里面的所有方法 */ @Pointcut(\"execution(public * safety.bankpay.rest..*.*(..))\") public void weblog() &#123; &#125; @Before(\"weblog()\") public void doBefore(JoinPoint joinpoint) throws Throwable &#123; // 接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); Enumeration&lt;String&gt; headerNames = request.getParameterNames(); Map map = MapFactory.newMap(); String parameterType = \"parameter\"; // 记录下请求内容 String method = request.getMethod(); logger.info(\"----------\" + joinpoint.getSignature().getName() + \"方法开始执行----------------------------\"); logger.info(\"&#123;&#125; : &#123;&#125; \", method.toUpperCase(), request.getRequestURL().toString()); logger.info(\"方法 : \" + joinpoint.getSignature().getDeclaringTypeName() + \".\" + joinpoint.getSignature().getName()); while (headerNames.hasMoreElements()) &#123; String key = headerNames.nextElement(); String parameter = request.getParameter(key); map.put(key, parameter); &#125; if (map.size() == 0) &#123; ServletInputStream inputStream = request.getInputStream(); String requestBoby = StreamUtils.convertStreamToString(inputStream); parameterType = \"body\"; logger.info(\"参数类型:&#123;&#125; 参数列表:&#123;&#125; \", parameterType, requestBoby); &#125; else &#123; logger.info(\"参数类型:&#123;&#125; 参数列表:&#123;&#125; \", parameterType, JsonUtils.toJson(map)); &#125; prcoessTimeList.set(System.currentTimeMillis()); &#125; @AfterReturning(returning = \"ret\", pointcut = \"weblog()\") public void doAfterReturning(Object ret) throws Throwable &#123; ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); Long startTime = prcoessTimeList.get(); Long endTime = System.currentTimeMillis(); prcoessTimeList.remove(); // 处理完请求，返回内容 logger.info(\"返回参数 : \" + ret); logger.info(\"-----------------方法执行完毕,耗时:&#123;&#125;ms-------------------\", (endTime - startTime)); &#125;&#125; 哦了。 123452017-04-12T15:28:39.736 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:50 ----------bindUser方法开始执行----------------------------]2017-04-12T15:28:39.736 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:51 GET : https://dev-zjrcu.otosaas.com/bindUser/v1 ]2017-04-12T15:28:39.737 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:52 方法 : safety.bankpay.rest.OtoRestController.bindUser]2017-04-12T15:28:39.737 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:64 参数类型:parameter 参数列表:&#123;\"openId\":\"a9a0565027b34312871f25901cfe9e04\",\"accessToken\":\"564d5b9514884d669cc6651893a4cf39\",\"clientId\":\"2018030700000000001005\",\"categoryCode\":\"dianying\"&#125; ]2017-04-12T15:28:40.617 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:78 -----------------方法执行完毕,耗时:880ms-------------------]","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot使用maven打包，加载不到配置文件原因","slug":"SpringBoot使用maven打包，加载不到配置文件原因","date":"2017-04-12T07:31:41.000Z","updated":"2018-04-14T04:38:22.478Z","comments":true,"path":"2017/04/12/SpringBoot使用maven打包，加载不到配置文件原因/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot使用maven打包，加载不到配置文件原因/","excerpt":"","text":"病情使用idea工具，测试没有问题，使用maven可以打包，但是运行，错误。 通过反编译分析，原因就是打包后的文件，没有包配置文件输入，解决办法 123456789101112131415&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt;&lt;/resources&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot自动扫描启动配置文件问题","slug":"SpringBoot自动扫描启动配置文件问题","date":"2017-04-12T07:29:57.000Z","updated":"2018-04-14T04:39:32.487Z","comments":true,"path":"2017/04/12/SpringBoot自动扫描启动配置文件问题/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot自动扫描启动配置文件问题/","excerpt":"","text":"1.SpringBoot会自动扫描resource下面的application配置文件， 2.然后是config下面当，config有多个配置文件时候，SpringBoot会找不到application文件， 3.当使用 12@Configuration@ConfigurationProperties(locations = \"classpath:config/callbackurl.properties\")","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)","slug":"Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)","date":"2017-04-12T07:29:14.000Z","updated":"2018-04-14T04:43:09.648Z","comments":true,"path":"2017/04/12/Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)/","excerpt":"","text":"==前文==，Quartz中迭代后，变化很大，让我走了很多的误区，这里简单解释一点，希望大家可以跳过误区，建议大家从下往上读（希望对大家有点帮助），我是一只爱分享的小菜鸟 JobDetail和Trigger和Schedule都是接口，统统不能new 1.如果只是执行一些自定义的类，其实使用SpringBoot的自带的任务就可以完成，简单的不能想象。这个可以看-&gt;我的另一篇SpringBoot原生定时任务解析。2.如果要是要动态的执行一些有Spring管理的bean，可能要稍微费点功夫了，网上有很多的教程，那部分都是xml形式配置的，本人菜鸟一枚（十分迷惑），十分不喜欢xml配置，看着眼花，当程序读取的时候还是要解析java对象来执行的，那么为何不直接配置成配置类呢？这个问题先方下，以后会详细解释如何使用Spring Boot配置类。开始代码展示1234567891011121314151617181920212223242526 //job是一个接口，当定时任务执行的时候，就要运行这个方法，那么可以推测 JobExecutionContext这个对象中包含了我们可能使用的关于这个定时任务的所有细节，请看代码public interface Job &#123; void execute(JobExecutionContext var1) throws JobExecutionException;&#125;/** * Created by liuxin on 16/12/21. * 方案1：反射执行类和执行方法（不解析，没有用，刚开始走了误区，自己反射方法执行，大家尽量不要用） * 方案2：读取bean（这个才是重点） */public class ScheduledTasks implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(\"------进入定时方法区域-------\"); try &#123; ConfigurableApplicationContext cac = (ConfigurableApplicationContext) jobExecutionContext.getJobDetail().getJobDataMap().get(\"ConfigurableApplicationContext\"); HelloService helloService = (HelloService) cac.getBean(\"helloService\"); helloService.hh(); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 上面的代码中看到这个JobExecutionContext可以得到JobDetail，而这个JobDetail对象是我们自己创建的用来详细介绍我们定时任务的，也就是我们要执行的方法的详细在这个里存放，123jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);这个是我们在main方法中测试时候，提前放进去，的在执行execute方法时候，取到的上下文对象，用来得到bean的这么说是不是很清楚了？接着看代码 测试的bean对象1234567@Servicepublic class HelloService &#123; static int i=0; public void hh()&#123; System.out.println(++i); &#125;&#125; 为了证明这个bean在上下文中，我们打印一下，上下文中的所有的bean 123456789101112131415161718192021222324252627282930313233@SpringBootApplicationpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean 可以看到helloService在倒数3 &#125;&#125; . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.2.RELEASE)org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorytestQuartzApplicationorg.springframework.boot.autoconfigure.internalCachingMetadataReaderFactoryorg.springframework.context.annotation.ConfigurationClassPostProcessor.importAwareProcessororg.springframework.context.annotation.ConfigurationClassPostProcessor.enhancedConfigurationProcessorhelloServiceredisConfigjedis 那么现在的任务就是把，这个上下文对象防盗JobDetil的map中，2.2.1的区别来了，不在是一起new的jobDetail了,由JobBuilder和TriggerBuilder构建1234567891011121314151617@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(\"testkey\", \"testvalue\").withDescription(\"一个测试的类\").build(); jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);//重点是这句话 Trigger trigger = TriggerBuilder.newTrigger().startNow().withSchedule(CronScheduleBuilder.cronSchedule(\"0/1 * * * * ?\")).startNow().build(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring整合Quartz","slug":"Spring整合Quartz","permalink":"https://blog.springlearn.cn/tags/Spring整合Quartz/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"Spring整合Quartz2.1.1","slug":"Spring整合Quartz2-1-1","date":"2017-04-12T07:29:14.000Z","updated":"2018-04-14T04:40:11.165Z","comments":true,"path":"2017/04/12/Spring整合Quartz2-1-1/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/Spring整合Quartz2-1-1/","excerpt":"","text":"==前文==，Quartz中迭代后，变化很大，让我走了很多的误区，这里简单解释一点，希望大家可以跳过误区，建议大家从下往上读（希望对大家有点帮助），我是一只爱分享的小菜鸟 JobDetail和Trigger和Schedule都是接口，统统不能new 1.如果只是执行一些自定义的类，其实使用SpringBoot的自带的任务就可以完成，简单的不能想象。这个可以看-&gt;我的另一篇SpringBoot原生定时任务解析。2.如果要是要动态的执行一些有Spring管理的bean，可能要稍微费点功夫了，网上有很多的教程，那部分都是xml形式配置的，本人菜鸟一枚（十分迷惑），十分不喜欢xml配置，看着眼花，当程序读取的时候还是要解析java对象来执行的，那么为何不直接配置成配置类呢？这个问题先方下，以后会详细解释如何使用Spring Boot配置类。开始代码展示1234567891011121314151617181920212223242526 //job是一个接口，当定时任务执行的时候，就要运行这个方法，那么可以推测 JobExecutionContext这个对象中包含了我们可能使用的关于这个定时任务的所有细节，请看代码 public interface Job &#123; void execute(JobExecutionContext var1) throws JobExecutionException;&#125;/** * Created by liuxin on 16/12/21. * 方案1：反射执行类和执行方法（不解析，没有用，刚开始走了误区，自己反射方法执行，大家尽量不要用） * 方案2：读取bean（这个才是重点） */public class ScheduledTasks implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(\"------进入定时方法区域-------\"); try &#123; ConfigurableApplicationContext cac = (ConfigurableApplicationContext) jobExecutionContext.getJobDetail().getJobDataMap().get(\"ConfigurableApplicationContext\"); HelloService helloService = (HelloService) cac.getBean(\"helloService\"); helloService.hh(); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 上面的代码中看到这个JobExecutionContext可以得到JobDetail，而这个JobDetail对象是我们自己创建的用来详细介绍我们定时任务的，也就是我们要执行的方法的详细在这个里存放，123jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);这个是我们在main方法中测试时候，提前放进去，的在执行execute方法时候，取到的上下文对象，用来得到bean的这么说是不是很清楚了？接着看代码 测试的bean对象1234567@Servicepublic class HelloService &#123; static int i=0; public void hh()&#123; System.out.println(++i); &#125;&#125; 为了证明这个bean在上下文中，我们打印一下，上下文中的所有的bean 123456789101112131415161718192021222324252627282930313233@SpringBootApplicationpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean 可以看到helloService在倒数3 &#125;&#125; . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.2.RELEASE)org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorytestQuartzApplicationorg.springframework.boot.autoconfigure.internalCachingMetadataReaderFactoryorg.springframework.context.annotation.ConfigurationClassPostProcessor.importAwareProcessororg.springframework.context.annotation.ConfigurationClassPostProcessor.enhancedConfigurationProcessorhelloServiceredisConfigjedis 那么现在的任务就是把，这个上下文对象防盗JobDetil的map中，2.2.1的区别来了，不在是一起new的jobDetail了,由JobBuilder和TriggerBuilder构建1234567891011121314151617@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(\"testkey\", \"testvalue\").withDescription(\"一个测试的类\").build(); jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);//重点是这句话 Trigger trigger = TriggerBuilder.newTrigger().startNow().withSchedule(CronScheduleBuilder.cronSchedule(\"0/1 * * * * ?\")).startNow().build(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"Spring Cloud初步理解","slug":"Spring Cloud初步理解","date":"2017-04-12T07:29:14.000Z","updated":"2018-04-23T06:32:28.474Z","comments":true,"path":"2017/04/12/Spring Cloud初步理解/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/Spring Cloud初步理解/","excerpt":"","text":"Ribbon实现负载均衡 关键字：Feign、Ribbon、eureka、负载均衡 大致：步骤，启动eureka服务(注册中心) 使用Spring Cloud Netflix中的Eureka实现服务注册中心，以及服务注册发现； 将service(port:2222,port:2223)注册到eureka服务中 使用Ribbon代理去访问service 会实现负载均衡 服务间通过Ribbon或Feign实现服务的消费以及均衡负载 通过Spring Cloud Config实现应用多环境的外部化配置及版本管理 使得服务集群更为健壮，使用Hystrix熔断机制避免微服务架构中个别服务出现异常引起的故障蔓延 引入断路器 Rabbion中引入Hystrix 123456789101112@Servicepublic class ComputeService &#123; @Autowired RestTemplate restTemplate; @HystrixCommand(fallbackMethod = \"addServiceFallback\") public String addService() &#123; return restTemplate.getForEntity(\"https://COMPUTE-SERVICE/add?a=10&amp;b=20\", String.class).getBody(); &#125; public String addServiceFallback() &#123; return \"error\"; &#125;&#125;","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.springlearn.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.springlearn.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.springlearn.cn/categories/Spring-Cloud/"}]},{"title":"SpringBoot整合Quartz-动态读取任务执行","slug":"SpringBoot整合Quartz-动态读取任务执行","date":"2017-04-12T07:28:33.000Z","updated":"2018-04-14T04:39:00.990Z","comments":true,"path":"2017/04/12/SpringBoot整合Quartz-动态读取任务执行/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot整合Quartz-动态读取任务执行/","excerpt":"","text":"本次使用redis作为数据库，存储定时任务类redis的连接不是重点，重点是解析序列化处理过的任务数组和Quartz如何添加任务 1. JobEntity 用来保存执行任务类123456789101112131415public class JobEntity implements Serializable &#123; //cron表达式 private String cronExpression; //组名 private String jobGroup = Scheduler.DEFAULT_GROUP; private String jobName; private String className; // 执行任务的类(完整路径 包含包名) private String methodName;//执行任务的方法名 set ... get ...&#125; 2.任务类12345678910public class Test &#123; public void xun()&#123; System.out.println(\"--------定时任务2-------\"); &#125;&#125;public class Test2 &#123; public void test()&#123; System.out.println(\"--------定时任务1-------\"); &#125;&#125; 3.存入redis1234567891011121314151617181920212223public void start2() &#123; Gson gson = new Gson(); JobEntity jobEntity = new JobEntity(); jobEntity.setMethodName(\"test\"); jobEntity.setJobName(\"MyJob2\"); jobEntity.setClassName(\"zebra.shjf.schedule.Test2\"); jobEntity.setCronExpression(\"0/1 * * * * ?\"); jobEntity.setJobGroup(\"MyGroup2\"); JobEntity jobEntity2 = new JobEntity(); jobEntity2.setMethodName(\"xun\"); jobEntity2.setJobName(\"MyJob\"); jobEntity2.setClassName(\"zebra.shjf.schedule.Test\"); jobEntity2.setCronExpression(\"0/1 * * * * ?\"); jobEntity2.setJobGroup(\"MyGroup\"); ArrayList&lt;JobEntity&gt; list = new ArrayList&lt;JobEntity&gt;(); list.add(jobEntity); list.add(jobEntity2); jedis.set(\"jobEntity\", gson.toJson(list)); &#125; 127.0.0.1:6379&gt; get \"jobEntity\" \"[&#123;\\\"cronExpression\\\":\\\"0/1 * * * * ?\\\",\\\"jobGroup\\\":\\\"MyGroup2\\\",\\\"jobName\\\":\\\"MyJob2\\\",\\\"className\\\":\\\"zebra.shjf.schedule.Test2\\\",\\\"methodName\\\":\\\"test\\\"&#125;,&#123;\\\"cronExpression\\\":\\\"0/1 * * * * ?\\\",\\\"jobGroup\\\":\\\"MyGroup\\\",\\\"jobName\\\":\\\"MyJob\\\",\\\"className\\\":\\\"zebra.shjf.schedule.Test\\\",\\\"methodName\\\":\\\"xun\\\"&#125;]\" 3.重点解析(注释解释)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Test public void start3() throws Exception &#123; //准备添加从redis中得到的实体类，目的是遍历，然后添加到定时容器中，去执行 ArrayList&lt;JobEntity&gt;arrayList=new ArrayList&lt;JobEntity&gt;(); Gson gson = new Gson(); //从redis中得到json数组对象 String str = jedis.get(\"jobEntity\"); //json解析器 JsonParser parser = new JsonParser(); //解析出json元素，jsonElement对象中有一些方法判断是对象还是数组，各对应不同的处理 JsonElement jsonElement = parser.parse(str); //如果是json数组就转换为jsonArray JsonArray jsonArray = null; if (jsonElement.isJsonArray()) &#123; jsonArray = jsonElement.getAsJsonArray(); &#125; //遍历 Iterator it= jsonArray.iterator(); while (it.hasNext())&#123; JsonElement e = (JsonElement)it.next(); //把获得的数组中每一个对象，重新添加到数组中 arrayList.add(gson.fromJson(e,JobEntity.class)); &#125; //容器 Scheduler scheduler=null; //遍历数组 for(JobEntity jobEntity:arrayList)&#123; //遍历获得每个job对象 JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(jobEntity.getJobName(), jobEntity.getJobGroup()).// usingJobData(\"className\", jobEntity.getClassName()) .usingJobData(\"methodName\", jobEntity.getMethodName()).build(); //jobDetail.getJobDataMap().put(\"test\", jobEntity); //为每个任务动态构建表达式 CronScheduleBuilder cron = CronScheduleBuilder.cronSchedule(jobEntity.getCronExpression()); //构建触发器 CronTrigger trigger = TriggerBuilder.newTrigger().withIdentity(jobEntity.getJobName(), jobEntity.getJobGroup()).withSchedule(cron).build(); SchedulerFactory schedulerFactory = new StdSchedulerFactory(); scheduler = schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); &#125; scheduler.start(); Thread thread = new Thread(); thread.sleep(10000); &#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot+Quartz整合定时任务","slug":"SpringBoot-Quartz整合定时任务","date":"2017-04-12T07:27:59.000Z","updated":"2018-04-14T04:37:52.764Z","comments":true,"path":"2017/04/12/SpringBoot-Quartz整合定时任务/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot-Quartz整合定时任务/","excerpt":"","text":"概念： 当处理一些，简单的，固定时间，重复次数的任务可以使用简单触发器 当处理一些，负载的任务，可以使用Cron表达式（触发器的name字段一定要写）1.一个jobDetail就是一个业务。也就是准备定时的任务12345@Bean public JobDetail jobDetail()&#123; JobDetail jobDetail=new JobDetail(\"scheduledTasks2s\", Scheduler.DEFAULT_GROUP, ScheduledTasks2.class); return jobDetail; &#125; 2.SimpleTrigger简单触发器，设置多久触发一次，触发次数12345678 @Beanpublic SimpleTrigger simpleTrigger()&#123; SimpleTrigger simpleTrigger=new SimpleTrigger(\"simpleTrigger\",Scheduler.DEFAULT_GROUP); simpleTrigger.setStartTime(new Date(System.currentTimeMillis())); simpleTrigger.setRepeatInterval(5000);//没 simpleTrigger.setRepeatCount(10);//执行10次 return simpleTrigger;&#125; 2.1可以使用cron表达式的触发器/** * 触发器名字一定要写 * @return * @throws Exception */ @Bean public CronTrigger cronTrigger() throws Exception { CronTrigger cronTrigger = new CronTrigger(); cronTrigger.setName(&quot;MyCronTrigger&quot;); cronTrigger.setCronExpression(&quot;0/1 * * * * ? &quot;); return cronTrigger; } 3.Scheduler调度器，这个调度器由SchedulerFactory工厂获得设置定时任务和触 发器1234567@Bean public Scheduler scheduler(JobDetail jobDetail,SimpleTrigger simpleTrigger)throws Exception&#123; SchedulerFactory schedulerFactory=new StdSchedulerFactory(); Scheduler scheduler=schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, simpleTrigger); return scheduler; &#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot项目中整合dubbo实战","slug":"SpringBoot项目中整合dubbo实战","date":"2017-04-12T07:25:52.000Z","updated":"2018-04-23T06:32:31.110Z","comments":true,"path":"2017/04/12/SpringBoot项目中整合dubbo实战/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot项目中整合dubbo实战/","excerpt":"","text":"“看看星空，会觉得自己很渺小，可能我们在宇宙中从来就是一个偶然。所以，无论什么事情，仔细想一想，都没有什么大不了的。这能帮助自己在遇到挫折时稳定心态，想得更开。”– 《腾讯传》 摘要: 原创出处:www.bysocket.com 泥瓦匠BYSocket 本文跟着我学习的脚步，进行一步一步的探索。 一、下载zookeeper服务注册管理器 下载ZooKeeper地址：https://www.apache.org/dyn/closer.cgi/zookeeper12345678910 liuxin@KK-MINI  ~  cd zookeeper-3.5.2-alpha\\ 2 liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2  lsCHANGES.txt README_packaging.txt contrib ivysettings.xml src zookeeper-3.5.2-alpha.jar.md5LICENSE.txt bin dist-maven lib zookeeper zookeeper-3.5.2-alpha.jar.sha1NOTICE.txt build.xml docs logs zookeeper-3.5.2-alpha.jarREADME.txt conf ivy.xml recipes zookeeper-3.5.2-alpha.jar.asc liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2  cd conf liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2/conf  lsconfiguration.xsl log4j.properties zoo.cfg zoo_sample.cfg liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2/conf  在conf中创建输入zoo.cfg 123456tickTime=2000#这个地址自定义dataDir=/javaee/zookeeper/data #这个地址自定义dataLogDir=/javaee/zookeeper/logclientPort=2181 然后在bin目录中./zkServer.sh start启动 二、创建生产者 在pom文件中引入dubbo 12345 &lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-spring-boot&#125;&lt;/version&gt;&lt;/dependency&gt; application.properties 1234567## Dubbo 服务提供者配置spring.dubbo.application.name=providerspring.dubbo.registry.address=zookeeper://127.0.0.1:2181spring.dubbo.protocol.name=dubbospring.dubbo.protocol.port=20880spring.dubbo.scan=org.spring.springboot.dubboserver.port=8082 向原来创建SpringBoot项目中一样，不过注意一个注解@Service使用dubbo提供的 123456789import com.alibaba.dubbo.config.annotation.Service;@Service(version = \"1.0.1\")public class UserDubboServiceImpl implements UserDubboService &#123; @Override public User getUserByName(String name) &#123; return new User(name,\"shanghai\"); &#125;&#125; 当项目启动的时候，会把这个服务注册到zookeeper中。等到消费 三、创建消费者 pom文件中和上面引入的一样。 application.properties 1234567## 避免和 server 工程端口冲突server.port=8081## Dubbo 服务消费者配置spring.dubbo.application.name=consumerspring.dubbo.registry.address=zookeeper://127.0.0.1:2181spring.dubbo.scan=org.spring.springboot.dubbo 创建在服务提供中一样的JavaBean对象 User和UserDubboService 使用@Reference(version = &quot;1.0.1&quot;)注解引入服务 123456789@Componentpublic class UserDubboConsumerService &#123; @Reference(version = \"1.0.1\") UserDubboService userDubboService; public void getUserByName()&#123; System.out.println(userDubboService.getUserByName(\"周杰伦\")); &#125;&#125; 当项目其中的时候，会想zookeeper中查询服务生产者地址，然后直接，调用生产者服务中的服务。zookeeper是提供软负载均衡。比nginx中需要手动配置服务地址，来看，好多了。 码云地址:https://git.oschina.net/chinesszz/springboot-learning-example.git 三、引入zkui视图查看zookeeper 上面服务生产和消费都创建成功了，那么我们需要看一下。此时需要下载 zkui 地址：https://github.com/DeemOpen/zkui 开发环境中安装好maven，mvn package打包，然后将config.cfg中的zookeeper地址改为自己的zkServer=localhost:2181,localhost:2181 12345678910111213141516171819 liuxin@KK-MINI  ~/git/模仿项目/zkui/target   master  lsarchive-tmp nohup.out zkui-2.0-SNAPSHOT.jarclasses surefire-reports zkui-out.loggenerated-sources test-classesmaven-archiver zkui-2.0-SNAPSHOT-jar-with-dependencies.jar liuxin@KK-MINI  ~/git/模仿项目/zkui/target   master  java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jarPlease create config.cfg properties file and then execute the program! ✘ liuxin@KK-MINI  ~/git/模仿项目/zkui/target   master  java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.metadatatable.MetaDataTableImpl createIfNotExists信息: Creating Metadata table: \"PUBLIC\".\"schema_version\"三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.command.DbMigrate migrate信息: Current version of schema \"PUBLIC\": &lt;&lt; Empty Schema &gt;&gt;三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.command.DbMigrate applyMigration信息: Migrating schema \"PUBLIC\" to version 1三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.command.DbMigrate logSummary信息: Successfully applied 1 migration to schema \"PUBLIC\" (execution time 00:00.143s).log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).log4j:WARN Please initialize the log4j system properly.log4j:WARN See https://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. 用户账号和密码都在配置文件中… 默认 { &quot;username&quot;:&quot;admin&quot; , &quot;password&quot;:&quot;manager&quot;,&quot;role&quot;: &quot;ADMIN&quot; } 参考: 基于Zookeeper的服务注册与发现 https://www.cnblogs.com/ASPNET2008/p/5622005.html","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot项目调试之热加载","slug":"SpringBoot项目调试之热加载","date":"2017-04-12T07:25:52.000Z","updated":"2018-04-14T04:40:04.196Z","comments":true,"path":"2017/04/12/SpringBoot项目调试之热加载/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot项目调试之热加载/","excerpt":"","text":"现代IDE（Eclipse，IDEA等）都支持热交换的字节码，所以如果你做一个不影响类或方法签名的更改，它应该重新加载干净没有副作用。Spring Loaded有点进一步，它可以重新加载类定义与方法签名中的更改。有一些自定义它可以强制ApplicationContext刷新自己（但没有一般的机制，以确保对于一个正在运行的应用程序是安全的，所以它只会是一个开发时间的伎俩）。 重新加载Java类，而不重新启动容器配置用于Maven的Spring Loaded 要使用Spring Loaded与Maven命令行，只需添加它作为Spring Boot插件声明中的依赖关系，例如 123456789101112131415161718&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;version&gt;1.2.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt;## 或者是下面这个依赖 &lt;dependency&gt; &lt;groupId&gt; org.springframework.boot &lt;/ groupId&gt; &lt;artifactId&gt; spring-boot-devtools &lt;/ artifactId&gt; &lt;optional&gt; true &lt;/ optional&gt; &lt;/ dependency&gt; 这通常适用于Eclipse和IntelliJ IDEA，只要他们的构建配置与Maven默认值（Eclipse m2e这是开箱即用）一致","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot配置视图","slug":"SpringBoot配置视图","date":"2017-04-12T07:25:52.000Z","updated":"2018-04-14T04:39:50.668Z","comments":true,"path":"2017/04/12/SpringBoot配置视图/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/SpringBoot配置视图/","excerpt":"","text":"1234567891011121314151617@Configuration@EnableWebMvcpublic class ApplicationConfigurerAdapter extends WebMvcConfigurerAdapter &#123; @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; configurer.enable(); &#125; @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix(\"WEB-INF/html\"); resolver.setSuffix(\".html\"); return resolver; &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"TCP-Keepalive解读","slug":"TCP-Keepalive解读","date":"2017-04-12T05:33:55.000Z","updated":"2018-04-23T06:32:29.533Z","comments":true,"path":"2017/04/12/TCP-Keepalive解读/","link":"","permalink":"https://blog.springlearn.cn/2017/04/12/TCP-Keepalive解读/","excerpt":"","text":"Netty 扩展TCP是无感知的虚拟连接，中间断开两端不会立刻得到通知。一般在使用长连接的环境下，需要心跳保活机制可以勉强感知其存活。业务层面有心跳机制，TCP协议也提供了心跳保活机制。 TCP 活性探测理解因为TCP是无感知的虚拟连接，所以在设计底层编程的时候，如果客户端和服务端互相不知道是否中断，那么服务端可能会一直等下去，==默认情况下使用keepalive周期为2个小时，如不选择更改，属于误用范畴，造成资源浪费== Java/netty服务器如何使用只需要在服务器端一方设置即可，客户端完全不用设置，比如基于netty 4服务器程序： 12345678910111213141516171819ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .childOption(ChannelOption.SO_KEEPALIVE, true) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast( new EchoServerHandler()); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(port).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); Java程序只能做到设置SO_KEEPALIVE选项，至于TCP_KEEPCNT，TCP_KEEPIDLE，TCP_KEEPINTVL等参数配置，只能依赖于sysctl配置，系统进行读取。 具体为： ChannelOption.SO_BACKLOG, 1024BACKLOG用于构造服务端套接字ServerSocket对象，标识当服务器请求处理线程全满时，用于临时存放已完成三次握手的请求的队列的最大长度。如果未设置或所设置的值小于1，Java将使用默认值50。 ChannelOption.SO_KEEPALIVE, true是否启用心跳保活机制。在双方TCP套接字建立连接后（即都进入ESTABLISHED状态）并且在两个小时左右上层没有任何数据传输的情况下，这套机制才会被激活。 ChannelOption.TCP_NODELAY, true在TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。这里就涉及到一个名为Nagle的算法，该算法的目的就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。 TCP_NODELAY就是用于启用或关于Nagle算法。如果要求高实时性，有数据发送时就马上发送，就将该选项设置为true关闭Nagle算法；如果要减少发送次数减少网络交互，就设置为false等累积一定大小后再发送。默认为false。 系统内核参数配置以下环境是在Linux服务器上进行。应用程序若想使用，需要设置SO_KEEPALIVE套接口选项才能够生效。 tcp_keepalive_time，在TCP保活打开的情况下，最后一次数据交换到TCP发送第一个保活探测包的间隔，即允许的持续空闲时长，或者说每次正常发送心跳的周期，默认值为7200s（2h）。 tcp_keepalive_probes 在tcp_keepalive_time之后，没有接收到对方确认，继续发送保活探测包次数，默认值为9（次） tcp_keepalive_intvl，在tcp_keepalive_time之后，没有接收到对方确认，继续发送保活探测包的发送频率，默认值为75s。发送频率tcp_keepalive_intvl乘以发送次数tcp_keepalive_probes，就得到了从开始探测到放弃探测确定连接断开的时间 若设置，服务器在客户端连接空闲的时候，每90秒发送一次保活探测包到客户端，若没有及时收到客户端的TCP Keepalive ACK确认，将继续等待15秒*2=30秒。总之可以在90s+30s=120秒（两分钟）时间内可检测到连接失效与否。 以下改动，需要写入到/etc/sysctl.conf文件： 123456net.ipv4.tcp_keepalive_time=90net.ipv4.tcp_keepalive_intvl=15net.ipv4.tcp_keepalive_probes=2保存退出，然后执行sysctl -p生效。可通过 sysctl -a | grep keepalive 命令检测一下是否已经生效。针对已经设置SO_KEEPALIVE的套接字，应用程序不用重启，内核直接生效。 引用TCP Keepalive笔记","categories":[{"name":"通信","slug":"通信","permalink":"https://blog.springlearn.cn/categories/通信/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://blog.springlearn.cn/tags/Netty/"}],"keywords":[{"name":"通信","slug":"通信","permalink":"https://blog.springlearn.cn/categories/通信/"}]},{"title":"SpringBoot原生定时任务解析","slug":"SpringBoot原生定时任务解析","date":"2017-04-11T07:29:14.000Z","updated":"2018-04-14T04:45:05.509Z","comments":true,"path":"2017/04/11/SpringBoot原生定时任务解析/","link":"","permalink":"https://blog.springlearn.cn/2017/04/11/SpringBoot原生定时任务解析/","excerpt":"","text":"#SpringBoot原生定时任务，不需要引入任何依赖 ==只要了解，几个注解就可以使用== 1.在启动类上加入@EnableScheduling标签 2.在定时任务方法上加入@Schedule(fixedDelay=5000) 3.就是如此简单，简单的不可想象 123456789101112131415161718192021222324package zebra.shjf;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.scheduling.annotation.EnableScheduling;@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TestQuartzApplication.class, args); &#125;&#125;@Componentpublic class ScheduledTasks&#123; @Scheduled(fixedDelay = 5000) public void execute() &#123; System.out.println(\"当前时间：\" + new Date()); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring定时器","slug":"Spring定时器","permalink":"https://blog.springlearn.cn/tags/Spring定时器/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot优化方案","slug":"SpringBoot优化方案","date":"2017-03-12T08:00:13.000Z","updated":"2018-04-23T06:32:29.527Z","comments":true,"path":"2017/03/12/SpringBoot优化方案/","link":"","permalink":"https://blog.springlearn.cn/2017/03/12/SpringBoot优化方案/","excerpt":"","text":"Bean优化1.当使用@SpringBootApplication会默认注册pom文件中拥有的为bean 默认情况下自动获取应用配置信息，会加载一些不需要的beans 增加cpu消耗 beanNames个数：261 堆内存：150-220M 2.使用@Configuration和@EnableAutoConfiguration beanNames个数：158 3.使用【不建议使用】 使用mvn spring-boot:run -Ddebug 只用装配30个左右组件就能启动 注解解释： @EnableAutoConfiguration会自动加载可能需要的配置信息 在知道需要的beans的情况下，可以使用@Import方式去配置 4.生产环境下禁止xml校验 继承XmlWebApplicationContext复写init 在web.xml文件中配置 &lt;context-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt;com.example.CustomXmlWebApplicationContext&lt;/param-value&gt; &lt;/context-param&gt; 5.减少自动扫描，尽量使用配置形式，减少初始化扫描时间 6.使用延迟初始化的bean 【Using Lazy-Initialized Beans】 lazy-init属性为true spring初始化bean就能立即发现其错误，并进行错误处理，造成的负面效应增加了应用程序的加 载时间 优化方案： 【jvisualvm】 1.不适用默认方式，采用第二种减少注册bean数量，项目中需要 的bean，采用注解方式在配置类中注册。 2.tomcat8，新特性8.5.6 Servlet 3.1、JSP 2.3、EL 3.0 Servlet 3.1实现了非阻塞式的I/O通信，性能得到 巨大的改进 参考资料： 阿里云栖社区link 51CTO开发频道link Spring Boot性能优化link Google Cloud Platform优化link Spring Boot内存优化-DZonelink","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot事务注解详解","slug":"SpringBoot事务注解详解","date":"2017-02-12T07:48:32.000Z","updated":"2018-04-14T04:38:17.191Z","comments":true,"path":"2017/02/12/SpringBoot事务注解详解/","link":"","permalink":"https://blog.springlearn.cn/2017/02/12/SpringBoot事务注解详解/","excerpt":"","text":"关系型数据库多用到事务，在传统项目中使用xml配置，配置虽然也还好，但是看着很不美观，在使用SpringBoot框架，就简单的多了，以实战为准，直接上代码 @Transactionalspring 事务注解 1.简单开启事务管理1@EnableTransactionManagement // 启注解事务管理，等同于xml配置方式的 &lt;tx:annotation-driven /&gt; 2.事务注解详解默认遇到throw new RuntimeException(“…”);会回滚需要捕获的throw new Exception(“…”);不会回滚 指定回滚 12345@Transactional(rollbackFor=Exception.class) public void methodName() &#123; // 不会回滚 throw new Exception(\"...\"); &#125; 指定不回滚 12345@Transactional(noRollbackFor=Exception.class) public ItimDaoImpl getItemDaoImpl() &#123; // 会回滚 throw new RuntimeException(\"注释\"); &#125; 如果有事务,那么加入事务,没有的话新建一个(不写的情况下) 1@Transactional(propagation=Propagation.REQUIRED) 容器不为这个方法开启事务 1@Transactional(propagation=Propagation.NOT_SUPPORTED) 不管是否存在事务,都创建一个新的事务,原来的挂起,新的执行完毕,继续执行老的事务 1@Transactional(propagation=Propagation.REQUIRES_NEW) 必须在一个已有的事务中执行,否则抛出异常 1@Transactional(propagation=Propagation.MANDATORY) 必须在一个没有的事务中执行,否则抛出异常(与Propagation.MANDATORY相反) 1@Transactional(propagation=Propagation.NEVER) 如果其他bean调用这个方法,在其他bean中声明事务,那就用事务.如果其他bean没有声明事务,那就不用事务. 1234567891011121314@Transactional(propagation=Propagation.SUPPORTS) /*public void methodName()&#123; // 本类的修改方法 1 update(); // 调用其他类的修改方法 otherBean.update(); // 本类的修改方法 2 update();&#125;other失败了不会影响 本类的修改提交成功本类update的失败,other也失败*/ @Transactional(propagation=Propagation.NESTED) readOnly=true只读,不能更新,删除 1@Transactional (propagation = Propagation.REQUIRED,readOnly=true) 设置超时时间 1@Transactional (propagation = Propagation.REQUIRED,timeout=30) 设置数据库隔离级别 1@Transactional (propagation = Propagation.REQUIRED,isolation=Isolation.DEFAULT) 3.指定事务管理器spring Boot 使用事务非常简单，首先使用注解 @EnableTransactionManagement 开启事务支持后，然后在访问数据库的Service方法上添加注解 @Transactional 便可。 关于事务管理器，不管是JPA还是JDBC等都实现自接口 PlatformTransactionManager 如果你添加的是 spring-boot-starter-jdbc 依赖，框架会默认注入 DataSourceTransactionManager 实例。如果你添加的是 spring-boot-starter-data-jpa 依赖，框架会默认注入 JpaTransactionManager 实例。 你可以在启动类中添加如下方法，Debug测试，就能知道自动注入的是 PlatformTransactionManager 接口的哪个实现类。 3.1 打印项目事务管理器1234567891011121314@EnableTransactionManagement // 启注解事务管理，等同于xml配置方式的 &lt;tx:annotation-driven /&gt;@SpringBootApplicationpublic class ProfiledemoApplication &#123; @Bean public Object testBean(PlatformTransactionManager platformTransactionManager)&#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\" + platformTransactionManager.getClass().getName()); return new Object(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ProfiledemoApplication.class, args); &#125;&#125; 这些SpringBoot为我们自动做了，这些对我们并不透明，如果你项目做的比较大，添加的持久化依赖比较多，我们还是会选择人为的指定使用哪个事务管理器。代码如下： 3.2 指定事务管理器1234567891011121314151617181920@EnableTransactionManagement@SpringBootApplicationpublic class ProfiledemoApplication &#123; // 其中 dataSource 框架会自动为我们注入 @Bean public PlatformTransactionManager txManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean public Object testBean(PlatformTransactionManager platformTransactionManager) &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\" + platformTransactionManager.getClass().getName()); return new Object(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ProfiledemoApplication.class, args); &#125;&#125; 在Spring容器中，我们手工注解@Bean 将被优先加载，框架不会重新实例化其他的 PlatformTransactionManager 实现类。 然后在Service中，被 @Transactional 注解的方法，将支持事务。如果注解在类上，则整个类的所有方法都默认支持事务。 对于同一个工程中存在多个事务管理器要怎么处理，请看下面的实例，具体说明请看代码中的注释。 3.1 使用指定的事务管理器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@EnableTransactionManagement // 开启注解事务管理，等同于xml配置文件中的 &lt;tx:annotation-driven /&gt;@SpringBootApplicationpublic class ProfiledemoApplication implements TransactionManagementConfigurer &#123; @Resource(name=\"txManager2\") private PlatformTransactionManager txManager2; // 创建事务管理器1 @Bean(name = \"txManager1\") public PlatformTransactionManager txManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; // 创建事务管理器2 @Bean(name = \"txManager2\") public PlatformTransactionManager txManager2(EntityManagerFactory factory) &#123; return new JpaTransactionManager(factory); &#125; // 实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器 @Override public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return txManager2; &#125; public static void main(String[] args) &#123; SpringApplication.run(ProfiledemoApplication.class, args); &#125;&#125;@Componentpublic class DevSendMessage implements SendMessage &#123; // 使用value具体指定使用哪个事务管理器 @Transactional(value=\"txManager1\") @Override public void send() &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;Dev Send()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\"); send2(); &#125; // 在存在多个事务管理器的情况下，如果使用value具体指定 // 则默认使用方法 annotationDrivenTransactionManager() 返回的事务管理器 @Transactional public void send2() &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;Dev Send2()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\"); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"线程数究竟设多少合理","slug":"线程数究竟设多少合理","date":"2017-02-12T03:34:53.000Z","updated":"2018-04-23T06:32:27.837Z","comments":true,"path":"2017/02/12/线程数究竟设多少合理/","link":"","permalink":"https://blog.springlearn.cn/2017/02/12/线程数究竟设多少合理/","excerpt":"","text":"分享一篇，关于线程的经典文章。 一、需求缘起Web-Server通常有个配置，最大工作线程数，后端服务一般也有个配置，工作线程池的线程数量，这个线程数的配置不同的业务架构师有不同的经验值，有些业务设置为CPU核数的2倍，有些业务设置为CPU核数的8倍，有些业务设置为CPU核数的32倍。“工作线程数”的设置依据是什么，到底设置为多少能够最大化CPU性能，是本文要讨论的问题。 二、一些共性认知在进行进一步深入讨论之前，先以提问的方式就一些共性认知达成一致。 提问：工作线程数是不是设置的越大越好？回答：肯定不是的 1）一来服务器CPU核数有限，同时并发的线程数是有限的，1核CPU设置10000个工作线程没有意义 2）线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低 提问：调用sleep()函数的时候，线程是否一直占用CPU？ 回答：不占用，等待时会把CPU让出来，给其他需要CPU资源的线程使用 不止调用sleep()函数，在进行一些阻塞调用，例如网络编程中的阻塞accept()【等待客户端连接】和阻塞recv()【等待下游回包】也不占用CPU资源 提问：如果CPU是单核，设置多线程有意义么，能提高并发性能么？ 回答：即使是单核，使用多线程也是有意义的1）多线程编码可以让我们的服务/代码更加清晰，有些IO线程收发包，有些Worker线程进行任务处理，有些Timeout线程进行超时检测 2）如果有一个任务一直占用CPU资源在进行计算，那么此时增加线程并不能增加并发，例如这样的一个代码 while(1){ i++; } 该代码一直不停的占用CPU资源进行计算，会使CPU占用率达到100% 3）通常来说，Worker线程一般不会一直占用CPU进行计算，此时即使CPU是单核，增加Worker线程也能够提高并发，因为这个线程在休息的时候，其他的线程可以继续工作 三、常见服务线程模型了解常见的服务线程模型，有助于理解服务并发的原理，一般来说互联网常见的服务线程模型有如下两种 IO线程与工作线程通过队列解耦类模型 如上图，大部分Web-Server与服务框架都是使用这样的一种“IO线程与Worker线程通过队列解耦”类线程模型： 1）有少数几个IO线程监听上游发过来的请求，并进行收发包（生产者） 2）有一个或者多个任务队列，作为IO线程与Worker线程异步解耦的数据传输通道（临界资源） 3）有多个工作线程执行正真的任务（消费者） 这个线程模型应用很广，符合大部分场景，这个线程模型的特点是，工作线程内部是同步阻塞执行任务的（回想一下tomcat线程中是怎么执行Java程序的，dubbo工作线程中是怎么执行任务的），因此可以通过增加Worker线程数来增加并发能力，今天要讨论的重点是“该模型Worker线程数设置为多少能达到最大的并发”。 纯异步线程模型任何地方都没有阻塞，这种线程模型只需要设置很少的线程数就能够做到很高的吞吐量，Lighttpd有一种单进程单线程模式，并发处理能力很强，就是使用的的这种模型。该模型的缺点是： 1）如果使用单线程模式，难以利用多CPU多核的优势 2）程序员更习惯写同步代码，callback的方式对代码的可读性有冲击，对程序员的要求也更高 3）框架更复杂，往往需要server端收发组件，server端队列，client端收发组件，client端队列，上下文管理组件，有限状态机组件，超时管理组件的支持however，这个模型不是今天讨论的重点。 四、工作线程的工作模式了解工作线程的工作模式，对量化分析线程数的设置非常有帮助： 上图是一个典型的工作线程的处理过程，从开始处理start到结束处理end，该任务的处理共有7个步骤： 1）从工作队列里拿出任务，进行一些本地初始化计算，例如http协议分析、参数解析、参数校验等 2）访问cache拿一些数据 3）拿到cache里的数据后，再进行一些本地计算，这些计算和业务逻辑相关 4）通过RPC调用下游service再拿一些数据，或者让下游service去处理一些相关的任务 5）RPC调用结束后，再进行一些本地计算，怎么计算和业务逻辑相关 6）访问DB进行一些数据操作 7）操作完数据库之后做一些收尾工作，同样这些收尾工作也是本地计算，和业务逻辑相关 分析整个处理的时间轴，会发现： 1）其中1，3，5，7步骤中【上图中粉色时间轴】，线程进行本地业务逻辑计算时需要占用CPU 2）而2，4，6步骤中【上图中橙色时间轴】，访问cache、service、DB过程中线程处于一个等待结果的状态，不需要占用CPU，进一步的分解，这个“等待结果”的时间共分为三部分： 2.1）请求在网络上传输到下游的cache、service、DB 2.2）下游cache、service、DB进行任务处理 2.3）cache、service、DB将报文在网络上传回工作线程 五、量化分析并合理设置工作线程数最后一起来回答工作线程数设置为多少合理的问题。 通过上面的分析，Worker线程在执行的过程中，有一部计算时间需要占用CPU，另一部分等待时间不需要占用CPU，通过量化分析，例如打日志进行统计，可以统计出整个Worker线程执行过程中这两部分时间的比例，例如： 1）时间轴1，3，5，7【上图中粉色时间轴】的计算执行时间是100ms 2）时间轴2，4，6【上图中橙色时间轴】的等待时间也是100ms 得到的结果是，这个线程计算和等待的时间是1：1，即有50%的时间在计算（占用CPU），50%的时间在等待（不占用CPU）： 1）假设此时是单核，则设置为2个工作线程就可以把CPU充分利用起来，让CPU跑到100% 2）假设此时是N核，则设置为2N个工作现场就可以把CPU充分利用起来，让CPU跑到N*100% 结论：N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。 经验：一般来说，非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务），瓶颈都在后端数据库，本地CPU计算的时间很少，所以设置几十或者几百个工作线程也都是可能的。 六、结论N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。 开源中国原文","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://blog.springlearn.cn/tags/线程/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"HEXO之博客搭建","slug":"HEXO之博客搭建","date":"2016-09-14T03:49:42.000Z","updated":"2018-04-23T06:32:34.692Z","comments":false,"path":"2016/09/14/HEXO之博客搭建/","link":"","permalink":"https://blog.springlearn.cn/2016/09/14/HEXO之博客搭建/","excerpt":"","text":"HEXO 安装hexo博客工具1npm install -g hexo-cli 初始化目录1hexo init 生成静态页面1hexo g 清理缓存1hexo clean 推送到服务器推送时候要先: npm install hexo-deployer-git –save安装依赖 修改 123456# URL## If your site is put in a subdirectory, set url as 'https://yoursite.com/child' and root as '/child/'url: https://lxchinesszz.gitee.io/chinesszz/ 访问地址root: /chinesszz 访问项目permalink: :year/:month/:day/:title/permalink_defaults: 1hexo d 本地服务预览1hexo s 查看1浏览器: https://127.0.0.1:4000/ 绑定码云 修改配置项目根目录_config.yml 文件，修改deploy的值然后保存 1234deploy: type: git repo: https://gitee.com/lxchinesszz/chinesszz.git branch: 分支 在oschina中点击服务,启动pages静态访问 绑定到GITHUB 当绑定到github上需要常见仓库为 用户名.github.io 购买域名并转发到github 购买域名,并备案 配置域名转发 在github上仓库点击Setting设置域名","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://blog.springlearn.cn/tags/博客搭建/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"SpringBoot之开始and销毁注解","slug":"SpringBoot之开始and销毁注解","date":"2016-06-12T08:02:37.000Z","updated":"2018-04-14T04:38:07.924Z","comments":true,"path":"2016/06/12/SpringBoot之开始and销毁注解/","link":"","permalink":"https://blog.springlearn.cn/2016/06/12/SpringBoot之开始and销毁注解/","excerpt":"","text":"12345678910111213141516@Componentpublic class InitMain &#123; @PostConstruct public void init()&#123; System.out.println(\"执行初始化方法\"); &#125; public void say()&#123; System.out.println(\"正常方法\"); &#125; @PreDestroy public void destory()&#123; System.out.println(\"执行销毁方法\"); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"Logback高级用法","slug":"Logback高级用法","date":"2016-06-12T05:26:12.000Z","updated":"2018-04-23T06:32:23.278Z","comments":true,"path":"2016/06/12/Logback高级用法/","link":"","permalink":"https://blog.springlearn.cn/2016/06/12/Logback高级用法/","excerpt":"","text":"在日常的生产中，尤其是在微服务盛行的今天,我们的服务很可能是作为分布式应用上的一个点，会接受来自不同客户端的请求，那么在服务的为每行日志标记出来自的客户端呢？本篇我们通过介绍Logback的高级用法，来为大家实现。 日志扩展 扩展知识 在分布式应用的今天，如何通过日志把客户端请求的不同应用的日志串起来，展示呢 首先分析原理其实很简单，就是为每个线程保存点私有变量，这个私有变量的值，由我们自定义，用于区分不同的应用。 说到线程的私有变量，可能老程序猿，就想到这个类及 ThreadLocal ,关于个类的源码分析，小编已经写过了，这里就不解释了，继续… ,我们今天用到的这个 MDC 就是为每个线程请求保存私有变量，然后在输出日志的时候打印出来，这样就能标识出，每一行日志的来源。 代码实现Logback 框架已经为我们实现了一套常用的请求，今天我们就用，这个来演示。MDCInsertingServletFilter 我们看一下该类的源码分析一下: 12345678910111213141516171819202122232425262728public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; this.insertIntoMDC(request); try &#123; chain.doFilter(request, response); &#125; finally &#123; this.clearMDC(); &#125; &#125; void insertIntoMDC(ServletRequest request) &#123; MDC.put(\"req.remoteHost\", request.getRemoteHost()); if(request instanceof HttpServletRequest) &#123; HttpServletRequest httpServletRequest = (HttpServletRequest)request; MDC.put(\"req.requestURI\", httpServletRequest.getRequestURI()); StringBuffer requestURL = httpServletRequest.getRequestURL(); if(requestURL != null) &#123; MDC.put(\"req.requestURL\", requestURL.toString()); &#125; MDC.put(\"req.method\", httpServletRequest.getMethod()); MDC.put(\"req.queryString\", httpServletRequest.getQueryString()); MDC.put(\"req.userAgent\", httpServletRequest.getHeader(\"User-Agent\")); MDC.put(\"req.xForwardedFor\", httpServletRequest.getHeader(\"X-Forwarded-For\")); &#125; &#125; 就是利用 MDC 为每个处理请求的线程添加上私有变量。就是如此，不过我们要注意的是为了让MDC中的信息在任何时候都是正确有效的，我们需要在request被处理之前，就讲相关信息放入mdc，再在处理完后，clear掉。大家看到其实这个类是继承了 Filter 就是一个过滤器，在这里小编用的是 SpringBoot实现的 那么如何使用呢？ 12345678910111213141516171819/** * @Package: firebird.logger.config.filter * @Description: 应用配置 * @author: liuxin * @date: 2017/8/29 下午5:32 */@Componentpublic class ApplicationConfig &#123; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); Filter actionFilter = new MDCInsertingServletFilter(); registrationBean.setFilter(actionFilter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add(\"/*\"); registrationBean.setUrlPatterns(urlPatterns); return registrationBean; &#125;&#125; Loback打印日志该教程还是参考了我之前写的日志错误提醒框架，所以注释部分包括了使用 Sentry的部分代码，如果对错误收集框架感兴趣的同学，可以看我的另一篇博客SpringBoot整合Sentry 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;configuration&gt; &lt;!-- 彩色日志 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(--)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt;/&gt; &lt;property name=\"MDC_LOG_PATTERN\" value=\"IP:%X&#123;req.remoteHost&#125; -url:%X&#123;req.requestURI&#125; -Method:%X&#123;req.method&#125; - QueryString:%X&#123;req.queryString&#125; - device:%X&#123;req.userAgent&#125; -ips:%X&#123;req.xForwardedFor&#125; - %m%n \"&gt;&lt;/property&gt; &lt;appender name=\"Console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;layout&gt; &lt;pattern&gt;$&#123;MDC_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!--&lt;appender name=\"Sentry\" class=\"com.getsentry.raven.logback.SentryAppender\"&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;每个项目生成不通的key&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;dsn&gt;https://d73b23c481654b9ca0e4e8a9db310169:daaf5dc2edef462690791ef324316738@sentry.boluome.com/7&lt;/dsn&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash; 设置拦截的最低级别为warn 警告&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;--&gt; &lt;!--&lt;level&gt;WARN&lt;/level&gt;--&gt; &lt;!--&lt;/filter&gt;--&gt; &lt;!--&lt;/appender&gt;--&gt; &lt;!--&lt;logger name=\"logback.SentryAppenderIT\" level=\"INFO\"&gt;--&gt; &lt;!--&lt;appender-ref ref=\"Sentry\"/&gt;--&gt; &lt;!--&lt;/logger&gt;--&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"Console\"/&gt; &lt;!--&lt;appender-ref ref=\"Sentry\"/&gt;--&gt; &lt;/root&gt;&lt;/configuration&gt; 可以看到 MDC_LOG_PATTERN 中获取了从MDC过滤器中的参数，这样我们就能打印出来了 代码测试12345678910111213141516171819IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - URL : https://localhost:10111/loggerIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 请求类型 : GETIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 请求IP : 0:0:0:0:0:0:0:1IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 方法 : firebird.logger.rest.OtoRestController.testLoggerIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 参数列表 : []IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - hello world !!!IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - hello world !!!IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 返回参数 : 请查看日志IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - -----------------方法执行完毕,耗时:1ms-------------------IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - ----------testLogger方法开始执行----------------------------IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - URL : https://192.168.199.235:10111/loggerIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 请求类型 : GETIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 请求IP : 192.168.199.191IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 方法 : firebird.logger.rest.OtoRestController.testLoggerIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 参数列表 : []IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - hello world !!!IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - hello world !!!IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 返回参数 : 请查看日志IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - -----------------方法执行完毕,耗时:0ms------------------- 扩展方法如何实现呢? 不积跬步无以至千里,接下来还有要学习如何使用 Logstash kibana elasticsearch","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://blog.springlearn.cn/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"SpringBoot之AutoConfig自动配置","slug":"SpringBoot之AutoConfig自动配置","date":"2016-05-12T08:03:13.000Z","updated":"2018-04-14T04:38:01.083Z","comments":true,"path":"2016/05/12/SpringBoot之AutoConfig自动配置/","link":"","permalink":"https://blog.springlearn.cn/2016/05/12/SpringBoot之AutoConfig自动配置/","excerpt":"","text":"1. @XxxxAuto在SpringBoot中有很多以XxxxAutoConfiguration注解，其实他的作用就是,自动配置当前模块要依赖的类 例如: @EnableAutoConfiguration 就告诉SpringBoot需要加载那些类,spring-boot-1.5.1.RELEASE.jar/META-INF/spring.factories 在该文件中 2. @Enable@SpringBootApplication其实也是有以下三个注解组成的 @EnableAutoConfiguration 自动依赖当前所有模块的配置类org/springframework/boot/spring-boot-autoconfigure/1.5.2.RELEASE/spring-boot-autoconfigure-1.5.2.RELEASE.jar!/META-INF/spring.factories @ComponentScan 扫描class @Configuration 配置 当我们不在启动类添加@EnableAutoConfiguration时候,我们要自定义要依赖的模块,就要使用 @EnableAsync @EnableScheduling @EnableWebMVC @EnableConfigurationProperties @EnableJpaRepositories @EnableTransactionManagement @EnableCaching 其实@EnableAutoConfiguration这个注解,都是从自己的模块中查询spring.factories文件,所以当应用启动就加载spring-boot-autoconfigure中的Spring.factories 代码中是12345678910类:AutoConfigurationImportSelector方法:public String[] selectImports(AnnotationMetadata annotationMetadata)AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader)public static AutoConfigurationMetadata loadMetadata(ClassLoader classLoader) &#123; return loadMetadata(classLoader, \"META-INF/spring-autoconfigure-metadata.properties\"); &#125; 具体的模块会导入不同的EnableConfigurationPropertiesImportSelector,然后复写selectImports方法,从当前类名中拿到包名+中依赖的信息,然后加载 1234567891011Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123; Class&lt;? extends Annotation&gt; annotation() default Annotation.class; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; 生注册Bean或者是添加配置时候我们可以更加细化 @ConditionalOnClass ： classpath中存在该类时起效 @ConditionalOnMissingClass ： classpath中不存在该类时起效 @ConditionalOnBean ： DI容器中存在该类型Bean时起效 @ConditionalOnMissingBean ： DI容器中不存在该类型Bean时起效 @ConditionalOnSingleCandidate ： DI容器中该类型Bean只有一个或@Primary的只有一个时起效 @ConditionalOnExpression ： SpEL表达式结果为true时 @ConditionalOnProperty ： 参数设置或者值一致时起效 @ConditionalOnResource ： 指定的文件存在时起效 @ConditionalOnJndi ： 指定的JNDI存在时起效 @ConditionalOnJava ： 指定的Java版本存在时起效 @ConditionalOnWebApplication ： Web应用环境下起效 @ConditionalOnNotWebApplication ： 非Web应用环境下起效 执行顺序 @AutoConfigureAfter：在指定的配置类初始化后再加载 @AutoConfigureBefore：在指定的配置类初始化前加载 @AutoConfigureOrder：数越小越先初始化 自定义Conditional约束类12345678910111213141516171819202122232425public class ConditionalOtoSaasApplication extends SpringBootCondition &#123; @Override public ConditionOutcome getMatchOutcome(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; Object name = annotatedTypeMetadata.getAnnotationAttributes(ConditionalOnMyProperties.class.getName()).get(\"name\"); conditionContext.getEnvironment(); if (((String) name).equalsIgnoreCase(\"test\")) &#123; return new ConditionOutcome(true, \"get name properties\"); &#125; return new ConditionOutcome(false, \"no get name properties\"); &#125;&#125;@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(ConditionalOtoSaasApplication.class)public @interface ConditionalOnMyProperties &#123; String name();&#125;@Configuration@ConditionalOnMyProperties(name = \"test\")public class BlmConfig &#123; private String url; private String name;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot添加过滤器-两种实现方式","slug":"SpringBoot添加过滤器-两种实现方式","date":"2016-04-12T08:01:58.000Z","updated":"2018-04-14T04:39:19.540Z","comments":true,"path":"2016/04/12/SpringBoot添加过滤器-两种实现方式/","link":"","permalink":"https://blog.springlearn.cn/2016/04/12/SpringBoot添加过滤器-两种实现方式/","excerpt":"","text":"集成Filter接口 public class MDCInsertingServletFilter implements Filter { /** * @Package: firebird.logger.config.filter * @Description: 应用配置 * @author: liuxin * @date: 2017/8/29 下午5:32 */ @Component public class ApplicationConfig { @Bean public FilterRegistrationBean filterRegistrationBean() { FilterRegistrationBean registrationBean = new FilterRegistrationBean(); Filter actionFilter = new MDCInsertingServletFilter(); registrationBean.setFilter(actionFilter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add(&quot;/*&quot;); registrationBean.setUrlPatterns(urlPatterns); return registrationBean; } } 使用注解 @WebFilter(filterName=”AppCodeInsertServletFilter”,urlPatterns={“/*”}) @ServletComponentScan 在启动类添加注解 @ServletComponentScan 扫描Servlet注解 @ServletComponentScan @SpringBootApplication public class OtoSaasApplication { public static void main(String[] args) { SpringApplication.run(OtoSaasApplication.class, args); } } 2.继承Filter 并添加 @WebFilter @WebFilter(filterName=&quot;HttpServletRequestReplacedFilter&quot;,urlPatterns={&quot;/*&quot;}) public class HttpServletRequestReplacedFilter implements Filter { ... } 验证是否添加成功 2017-11-15T14:05:14.144 INFO oto_saas__pay o.s.boot.web.servlet.FilterRegistrationBean [line:271 Mapping filter: &apos;HttpServletRequestReplacedFilter&apos; to urls: [/*]]","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"SpringBoot读取两种格式的配置文件","slug":"SpringBoot读取两种格式的配置文件","date":"2016-04-12T07:54:36.000Z","updated":"2018-04-14T04:39:36.046Z","comments":true,"path":"2016/04/12/SpringBoot读取两种格式的配置文件/","link":"","permalink":"https://blog.springlearn.cn/2016/04/12/SpringBoot读取两种格式的配置文件/","excerpt":"","text":"一般情况下我们常用Enventment读取配置，读取.properties，本篇文章主要从.properties和.yml文件来分析如何使用.也谈不上分析，直接上代码，一看就会了。如果不会yml的同学，直接看代码也能看懂了(规则是死的会用就ok) 首先引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 读取.propertiesmaster.ds.url=jdbc:mysql://localhost:3306/testmaster.ds.username=rootmaster.ds.password=root 1234567@ConfigurationProperties(prefix = \"master.ds\",locations = \"classpath:application.properties\") public class PropsConfig &#123; private String url; private String username; private String password; &#125; 读取yml1234567891011121314myProps: #自定义的属性和值 simpleProp: simplePropValue arrayProps: 1,2,3,4,5 listProp1: - name: abc value: abcValue - name: efg value: efgValue listProp2: - config2Value1 - config2Vavlue2 mapProps: key1: value1 key2: value2 1234567@ConfigurationProperties(prefix=\"myProps\") //application.yml中的myProps下的属性 public class YmlConfig &#123; private String simpleProp; private String[] arrayProps; private List&lt;Map&lt;String, String&gt;&gt; listProp1 = new ArrayList&lt;&gt;(); //接收prop1里面的属性值 private List&lt;String&gt; listProp2 = new ArrayList&lt;&gt;(); //接收prop2里面的属性值 private Map&lt;String, String&gt; mapProps = new HashMap&lt;&gt;(); //接收prop1里面的属性值","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"RequestMapper参数说明","slug":"RequestMapper参数说明","date":"2016-04-12T07:52:27.000Z","updated":"2018-04-23T06:32:38.653Z","comments":true,"path":"2016/04/12/RequestMapper参数说明/","link":"","permalink":"https://blog.springlearn.cn/2016/04/12/RequestMapper参数说明/","excerpt":"","text":"1234567891011/*** @param account 账户id* @param quota 充钱金额(元)* @return*/@RequestMapping(value = \"/&#123;account&#125;/account/quota\", method = RequestMethod.POST,consumes = \"application/json\")//方法仅处理request Content-Type为“application/json”类型的请求。@RequestMapping(value = \"/&#123;account&#125;/account/quota\", method = RequestMethod.POST, produces=\"application/json\",params=\"myParam=myValue\",headers=\"Referer=https://www.ifeng.com/\")//方法仅处理request请求中Accept头中包含了\"application/json\"的请求，同时暗示了返回的内容类型为application/json;//仅处理请求中包含了名为“myParam”，值为“myValue”的请求；//headers 请求头中包含这个的地址 consumes = “application/json” 请求头 produces=”application/json” 响应头","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"Tomcat7和Tomcat8的区别","slug":"Tomcat7和Tomcat8的区别","date":"2016-03-12T05:12:59.000Z","updated":"2018-04-14T04:40:26.131Z","comments":true,"path":"2016/03/12/Tomcat7和Tomcat8的区别/","link":"","permalink":"https://blog.springlearn.cn/2016/03/12/Tomcat7和Tomcat8的区别/","excerpt":"","text":"因为一次意外的原意，我部署了两个web容器 本地mac上是tomcat8 远程服务器是tomcat7 同时这两个web容器都使用nginx代理,项目打包在本地没有任何问题 但是在远程服务器就会出现图片加载不出来，应该是以汉字结尾的数据，不能够加载，刚开始是找到不到问题，原因。 因为所有以中文命名的图片和表格都是在一个文件夹，下面，所以以为，改文件夹没有被编译进去，但是最后发现确实是在。 然后我手动在远程服务器改文件夹，下面touch dadfa&gt;1.txt然后去访问1.txt结果却能访问，忽然豁然开朗，找到原因就是因为汉字不能够解析，然后搜索解决办法 tomcat7:URIEncodingThis specifies the character encoding used to decode the URI bytes, after %xx decoding the URL. If not specified, ISO-8859-1 will be used 这个参数用来设置解码url参数，如果没指定，默认是ISO-8859-1。 tomcat8:URIEncodingThis specifies the character encoding used to decode the URI bytes, after %xx decoding the URL. If not specified, UTF-8 will be used unless the org.apache.catalina.STRICT_SERVLET_COMPLIANCE system property is set to true in which case ISO-8859-1 will be used.这个参数用来设置解码url参数，如果没指定，默认是UTF-8，除非设置了org.apache.catalina.STRICT_SERVLET_COMPLIANCE这个系统参数为true，这个时候会使用ISO-8859-1。 123456&lt;Connector port=\"8080\" URIEncoding=\"utf-8\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.springlearn.cn/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"StringBoot整合Shiro","slug":"StringBoot整合Shiro","date":"2016-01-12T07:52:56.000Z","updated":"2018-04-14T04:40:14.640Z","comments":true,"path":"2016/01/12/StringBoot整合Shiro/","link":"","permalink":"https://blog.springlearn.cn/2016/01/12/StringBoot整合Shiro/","excerpt":"","text":"首先第一步引入12345&lt;!--shiro权限控制框架--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; 添加配置类 安全管理器(在管理器中添加自己的验证密码和权限的方法) 123456@Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(myShiroRealm()); return securityManager; &#125; 配置拦截链 拦截链的意思，就是给url赋值权限 12345678910111213141516171819202122232425262728293031/** * ShiroFilterFactoryBean 处理拦截资源文件问题。 * 注意：单独一个ShiroFilterFactoryBean配置是或报错的，以为在 * 初始化ShiroFilterFactoryBean的时候需要注入：SecurityManager * * Filter Chain定义说明 1、一个URL可以配置多个Filter，使用逗号分隔 2、当设置多个过滤器时，全部验证通过，才视为通过 * 3、部分过滤器可指定参数，如perms，roles * */ @Bean public ShiroFilterFactoryBean shirFilter(SecurityManager securityManager) &#123; ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); // 必须设置 SecurityManager shiroFilterFactoryBean.setSecurityManager(securityManager); // 如果不设置默认会自动寻找Web工程根目录下的\"admin登录页面\"页面 shiroFilterFactoryBean.setLoginUrl(\"/admin/login\"); // 登录成功后要跳转的链接 shiroFilterFactoryBean.setSuccessUrl(\"/index\"); // 未授权界面; shiroFilterFactoryBean.setUnauthorizedUrl(\"/403\"); // 拦截器. Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;String, String&gt;(); filterChainDefinitionMap.put(\"/admin/login\", \"anon\");//登录页面 //TODO 跟登录权限,添加权限test测试。 filterChainDefinitionMap.put(\"/admin/index\", \"authc,perms[\" +\"test\" + \"]\");//校验密码和权限 // 配置退出过滤器,其中的具体的退出代码Shiro已经替我们实现了 filterChainDefinitionMap.put(\"/logout\", \"logout\"); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; &#125; 实现Realm doGetAuthenticationInfo 校验密码 1234567891011121314151617181920212223/** * 校验用户名和密码 * * @param authcToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authcToken) throws AuthenticationException &#123; logger.debug(\"身份认证方法：MyShiroRealm.doGetAuthenticationInfo()\"); UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) authcToken; //TODO 根据用户名和用户密码判断用户，用户验证成功，就把用户名和用户密码放行 String userName = usernamePasswordToken.getUsername(); Admin user = mongoDao.findOneByQuery(Admin.class, \"userName\", usernamePasswordToken.getUsername()); String pwd = String.valueOf(usernamePasswordToken.getPassword()); if (ObjectUtils.isEmpty(user))&#123; throw new IncorrectCredentialsException(); &#125; if (StringUtils.endsWithIgnoreCase(user.getPassword(), pwd)) &#123; return new SimpleAuthenticationInfo(userName, pwd, getName()); &#125; return null; &#125; doGetAuthorizationInfo 在本方法中,查询用户的所有权限，然后添加 123456789101112131415161718192021/** * 权限链配置 * 在shiro配置类中把资源对应的权限都加载到应用中 * * 在本方法中,查询用户的所有权限，然后添加 * * @param principals * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; logger.debug(\"##################执行Shiro权限认证##################\"); //获取当前登录输入的用户名，等价于 String userName = (String) super.getAvailablePrincipal(principals); logger.debug(\"##################开始查询用户【\" + userName + \"】的权限##################\"); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); //根据每个用户名获得对应的权限列表 //根据用户名获取用户的权限 info.addStringPermission(\"test\"); return info; &#125; ​","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://blog.springlearn.cn/categories/Spring-Boot/"}]},{"title":"ELK服务搭建之Kibana使用说明","slug":"ELK服务搭建之Kibana使用说明","date":"2016-01-12T03:29:04.000Z","updated":"2018-04-23T06:32:38.843Z","comments":true,"path":"2016/01/12/ELK服务搭建之Kibana使用说明/","link":"","permalink":"https://blog.springlearn.cn/2016/01/12/ELK服务搭建之Kibana使用说明/","excerpt":"","text":"前言logstash 通过配置文件把收集到的日志文件，通过正则匹配分析，发送到es服务器构建索引，并通过Kibana展示 目录 Logstash正则构建 查询语句 量化分析 Visualize 仪表盘 Dashboard Logstash正则匹配正则工具官方文档 在logstash目录 mkdir patterns 12# contents of ./patterns/postfix:STR [a-zA-Z]&#123;1,&#125; 12345678910111213141516171819input &#123; file &#123; type =&gt; \"order_shenghuojiaofei\"truepath =&gt; \"/Users/liuxin/rabbitmql_pro.log\" &#125; &#125;filter &#123; grok &#123; patterns_dir =&gt; [\"./patterns\"] match =&gt; &#123; \"message\" =&gt; \"%&#123;STR:logLevel&#125; %&#123;STR:packName&#125;.%&#123;STR:thread&#125;.%&#123;STR:className&#125; %&#123;STR:date&#125;\" &#125;true&#125; &#125;output &#123;trueelasticsearch &#123;truetruehosts =&gt; \"127.0.0.1:9200\"truetrueindex =&gt; \"order_shenghuojiaofei-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\"truetruetemplate_overwrite =&gt; truetruetrue &#125;true &#125; 启动 logstash -f pro.conf 查询语句I. 字段查询(可以使用通配符*或?) 1field:value 例：city:Keyport*， age:26 II. 范围查询 12age:[20 TO 30] age:&#123;20 TO 30&#125;注：[ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内 III. 逻辑操作 1234AND OR 例子：firstname:H* AND age:20 firstname:H* OR age:20+ ：搜索结果中必须包含此项- ：不能含有此项例： +firstname:H* -age:20 city:H* firstname字段结果中必须存在H开头的，不能有年龄是20的，city字段H开头的可有可无 VI. 分组查询 1234分组(firstname:H* OR age:20) AND state:KS 先查询名字H开头年龄或者是20的结果，然后再与国家是KS的结合字段分组firstname:(+H* -He*) 搜索firstname字段里H开头的结果，并且排除firstname里He开头的结果 量化分析点击发现 Discover 输入查询条件 鼠标放置在字段上会添加展示改字段 Kibana参考文档 仪表盘Visualize 生成的报表信息，可以保存，放置在仪表盘里面展示","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://blog.springlearn.cn/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"ELK服务搭建之初识","slug":"ELK服务搭建之初识","date":"2016-01-12T03:27:45.000Z","updated":"2018-04-23T06:32:28.980Z","comments":true,"path":"2016/01/12/ELK服务搭建之初识/","link":"","permalink":"https://blog.springlearn.cn/2016/01/12/ELK服务搭建之初识/","excerpt":"","text":"logback配置详情 ELK E elasticsearch 负责对日志进行索引 L logstash 负责收集日志,输出到els K Kibaba 负责展示es索引的页面 Kibaba5.5.0 只支持Es5.5.0及以上版本 安装 elasticsearch 注意问题 1234Likely root cause: expected '&lt;document start&gt;', but found BlockMappingStart in 'reader', line 54, column 1: network.bind_host: 0.0.0.0 ^ 解决办法 参数key 前面要加空格 最小配置1234567path.data: /Users/liuxin/elasticsearch-5.5.2/datapath.logs: /Users/liuxin/elasticsearch-5.5.2/logsnetwork.bind_host: 0.0.0.0 network.publish_host: 127.0.0.1 network.host: m000 elasticsearch.yml配置详解 下载地址 安装Logstash解压配置环境变量 12345678910111213141516 liuxin@MacBook-Pro  ~/logstash-2.4.0  cat pro.confinput &#123; file &#123; type =&gt; \"rabbitmq-test\" path =&gt; \"/Users/liuxin/rabbitmql_pro.log\"true &#125;true &#125;true output &#123;true elasticsearch &#123;true hosts =&gt; \"127.0.0.1:9200\"truetrue index =&gt; \"logstash-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\"truetrue template_overwrite =&gt; truetruetruetrue &#125;truetruetrue &#125; liuxin@MacBook-Pro  ~/logstash-2.4.0  启动命令 : logstash -f pro.conf Logstash详解 安装Kibaba最小配置 123server.port: 5601server.host: \"localhost\"elasticsearch.url: \"https://localhost:9200\" 启动 bash kibana 以上方法是通过logstash读取文件的形式收集日志也可以应用主动发起日志logback.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;configuration debug=\"false\"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name=\"LOG_HOME\" value=\"E:/logs\" /&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log_%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" /&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.QueryParameters\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.query.HQLQueryPlan\" level=\"DEBUG\" /&gt; &lt;!--myibatis log configure--&gt; &lt;logger name=\"com.apache.ibatis\" level=\"TRACE\" /&gt; &lt;logger name=\"java.sql.Connection\" level=\"DEBUG\" /&gt; &lt;logger name=\"java.sql.Statement\" level=\"DEBUG\" /&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"DEBUG\" /&gt; &lt;appender name=\"stash\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt; &lt;destination&gt;192.168.10.200:8082&lt;/destination&gt; &lt;!-- encoder is required --&gt; &lt;encoder charset=\"UTF-8\" class=\"net.logstash.logback.encoder.LogstashEncoder\" /&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=\"INFO\"&gt; &lt;!-- 只有添加stash关联才会被收集--&gt; &lt;appender-ref ref=\"stash\" /&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt;&lt;/configuration&gt; pom 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt;&lt;/dependency&gt;&lt;!--实现slf4j接口并整合--&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.logstash.log4j&lt;/groupId&gt; &lt;artifactId&gt;jsonevent-layout&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt;&lt;/dependency&gt;","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://blog.springlearn.cn/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"CentOs配置防火墙","slug":"CentOs配置防火墙","date":"2015-06-12T10:31:57.000Z","updated":"2018-04-14T04:37:13.862Z","comments":true,"path":"2015/06/12/CentOs配置防火墙/","link":"","permalink":"https://blog.springlearn.cn/2015/06/12/CentOs配置防火墙/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334使用命令的方式配置CentOS7防火墙##Addfirewall-cmd --permanent --zone=public --add-port=80/tcp##Removefirewall-cmd --permanent --zone=public --remove-port=80/tcp##Reloadfirewall-cmd --reload复制代码检查是否生效firewall-cmd --zone=public --query-port=80/tcp列出所有的开放端口firewall-cmd --list-all查看防火墙状态systemctl status firewalld.service启动防火墙systemctl start firewalld.service关闭防火墙systemctl stop firewalld.service重新启动防火墙systemctl restart firewalld.service","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.springlearn.cn/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"本地服务器搭建","slug":"本地服务器搭建","date":"2015-04-12T05:35:42.000Z","updated":"2018-04-14T04:40:36.678Z","comments":true,"path":"2015/04/12/本地服务器搭建/","link":"","permalink":"https://blog.springlearn.cn/2015/04/12/本地服务器搭建/","excerpt":"","text":"工作之余，本人一直想买一台服务器，介于价格，一忍再忍，穷逼一个，无奈之下，萌生一个想法，通过自己的两台电脑，自己搭建一个服务器。 尤其之前用的ubuntu系统，用了三个多月，期间发现很多bug，所以准备换回centOS6，首先使用大白菜，把系统换位win10专业版，然后安装VMware10，在虚拟机里面安装CentOS6，因为两台电脑之间用的是同一个网络，所以可以互相连接。以下是我的操作步骤。 准备工作 两台电脑，同一个网络 1.服务器创建用户 首先创建一个组 groupadd -g 1500 maclink //g参数就是组id 如果不加默认是1000 开始 添加一个用户 useradd macuser -g maclink //添加一个用户名为macuser的用户在macgroup组中 如果你忘记你创建的组，那么使用下面的命令查看所有的组cat /etc/group 2.查看互相的ip mac系统和centOS中查看ip地址是 ifconfig # 这里我的mac地址是 192.168.1.107 # centOS中地址是设置和主机共享同一个网段 使用桥接方式，不要使用NAT方式，否则不是在一个网段 # centOS 中ip是 192.168.1.109 # 本篇文章最重要的地方就是这里，虚拟机中的服务器必须要和将要连接的电脑共处一个网段 # 所以必须使用桥接。 window系统中命令 ipconfig #windows下ip地址是 192.168.1.104 互相ping查看一下是否可以互相访问到Last login: Sun Feb 19 13:46:15 on ttys000 mac@MacBook-Air  ~  ping 192.168.1.109 PING 192.168.1.109 (192.168.1.109): 56 data bytes 64 bytes from 192.168.1.109: icmp_seq=0 ttl=64 time=139.139 ms 64 bytes from 192.168.1.109: icmp_seq=1 ttl=64 time=14.407 ms 64 bytes from 192.168.1.109: icmp_seq=2 ttl=64 time=173.413 ms 64 bytes from 192.168.1.109: icmp_seq=3 ttl=64 time=205.352 ms # 如果看到这里，那么已经成功一大半了 3.centOS中开方端口 ssl mac@192.168.1.109 //默认使用的22端口 ，因为没有使用安全连接，他会让你选择yes和no ✘ ⚙ mac@MacBook-Air  ~  ssh mac@192.168.1.109 The authenticity of host &apos;192.168.1.109 (192.168.1.109)&apos; can&apos;t be established. RSA key fingerprint is SHA256:8GcRL3cDzo3UHBCOTq5ExwKJ37VfTwJLBxZU0xWHBPY. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;192.168.1.109&apos; (RSA) to the list of known hosts. mac@192.168.1.109&apos;s password: [mac@localhost ~]$ ls Desktop Documents Downloads Music Pictures Public Templates Videos [mac@localhost ~]$ ls 这篇的内容就是这样，下一篇，使用安全连接 主要内容： 服务器生成安全密钥 服务器开放一个供访问的安全端口 使用ssl 公钥 安全连接 最后终级目标是将局域网地址映射到公网","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.springlearn.cn/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"本地服务器搭建之秘钥登录","slug":"本地服务器搭建之秘钥登录","date":"2015-04-12T05:35:42.000Z","updated":"2018-04-14T04:40:39.823Z","comments":true,"path":"2015/04/12/本地服务器搭建之秘钥登录/","link":"","permalink":"https://blog.springlearn.cn/2015/04/12/本地服务器搭建之秘钥登录/","excerpt":"","text":"作者：@lxchinesszz本文为作者原创，转载请注明出处 紧接上文，上文的重点不是连接，而是如何在局域网中用废弃的电脑搭建，是不是感觉很easy，那么这篇文章我们的重点就放在了安全上了，因为毕竟服务器是我们放应用或者数据库的地方，安全性一定要可靠。小编是做Java开发的，一只热爱技术的小菜鸟，因为工作中常常要一条龙服务，即，自己写需求文档，自己码代码，自己测试，自己部署，自己维护。虽然很累，但是很充实，很能提高自己。我也希望把自己的工作经验分享出来，对那些想小编一样热爱技术的小伙，有所帮助。说半天废话，下面开始。 密钥登录原理： 密钥常是一对的，即公钥和私钥，将公钥添加到服务器上的某个账户，然后客户端连接的时候，使用私钥完成认证就可以登录 A.使用私钥登录1.制作密钥对 首先在服务器制作，需要的登录账户，然后执行以下命令 12345678910[root@host ~]$ ssh-keygen #建立密钥对Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): #按 EnterCreated directory '/root/.ssh'.Enter passphrase (empty for no passphrase): # 输入密钥锁码，或直接按 Enter 留空Enter same passphrase again: # 再输入一遍密钥锁码Your identification has been saved in /root/.ssh/id_rsa. # 私钥Your public key has been saved in /root/.ssh/id_rsa.pub. # 公钥The key fingerprint is:0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:df:9b:cc:08 root@host 2.安装公钥到服务端 讲公钥安装到服务器 12[root@host ~]$ cd .ssh[root@host .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys 设置权限 12[root@host .ssh]$ chmod 600 authorized_keys #不让其他用户写入 600 权限[root@host .ssh]$ chmod 700 ~/.ssh #读写执行的权限 700 ssh的配置文件都在/etc/ssh/ 里面 1234[centos@localhost ~]$ cd /etc/ssh/[centos@localhost ssh]$ ls ssh_config #是客户单配置的 sshd_config #是服务端配置的 在sshd_config中配置使用RSA登录 1234RSAAuthentication yesPubkeyAuthentication yesPermitRootLogin yes # 允许root用户通过ssh登录PasswordAuthentication no #不允许密码登录，只用使用私钥登录[一般我也用yes] 最后服务端重启 ssh 1[root@host .ssh]$ service sshd restart 3.操作客户端 3.1把服务端私钥复制到客户端，cat id_rsa，就是一下内容 123456789101112131415161718192021222324252627282930-----BEGIN RSA PRIVATE KEY-----Proc-Type: 4,ENCRYPTEDDEK-Info: DES-EDE3-CBC,A757691CABE05419yvEX5nQY3+OeZ56kTt8i41YChrQgL9OwglA3SIU2ymrWvY+5IxXMOQbjJmoSFtRzOr0lB1eWZx8ZimGdG+y9KoN4AkUzX+HqzaC8/eMczrv2KXP6DpOvV6MTdHoBrTb8pJOSVzw1K1jmGPaCdWg3XJ7iNSdYr+FVHC6gmJhCCvSHjXLHYBseTSJNXzs4DpQrrTAnU1NXVt0ce3R7DCO/hGClS5zeQ7j7fpQ48cwBgNJumCcr5eU/TWlUMKm7Q8ZazLaugTg387qKaieFY6v8CvpqT4Oqt+j1+6B05sr2S4XiiWHdlcieG4fgSRc5I7kpEhzZWM2LdK6NtxkbWVzd0ZOu5dZDIaMykC2KJJwT+NW3yKZvN1iebm7jzLC3Pv1BdAqnzxMuwBVNbkvrmVWzi8+OvSfH3ttCoRVnshAAvPylBazAZpWn5k6f0QC8MkUQAIEFex80xBPJTT+L6HuijrO2Z1K6qeWe+ptUAqX3FrcuneH1Nn3MnOhNVb4HZvk0xoy3/+2xe3sYKOUsMqjpWlI3DzGnZ81R8z1sTquRQy3hHDZ8cA6k1wUWoVTpJArbCLphYurek+YN3kFGLhvKnd6YjnH3d2sq/qSIMp4m3T8iBkex5raf4iNpFwKzb3S9D6QSWl9Nfnd2tAWkApXU4TPOcbX7XtX1P5yexyNxAZaUHuDsPStO/53WHfu8G2BPnM2Pefaj1sUcODLK+4JR+edmtA9rjHXVx7Kd3OKRmpocmzYWgEOQJtklr+cL7SJJHzoKBjx0NB5/iW23KxSnj7gJhnrDbcD9wY5g63DuMsNnreMfk6trTbXe5ck/mfYN6bTCXkVczm5Q8BKY0cJF2n/2dJyow9RFJtxDTzm11SvqdXtZoanC5mttePViu3J88dbNETFw0DwutyY3KPq3taX40Ps76Ahh6BTb5QD8ctxpYx63MOfQG/BrPFD9M6All5YLzi1In3hc0s6GN2yvx/fdjNZpYFgxA0GH66evtlo3HMr/Id8zgZ+ZSikHMXpvpiXS4uBIgeCZeRaTbq/Bd2V2sN3ENQgV7UTVrnHDc5IWH+qpg8AZxnvmP6BBATNQ2WAc6I10JqkrtfwjKuSYGyJmg6fY5uSKkZo9JQ1uviWEyhdKDhtYgStxyoIznrbJE7PQ3iE3VanB0zmhJHdFJ9xsy5yggMSnRfLCmLsXrczJX0ALwtCDGrrAR3wAg1fn7WmdUfyfnAugJGOBMx25vOLASL3q5zKoxEr7ayln51uuWRE2oK63low68lcWt42aS/ozMsev6Wg7QQjg7HRYEavYZGmCv9OBAblOmneUQjajT2F6zY1R4Cajkk3XmBO2GHXJ685hTiBMQsGf81NMtGd2Zkd5jbcHYhfOe1TKRhgp9cxtzKuyzD2Hj5Bltw8Pq26JVqhLAXZpy73kVsCpU8KplyvZM349kM+VwzOwvvuoWuS+pi9iYYv2f4CjDWZ4dfzg30+ekEc2QTwsZrYbG8SyIOn4oZSE+ygFNge/o2ftqwpRSwJhV8sUlrhBHQb/plePpQQfRQlnifiqR/z2JQ4y28purVt5GKPuwsK4SpHCQTpXW3OkdA==-----END RSA PRIVATE KEY----- 把里面的内容复制（这个是我的）自己的文件下 12341.你也可以把服务端的id_rsa 下载到你的客户端，放在当前用户的.ssh目录下2.也可以复制里面的内容然后再.ssh目录下，重新创建一个id_rsavi ~/.ssh/id_rsa # 创建私钥 4.直接可以登录了【然后就会发现问题】123456789101112131415✘ ⚙ mac@MacBook-Air  ~/.ssh  ssh centos@192.168.1.112@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: UNPROTECTED PRIVATE KEY FILE! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@Permissions 0644 for '/Users/mac/.ssh/id_rsa' are too open.It is required that your private key files are NOT accessible by others.This private key will be ignored.Load key \"/Users/mac/.ssh/id_rsa\": bad permissionscentos@192.168.1.112's password:# 遇到这个问题一般就是权限问题 赋权700 ，然后就ok了⚙ mac@MacBook-Air  ~/.ssh  chmod 700 id_rsa⚙ mac@MacBook-Air  ~/.ssh  ssh centos@192.168.1.112Enter passphrase for key '/Users/mac/.ssh/id_rsa':Last login: Sun Feb 19 12:56:05 2017 from 192.168.1.113 B.设置安全端口 默认使用22端口，这个在etc/ssh/ssh_config 就可以看到 我们可以不使用22端口，此时我们可以在服务器重新创建一个端口，然后使用防火墙屏蔽其他端口 开启端口 开启一个10222端口 12345/sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT #写入修改 /etc/init.d/iptables save #保存修改 service iptables restart #重启防火墙，修改生效 ​ 然后可以查看一下端口状态 查看的时候一定要用root用户，否则查看不到的，所以我切换了10222 端口连接 端口的知识属于计算机的基础知识，如果你能看到这里，说明你的基础已经够了，不过下面我会专门写一篇关于底层的计算机的文章。 1234567891011121314151617181920[centos@localhost ssh]$ su root密码：[root@localhost ssh]# /etc/init.d/iptables status表格：filterChain INPUT (policy ACCEPT)num target prot opt source destination1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:102222 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:102223 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED4 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/05 ACCEPT all -- 0.0.0.0/0 0.0.0.0/06 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:227 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT)num target prot opt source destination1 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT)num target prot opt source destination 服务端在/etc/ssh/sshd_config 中监听10222端口，然后就可以使用 1ssh -p 10222 centos@192.168.1.112","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.springlearn.cn/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"服务器防止ping配置","slug":"服务器防止ping配置","date":"2015-04-12T05:31:25.000Z","updated":"2018-04-14T04:40:32.609Z","comments":true,"path":"2015/04/12/服务器防止ping配置/","link":"","permalink":"https://blog.springlearn.cn/2015/04/12/服务器防止ping配置/","excerpt":"","text":"1echo 0 &gt;/proc/sys/net/ipv4/icmp_echo_ignore_all 0 开启ping1 不开启","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.springlearn.cn/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"X","slug":"me","date":"2015-03-11T15:37:26.000Z","updated":"2018-06-27T01:22:09.930Z","comments":true,"path":"2015/03/11/me/","link":"","permalink":"https://blog.springlearn.cn/2015/03/11/me/","excerpt":"","text":"个人信息 笔名: chinesszz , 网名: X , 非著名码农。生于1993年，籍贯河南，现居上海。专注于基础架构和rpc通信框架研发。目前就职于某互联网软件服务公司 专注于企业微服务架构研究及开源框架底层源码研究 熟练运用各种流行的JavaEE技术进行组合式架构设计与开发。精通SpringFrameWork,业余时间研究并发编程,中间件,异地多活,Spring Cloud,SpringBoot1.x,SpringBoot2.x,Netty等开源项目，以及软件架构设计，程序性能优化，JVM，高并发等！ 个人爱好 热爱技术,相信技术改变生活.喜欢阅读优秀框架源码,学习其设计模式,及编程技巧 热爱编程,熟练掌握Java,Python等主流编程语言及服务器Linux Bash脚本编程, 具有良好的笔记习惯, 具有快速学习的能力 喜欢记笔记,记录分享传播工作中学习到的知识,分享给同样热爱技术的人儿 宗旨本博客主要分享小编在日常工作遇到的实际问题和学习中读过的好文。希望通过博客文章,将知识分享给大家,我认为在企业应用架构实践中非常实用的干货内容。 意见反馈若本号内容有做得不到位的地方（比如：涉及版权或其他问题），请及时联系我进行整改。 联系方式邮箱: lxchinesszz@163.com 今日头条 微信&amp;头条","categories":[{"name":"about","slug":"about","permalink":"https://blog.springlearn.cn/categories/about/"}],"tags":[],"keywords":[{"name":"about","slug":"about","permalink":"https://blog.springlearn.cn/categories/about/"}]},{"title":"Contos安装yum源","slug":"Contos安装yum源","date":"2015-01-11T05:30:05.000Z","updated":"2018-04-14T04:37:17.796Z","comments":true,"path":"2015/01/11/Contos安装yum源/","link":"","permalink":"https://blog.springlearn.cn/2015/01/11/Contos安装yum源/","excerpt":"","text":"cd /etc/yum.repos.d/ 因为使用yum安装都是安装的rpm包，所以可以使用 rpm -ql 查看安装的目录 12345[root@iz2ze283ts0vfkcqfvduzdz ~]# cd /etc/yum.repos.d/[root@iz2ze283ts0vfkcqfvduzdz yum.repos.d]# lsCentOS-Base-Aliyun.repo epel-Aliyun.repo epel-testing.repo nginx.repoCentOS-Base.repo epel.repo jenkins.repo[root@iz2ze283ts0vfkcqfvduzdz yum.repos.d]#","categories":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.springlearn.cn/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://blog.springlearn.cn/categories/杂记/"}]},{"title":"Git常用命令","slug":"GIt命令","date":"2015-01-11T03:49:42.000Z","updated":"2018-04-14T03:35:23.072Z","comments":true,"path":"2015/01/11/GIt命令/","link":"","permalink":"https://blog.springlearn.cn/2015/01/11/GIt命令/","excerpt":"","text":"查看配置文件 1git config --list 本地项目添加到github 12345678910111213git init 初始化git add ./ 进行跟踪git commit -m '' 提交本地#根据github仓库git remote add origin https:liuxin..#如果上面操作失败说明已经绑定了一个，就删除之前的git remote rm origin#推到远程仓库git push -u origin master 查看最近提交信息 1git log 添加并提交git commit -am ‘message’相当于添加跟踪并提交 12git commit -am \"some str\"git push 回退到上一次提交的状态git revert HEAD1git revert HEAD 回退到某个版本git reset 057d 12回退到某个版本 git reset 830bc084264841... 查看当前分支git branch123KK-MINI:svc_shenghuojiaofei liuxin$ git branch develop* master 创建分支git branch feature12345KK-MINI:svc_shenghuojiaofei liuxin$ git branch featureKK-MINI:svc_shenghuojiaofei liuxin$ git branch develop feature* master 切换分支12345678KK-MINI:svc_shenghuojiaofei liuxin$ git checkout featureM .gitignoreM src/main/resource/application.propertiesSwitched to branch 'feature'KK-MINI:svc_shenghuojiaofei liuxin$ git branch develop* feature master 提交到最新分支 12345KK-MINI:svc_shenghuojiaofei liuxin$ git push -u origin featureTotal 0 (delta 0), reused 0 (delta 0)To https://github.com/kpboluome/svc_shenghuojiaofei.git * [new branch] feature -&gt; featureBranch feature set up to track remote branch feature from origin. 删除远程分支 git push origin --delete testfenzhi 删除本地分支 git branch -D stg 同步feature分支到master分支 git checkout master git merge feature git push origin master 回退所有内容到上一个版本 1git reset HEAD^ 回退a.py这个文件的版本到上一个版本 1git reset HEAD^ a.py ` 拉取远程分支到本地分支可以把远程某各分支拉去到本地的branchname下，如果没有branchname，则会在本地新建branchname git fetch origin branchname:branchname","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://blog.springlearn.cn/tags/Git/"}],"keywords":[]}]}