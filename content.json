{"meta":{"title":"程序猿升级课","subtitle":null,"description":"一个关注于程序猿技术提升的博客","author":"liuxin","url":"https://lxchinesszz.github.io"},"pages":[],"posts":[{"title":"SpringBoot2.0之WebFlux解析及实战","slug":"SpringBoot2-0之WebFlux解析及实战","date":"2018-04-18T12:10:31.000Z","updated":"2018-04-18T12:20:41.133Z","comments":true,"path":"2018/04/18/SpringBoot2-0之WebFlux解析及实战/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/18/SpringBoot2-0之WebFlux解析及实战/","excerpt":"","text":"SpringBoot我是从1.2开始用的，我仿佛停留在1.5刚出来,支持了动态修改日志级别的时候,可突然之间2.0就出来了，貌似只有短短一年半的时间，突然感觉到了危机感，仿佛自己马上就要被淘汰了,在经过学习之后，将自己的项目demo和我对SpringBoot2.0的理解，分享给大家！ 如果有错误的地方,欢迎留言指出，最后谢谢各位，观看！ 小编学习的途径是先直接到官网看看，于是看到了最明显的区别就是下图图先放这里,先不着急，先看下，有一个印象，后面会说到。 先说一下官方的SpringBoot2.0新特性描述 SpringBoot2.0新特性 编程语言Java8+,和当前火爆的Kotlin 底层框架Spring Framwork 5.0.x 全新特性Web Flux（小编认为我们学习SpringBoot2.0就是学习这个） 我们分析下2.0的新特性为什么编程语言要从Java8开始呢？ 一个重要的原因就是使用Java8的Lambda表达式和Stream流处理 包括Spring Framwork 5.0.x也是要用到Java8的新特性. 当我们对SpringBoot2.0的新特性有一个认识的时候，再来看开头的第一张图片上面开篇截取Spring.io官网的图片。我们就能对SpringBoot1.0和2.0在心里有一个判断 SpringBoot1.0是仅支持Servlet Containers-&gt;Servlet API属于传统方式 SpringBoot2.0在支持1.0的特性上,同时添加了一个新特性就是WebFlux,可以使用Netty及Servlet3.1作为容器,基于 Reactive Streams 流处理。 当读到这里可能就有点懵了,Netty和Servlet3.1是一个什么鬼？ Netty是什么先不介绍，先说Servlet3.1在举例的时候，会提到Netty。 那么我们在分析Servlet3.0之前和3.0的区别？ 3.0之前Servlet 线程会一直阻塞，只有当业务处理完成并返回后时结束 Servlet线程。 3.0规范其中一个新特性是异步处理支持,即是在接收到请求之后，Servlet 线程可以将耗时的操作委派给另一个线程来完成，在不生成响应的情况下返回至容器 这样说可能大家还不太容易理解，我们来举一个例子 eg： 我们假设,设置tomcat最大线程为200,遇到200个非常耗时的请求 那么当有200个线程同时并发在处理,那么当来201个请求的时候,就已经处理不了，因为所有的线程都阻塞了。这是3.0之前的处理情况 而3.0之后异步处理是怎样处理呢？学过Netty通信框架的同学会比较容易理解一点，Servlet3.0类似于Netty一样就一个boss线程池和work线程池，boss线程只负责接收请求,work线程只负责处理逻辑。那么servlet3.0规范中，这200个线程只负责接收请求，然后每个线程将收到的请求，转发到work线程去处理。因为这200个线程只负责接收请求，并不负责处理逻辑，故不会被阻塞，而影响通信，就算处理非常耗时，也只是对work线程形成阻塞，所以当再来请求，同样可以处理,其主要应用场景是针对业务处理较耗时的情况可以减少服务器资源的占用，并且提高并发处理速度。 好了，当你已经读到这里，相信已经对SpringBoot1.0和SpringBoot2.0有一个比较清晰的认识了(当用过Netty通信框架类的童鞋一定是非常清晰的,如果还不清晰,就要补补课了)，所以我们不得不说SpringBoot2.0的性能一定是比1.0有所提升的。不过各有所爱，企业具体技术选型还要看业务需求，不能盲目追求新技术，毕竟新技术还不太稳定，没有被大规模的实践。好了，理论的知识就先讲到这里，开始实战编码吧。 项目实战通过上面的讲解，我们对其有了一个简单的认识，现在开始跟着我实战吧 ！SpringBoot2.0之WebFlux解析及实战请点击此处输入图片描述 在做项目实战的时候，我们要对下面两个问题有所了解！当这两个问题清楚后，实战就异常简单了 1. 我们知道SpringMVC是通过@Controller和@RequestMapping来定义路由的那么WebFlux是怎么定义路由的？ 我们看上图(下面的这两个区别要注意，项目中会遇到) 基于 Spring MVC 注解 @Controller 等 基于 Functional 函数式路由是 RouterFunctions 2. Flux和Mono分别是什么，在小编看来Flux和Mono都是一个数据的载体,不同的是 Flux 一种集合(0,n) Mono 一个实体包装(0,1) 为了代码的美观，小编在这里直接上图,因为头条不支持markdown，所以就直接看图吧启动时候添加测试数据 编写业务处理层 编写路由层 如果想获取源码的同学，请点击关注小编，并私信发送 SpringBoot2.0 获取项目地址，最后再次谢谢您的阅读，小编会每天分享一点小知识，及项目实战笔记，欢迎您的关注 ！","categories":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot2-0/"}],"tags":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot2-0/"}],"keywords":[{"name":"Spring-Boot2.0","slug":"Spring-Boot2-0","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot2-0/"}]},{"title":"Rabbitmq业务流程包含容错排查","slug":"Rabbitmq业务流程包含容错排查","date":"2018-04-17T09:47:47.000Z","updated":"2018-04-17T09:48:15.648Z","comments":true,"path":"2018/04/17/Rabbitmq业务流程包含容错排查/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/17/Rabbitmq业务流程包含容错排查/","excerpt":"","text":"流程是这样的，订阅者，发送消息到test交换机，通过route key 分发到绑定的队列，这里涉及到交换机的类型，可以看我上一篇文章。如果没有匹配到这个routeKey就默认发送到AE交换机(fanout模式)，这个交换机要设置internal:true意为内部交换机 。AE交换机再把错误的消息，发送到其绑定的队列中，如果test交换机，发送消息被匹配到的队里中，而处理该队列的订阅者，拒绝了或者超时了处理，test交换机就将该消息发送到就死信交换机，然后到死信队列中 一、 进入死信队列(进入死信的三种方式) 1.消息被拒绝（basic.reject or basic.nack）并且requeue=false 2.消息TTL过期 3.队列达到最大长度 代码演示 123- channel.basicReject(message.getMessageProperties().getDeliveryTag(), true); // 拒绝消息 - true 发送给下一个消费者 - false 谁都不接受，从队列中删除 Rabbit设置 1.设置AE交换机 设置为内部交换机，模式为fanout当发送到正常交换机消息，没有被匹配到route key的消息对进到改交换机 12 FanoutExchange fanoutExchange=new FanoutExchange(\"alter\");fanoutExchange.setInternal(true);//设置为内部交换机，作为处理了非法的消息,无法匹配到route key的消息 - 为AE交换机绑定队列 `alter_message` 2.设置处理正常的交换机 test 绑定参数,设置没有匹配 route key 的消息发送到AE交换机 alternate-exchange 3.添加正常的队列 hello 测试处理正常逻辑 task_queue 模拟被拒绝的消息添加超时时间和死信交换机和rk x-dead-letter-exchange: dead_letter_exchange x-dead-letter-routing-key: task_queue.fail x-message-ttl: 600 4.设置死信交换机 dead_letter_exchange 另外创建死信队列 dead 绑定 route key task_queue.fail 代码实例 Python123456789101112131415161718192021222324252627282930import pika#认证，生产者credentials = pika.PlainCredentials('guest', 'guest')#链接rabbit服务器（localhost是本机，如果是其他服务器请修改为ip地址）connection = pika.BlockingConnection(pika.ConnectionParameters('127.0.0.1',5672,'/',credentials))#通过tcp协议获取一个连接channel = connection.channel()#声明一个对下列和贾环加#channel.queue_declare(queue='hello')#被hello接受了channel.basic_publish(exchange='test', routing_key='hello', body='Hello World!')#发送了一个没有匹配的消息，匹配到了alter_messagechannel.basic_publish(exchange='test', routing_key='hello12312', body='Hello World!')#模拟一条虽然能被匹配到，但是无法消费的消息，然后被发送到死信队列消息channel.basic_publish(exchange='test', routing_key='task_queue', body='Hello World!') 正常队列 没有匹配到的到 被拒绝或者超时进入私信队列的 使用代码去创建队列和交换机 Java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Beanpublic ConnectionFactory connectionFactory() throws Exception &#123; CachingConnectionFactory connectionFactory = new CachingConnectionFactory(\"127.0.0.1\", 5672); connectionFactory.setUsername(\"liuxin\"); connectionFactory.setPassword(\"930914lx\"); connectionFactory.setVirtualHost(\"az\"); connectionFactory.setPublisherConfirms(true); // 必须要设置回调 Channel channel = connectionFactory.createConnection().createChannel(false); //String exchange, String type, boolean durable, boolean autoDelete, Map&lt;String, Object&gt; arguments Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(\"internal\",true); //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments //设置AE交换机 channel.exchangeDeclare(\"alter\", \"fanout\", false, false, false, arguments); channel.queueDeclare(\"alter_message\", false, false, false, null); channel.queueBind(\"alter_message\", \"alter\", \"\"); //声明死信交换机并绑定 channel.exchangeDeclare(\"dead_letter_exchange\", \"direct\", false, false, null); channel.queueDeclare(\"dead\", false, false, false, null); channel.queueBind(\"dead\", \"dead_letter_exchange\", \"task_queue.fail\"); arguments = new HashMap&lt;&gt;(); arguments.put(\"alternate-exchange\", \"alter\");//指定AE交换机 channel.exchangeDeclare(\"test\", \"direct\", false, false, arguments); //声明接受正式的队列，不需要参数 channel.queueDeclare(\"hello\", false, false, false, null); channel.queueBind(\"hello\", \"test\", \"hello\"); arguments = new HashMap&lt;&gt;(); arguments.put(\"x-dead-letter-exchange\", \"dead_letter_exchange\"); arguments.put(\"x-dead-letter-routing-key\", \"task_queue.fail\"); arguments.put(\"x-message-ttl\",6000);//6s没有被处理，就死了 //设置测试死信队列的task_queue，推送该队列里面，被拒绝会到dead_letter_exchange，并最终到dead，routeKey，task_queue.fail 为并设置死信队列参数 channel.queueDeclare(\"task_queue\", false, false, false, arguments); channel.queueBind(\"task_queue\", \"test\", \"task_queue\"); return connectionFactory;&#125; /** * 接受消息的监听，这个监听客户交易流水的消息 * 针对消费者配置 * * @return */@Beanpublic SimpleMessageListenerContainer messageContainer1(ConnectionFactory connectionFactory, PayMentConsumeImpl transactionConsume) &#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); container.addQueueNames(\"hello\"); container.setExposeListenerChannel(true); container.setMaxConcurrentConsumers(8); container.setConcurrentConsumers(4); container.setAcknowledgeMode(AcknowledgeMode.MANUAL); //设置确认模式手工确认,当设置了此模式，必须返回ACK，否则会进入死信队列 container.setMessageListener(transactionConsume); container.setPrefetchCount(1000); return container;&#125;","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://lxchinesszz.github.io/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}]},{"title":"Rabbitmq之事务模式及confirm确认模式","slug":"Rabbitmq之事务模式及confirm确认模式","date":"2018-04-17T09:47:06.000Z","updated":"2018-04-17T09:47:31.546Z","comments":true,"path":"2018/04/17/Rabbitmq之事务模式及confirm确认模式/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/17/Rabbitmq之事务模式及confirm确认模式/","excerpt":"","text":"事务模式 RabbitMQ中与事务机制有关的方法有三个，分别是Channel里面的txSelect()，txCommit()以及txRollback()，txSelect用于将当前Channel设置成是transaction模式，txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，如果txCommit提交成功了，则消息一定是到达broker了，如果在txCommit执行之前broker异常奔溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务了；然后重新发送 实际中使用事务会带来很大的性能损失，那么有没有更好的方法既能保证发布者知道消息已经正确到达，又能基本上不带来性能上的损失呢？从AMQP协议的层面看是没有更好的方法的，但是RabbitMQ提供了一个更好的方案，即将channel信道设置成confirm模式 1234567891011121314151617181920212223242526272829303132333435363738 public void run() &#123; Channel channel = null; try &#123; Connection connection = factory.newConnection(); channel = connection.createChannel(); //创建exchange channel.exchangeDeclare(exchangeName, \"direct\", true, false, null); //创建队列 channel.queueDeclare(queueName, true, false, false, null); //绑定exchange和queue channel.queueBind(queueName, exchangeName, bindingKey); //发送持久化消息 for(int i = 0;i &lt; count;i++) &#123; //第一个参数是exchangeName(默认情况下代理服务器端是存在一个\"\"名字的exchange的, //因此如果不创建exchange的话我们可以直接将该参数设置成\"\",如果创建了exchange的话 //我们需要将该参数设置成创建的exchange的名字),第二个参数是路由键 //开启事务 channel.txSelect(); channel.basicPublish(exchangeName, routingKey, true, MessageProperties.PERSISTENT_BASIC, (\"第\"+(i+1)+\"条消息\").getBytes()); if(i == 1) &#123; int result = 1/0; &#125; //提交事务 channel.txCommit(); &#125; &#125; catch (Exception e) &#123; try &#123; //回滚操作 channel.txRollback(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; e.printStackTrace(); &#125; &#125; &#125;","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://lxchinesszz.github.io/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}]},{"title":"Rabbitmq用户权限配置","slug":"Rabbitmq用户权限配置","date":"2018-04-17T09:46:30.000Z","updated":"2018-04-17T09:46:53.379Z","comments":true,"path":"2018/04/17/Rabbitmq用户权限配置/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/17/Rabbitmq用户权限配置/","excerpt":"","text":"由于账号guest具有所有的操作权限，并且又是默认账号，出于安全因素的考虑，guest用户只能通过localhost登陆使用，并建议修改guest用户的密码以及新建其他账号管理使用rabbitmq(该功能是在3.3.0版本引入的)。 用户管理 用户管理包括增加用户，删除用户，查看用户列表，修改用户密码。 相应的命令 (1) 新增一个用户 rabbitmqctl add_user Username Password (2) 删除一个用户 rabbitmqctl delete_user Username (3) 修改用户的密码 rabbitmqctl change_password Username Newpassword (4) 查看当前用户列表 rabbitmqctl list_users 用户角色 按照个人理解，用户角色可分为五类，超级管理员, 监控者, 策略制定者, 普通管理者以及其他。 (1) 超级管理员(administrator) 可登陆管理控制台(启用management plugin的情况下)，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 (2) 监控者(monitoring) 可登陆管理控制台(启用management plugin的情况下)，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) (3) 策略制定者(policymaker) 可登陆管理控制台(启用management plugin的情况下), 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 与administrator的对比，administrator能看到这些内容 (4) 普通管理者(management) 仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对策略进行管理。 (5) 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 了解了这些后，就可以根据需要给不同的用户设置不同的角色，以便按需管理。 设置用户角色的命令为： rabbitmqctl set_user_tags User Tag User为用户名， Tag为角色名(对应于上面的administrator，monitoring，policymaker，management，或其他自定义名称)。 也可以给同一用户设置多个角色，例如 rabbitmqctl set_user_tags hncscwc monitoring policymaker 用户权限 用户权限指的是用户对exchange，queue的操作权限，包括配置权限，读写权限。配置权限会影响到exchange，queue的声明和删除。读写权限影响到从queue里取消息，向exchange发送消息以及queue和exchange的绑定(bind)操作。 例如： 将queue绑定到某exchange上，需要具有queue的可写权限，以及exchange的可读权限；向exchange发送消息需要具有exchange的可写权限；从queue里取数据需要具有queue的可读权限。详细请参考官方文档中”How permissions work”部分。 相关命令为： (1) 设置用户权限 rabbitmqctl set_permissions -p VHostPath User ConfP WriteP ReadP (2) 查看(指定hostpath)所有用户的权限信息 rabbitmqctl list_permissions [-p VHostPath] (3) 查看指定用户的权限信息 rabbitmqctl list_user_permissions User (4) 清除用户的权限信息 rabbitmqctl clear_permissions [-p VHostPath] User 123456789101112liuxin@MacBook-Pro  ~  rabbitmqctl add_user liuxin 950914lxCreating user \"liuxin\" ... liuxin@MacBook-Pro  ~  rabbitmqctl list_usersListing users ...liuxin []guest [administrator] liuxin@MacBook-Pro  ~  rabbitmqctl set_user_tags liuxin administratorSetting tags for user \"liuxin\" to [administrator] ... liuxin@MacBook-Pro  ~  rabbitmqctl list_usersListing users ...liuxin [administrator]guest [administrator] 2.删除用户rabbitmqctl delete_user username 3.修改密码rabbitmqctl change_password usernamenewpassword 4.列出所有用户rabbitmqctl list_users权限控制1.创建虚拟主机rabbitmqctl add_vhost vhostpath 2.删除虚拟主机rabbitmqctl delete_vhost vhostpath 3.列出所有虚拟主机rabbitmqctl list_vhosts 4.设置用户权限 rabbitmqctl set_permissions [-pvhostpath] username regexp regexp regexp 5.清除用户权限 rabbitmqctl clear_permissions [-pvhostpath] username 6.列出虚拟主机上的所有权限 rabbitmqctl list_permissions [-pvhostpath] 7.列出用户权限 rabbitmqctl list_user_permissionsusername 123456789101112131415161718192021222324#添加虚拟端口 liuxin@MacBook-Pro  ~  rabbitmqctl add_vhost azCreating vhost \"az\" ... liuxin@MacBook-Pro  ~  rabbitmqctl add_user liuxin liuxinCreating user \"liuxin\" ...Error: user_already_exists: liuxin#为用户设置权限策略 ✘ liuxin@MacBook-Pro  ~  rabbitmqctl set_user_tags User administratorSetting tags for user \"User\" to [administrator] ...Error: no_such_user: User ✘ liuxin@MacBook-Pro  ~  rabbitmqctl set_user_tags liuxin administratorSetting tags for user \"liuxin\" to [administrator] ... liuxin@MacBook-Pro  ~  rabbitmqctl set_permissions -p az User ConfP WriteP ReadPSetting permissions for user \"User\" in vhost \"az\" ...Error: no_such_user: User#为用户设置虚拟端口 ✘ liuxin@MacBook-Pro  ~  rabbitmqctl set_permissions -p az liuxin ConfP WriteP ReadPSetting permissions for user \"liuxin\" in vhost \"az\" ...#匹配所有的队列和交换机#若果是liuxin-.* ,就是指匹配liuxin-开头的交换机或者队列rabbitmqctl set_permissions -p az liuxin \".*\" \".*\" \".*\"然后重新登录","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://lxchinesszz.github.io/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}]},{"title":"Rabbitmq之Topic和Direct、Fanout匹配解析","slug":"Rabbitmq之Topic和Direct、Fanout匹配解析","date":"2018-04-17T09:45:01.000Z","updated":"2018-04-17T09:46:33.149Z","comments":true,"path":"2018/04/17/Rabbitmq之Topic和Direct、Fanout匹配解析/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/17/Rabbitmq之Topic和Direct、Fanout匹配解析/","excerpt":"","text":"RabbitMQ详解 MQ常用概念快速入门使用 推荐查看 &lt;&lt;SpringBoot集成Rabbit使用TopicRabbit指定发送集合&gt;&gt; 目录 交换机(Exchange) 1.Direct Exchange 根据route key 直接找到队列 2.Topic Exchange 根据route key 匹配队列 3.Fanout Exchange 不处理route key 全网发送，所有绑定的队列都发送 交换机(Exchange)1. Direct Exchange Direct Exchange是RabbitMQ默认的交换机模式，也是最简单的模式，根据key全文匹配去寻找队列。 Q1 绑定了一个 binding key 名字为 orange； Q2 就有 2 个 binding key，名字为black和 green。 当消息中的 路由键 和 这个 binding key 对应上的时候，那么就知道了该消息去到哪一个队列中。 代码演示 A 12345678910111213@Beanpublic Queue helloQueue() &#123; return new Queue(\"retry_payment\");&#125;@BeanDirectExchange exchange() &#123; return new DirectExchange(\"retry_payment\");&#125;//绑定一个key，当消息匹配到就会放到这个队列中@BeanBinding bindingExchangeMessage(Queue queueMessage, DirectExchange exchange) &#123; return BindingBuilder.bind(queueMessage).to(exchange).with(\"retry_payment\");&#125; 12//向指定routingKey中推送，推送到指定队列rabbitTemplate.convertAndSend(exchange:\"retry_payment\", routingKey:\"retry_payment\", message:message); 代码演示 B 123456789101112Channel channel = connection.createChannel(); channel.exchangeDeclare(\"retry_payment\", \"direct\"); //声明一个交换机,direct 可以换位topic或者是fannoutchannel.queueDeclare(\"retry_payment\"); //声明一个队列channel.queueBind(\"queueName\", \"exchangeName\", \"routingKey\"); //绑定路由键 //需要绑定路由键,发送消息byte[] messageBodyBytes = \"hello world\".getBytes(); channel.basicPublish(\"exchangeName\", \"routingKey\", MessageProperties.PERSISTENT_TEXT_PLAIN, messageBodyBytes); 2.Topic Exchange Topic Exchange 转发消息主要是根据通配符。 在这种交换机下，队列和交换机的绑定会定义一种路由模式，那么，通配符就要在这种路由模式和路由键之间匹配后交换机才能转发消息。 在这种交换机模式下： 路由键必须是一串字符，用句号（.） 隔开，比如说 agreements.us，或者 agreements.eu.stockholm 等。 路由模式必须包含一个 星号（*），主要用于匹配路由键指定位置的一个单词，比如说，一个路由模式是这样子：agreements..b.*，那么就只能匹配路由键是这样子的：第一个单词是 agreements，第四个单词是 b。 井号（#）就表示相当于一个或者多个单词，例如一个匹配模式是agreements.eu.berlin.#，那么，以agreements.eu.berlin开头的路由键都是可以的。 具体代码发送的时候还是一样，第一个参数表示交换机，第二个参数表示routing key，第三个参数即消息。如下： 1rabbitTemplate.convertAndSend(\"testTopicExchange\",\"key1.a.c.key2\", \" this is RabbitMQ!\"); topic 和 direct 类似, 只是匹配上支持了”模式”, 在”点分”的 routing_key 形式中, 可以使用两个通配符: *表示一个词. #表示零个或多个词. 3.Fanout Exchange 不处理路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。 发送消息，只需要指定交换机，route key 可以为空 给消息设置属性值123设置请求头或者编码 MessageProperties messageProperties= message.getMessageProperties();","categories":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}],"tags":[{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"https://lxchinesszz.github.io/tags/Rabbitmq/"}],"keywords":[{"name":"数据处理","slug":"数据处理","permalink":"https://lxchinesszz.github.io/categories/数据处理/"}]},{"title":"Linux目录详细介绍","slug":"Linux目录详细介绍","date":"2018-04-16T17:14:47.000Z","updated":"2018-04-16T17:15:50.900Z","comments":true,"path":"2018/04/17/Linux目录详细介绍/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/17/Linux目录详细介绍/","excerpt":"","text":"平时开发中难免会经常操作服务器,而大部分服务器都是Linux,作为程序员我们经常会被linux服务器众多的目录所吓倒, 小编我之前也是这样,所以就收集了很多的linux常用的操作命令和linux目录的介绍，今天就把我笔记里面的linux目录这快的笔记，分享给大家，如果各位发现有问题，请及时指出哈,最后谢谢各位阅读，每天学习一点小知识。 文件目录 缩写 解释 /bin User Binaries 用户二进制文件 /sbin System Binaries 系统二进制文件 /etc Configuration Files 配置文件 /dev Device Files 设备文件 /proc Process Information 处理器信息 /var Variable Files 变量文件 /tmp Temporary Files 临时文件 /usr User Programs 用户程序 /home Home Directories 用户目录 /boot Boot Loader Files 系统引导文件 /lib System Libraries 系统依赖库 /opt Optional add-on Apps 附加应用 /mnt Mount Directory 临时挂载目录 /media Removable Devices 可移动设备文件 /srv Service Data 服务数据 / - 根 每个文件和目录都从根目录开始。 只有root用户拥有这个目录下的写权限。 请注意/ root是root用户的主目录，与/不一样。 / bin - 用户二进制文件 包含二进制可执行文件。 您需要在单用户模式下使用的常用linux命令位于此目录下。 系统的所有用户使用的命令位于此处。 例如：ps，ls，ping，grep，cp。 / sbin - 系统二进制文件 就像/ bin一样，/ sbin也包含二进制可执行文件。 但是，位于此目录下的linux命令通常由系统aministrator使用，用于系统维护目的。 例如：iptables，reboot，fdisk，ifconfig，swapon / etc - 配置文件 包含所有程序所需的配置文件。 这还包含用于启动/停止单个程序的启动和关闭shell脚本。 例如：/etc/resolv.conf，/etc/logrotate.conf / dev - 设备文件 包含设备文件。 这些包括终端设备，USB或连接到系统的任何设备。 例如：/ dev / tty1，/ dev / usbmon0 / proc - 进程信息 包含有关系统进程的信息。 这是一个包含运行进程信息的伪文件系统。例如：/ proc / {pid}目录包含有关该特定pid进程的信息。 这是一个具有关于系统资源的文本信息的虚拟文件系统。例如：/ proc / uptime / var - 变量文件 var代表可变文件。 预期会增长的文件内容可以在这个目录下找到。 这包括 - 系统日志文件（/ var / log）; 包和数据库文件（/ var / lib）; 电子邮件（/ var / mail）; 打印队列（/ var / spool）; 锁定文件（/ var / lock）; 重新启动时需要临时文件（/ var / tmp）; / tmp - 临时文件 包含由系统和用户创建的临时文件的目录。 系统重新启动时，此目录下的文件将被删除。 / usr - 用户程序 包含二进制文件，库，文档和二级程序的源代码。 / usr / bin包含用户程序的二进制文件。如果在/ bin下找不到用户二进制文件，请查看/ usr / bin。例如：at，awk，cc，less，scp / usr / sbin包含系统管理员的二进制文件。如果在/ sbin下找不到系统二进制文件，请查看/ usr / sbin。例如：atd，cron，sshd，useradd，userdel / usr / lib包含/ usr / bin和/ usr / sbin的库 / usr / local包含您从源代码安装的用户程序。例如，当您从源代码安装apache时，它将在/ usr / local / apache2下 / home - 主页目录 所有用户的主目录存储他们的个人文件。 例如：/ home / john，/ home / nikita / boot - 引导加载程序文件 包含启动加载器相关的文件。 内核initrd，vmlinux，grub文件位于/ boot下 例如：initrd.img-2.6.32-24-generic，vmlinuz-2.6.32-24-generic / lib - 系统库 包含支持位于/ bin和/ sbin下的二进制文件的库文件 库文件名是ld 或lib .so。* 例如：ld-2.11.1.so，libncurses.so.5.7 / opt - 可选的附加应用程序 opt代表可选。 包含来自各个供应商的附加应用程序。 附加应用程序应安装在/ opt /或/ opt /子目录下。 / mnt - 挂载目录 系统管理员可以挂载文件系统的临时挂载目录。 /媒体 - 可移动媒体设备 临时安装目录的可移动设备。 例如，用于CD-ROM的/ media / cdrom; /媒体/软盘软驱; / media / cdrecorder for CD writer / srv - 服务数据 srv代表服务。 包含服务器特定的服务相关数据。 例如，/ srv / cvs包含CVS相关数据。","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"Linux服务器","slug":"Linux服务器","permalink":"https://lxchinesszz.github.io/tags/Linux服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"Java开发之深浅拷贝","slug":"Java开发之深浅拷贝","date":"2018-04-15T17:06:59.000Z","updated":"2018-04-15T17:07:25.012Z","comments":true,"path":"2018/04/16/Java开发之深浅拷贝/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/16/Java开发之深浅拷贝/","excerpt":"","text":"什么是深复制呢？什么是浅复制呢？作为一名合格的coder的你是否清楚呢？ 小编我最近看到一张图,可以说完美的以可视化的方式，解释清楚了这个问题，请看下图 浅复制浅复制,也就是说是引用复制,是将堆里面的zhang内存地址值0xx1的复制了,给了 p和p1 ,p和p1里面的name都是指向内存值0xx1的位置，这个地址的值是zhang, 此时当p改变了0xx1这个地址的zhang为liu,那么也会影响到p1,因为p1的name也是指向0xx1 深复制深复制,就是值复制,此时p和p1里面的name分别是0xx1和0xx2,这个时候当其中任何一个被修改,并不影响另外一个的值 如此一来是不是非常清晰了呢？ 如果感觉到有用，请点击关注，支持下小编，小编会持续为您分享更多干货内容.","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"深浅拷贝","slug":"深浅拷贝","permalink":"https://lxchinesszz.github.io/tags/深浅拷贝/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"看懂一行GC日志","slug":"看懂一行GC日志","date":"2018-04-14T16:37:53.000Z","updated":"2018-04-16T04:51:23.920Z","comments":true,"path":"2018/04/15/看懂一行GC日志/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/15/看懂一行GC日志/","excerpt":"","text":"PSYoungGen 表示垃圾收集类型年轻代使用了Parallel Scavenge中括号里面数字: 5632K: 年轻代收集前大小 496K: 年轻代收集后大小 6144K: 年轻代总大小 5632K: 表示年轻代收集前,占堆大小 2931K: 表示年轻代收集后,占堆大小 19968K: 表示年轻代总大小 user: 用户耗时 sys: 系统耗时 (指的是cpu耗时,在多核的情况下,会大于real耗时) real: 真实耗时(包括,真实等待时间,eg: 磁盘io等待,线程等待)","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://lxchinesszz.github.io/tags/GC/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"忘掉那些所谓的真理，请继续重复发明好轮子","slug":"忘掉那些所谓的真理，请继续重复发明好轮子","date":"2018-04-13T09:39:58.000Z","updated":"2018-04-14T04:40:54.809Z","comments":true,"path":"2018/04/13/忘掉那些所谓的真理，请继续重复发明好轮子/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/13/忘掉那些所谓的真理，请继续重复发明好轮子/","excerpt":"","text":"忘掉那些所谓的真理，请继续重复发明好轮子 作者｜George 编辑｜无明 “重复发明轮子”这句话原本用于比喻无谓的重复劳动，但这个比喻似乎也不那么恰当，因为在人类的历史长河中，轮子已经被重复发明了无数次。 制作轮子的材料在变化，从石头、木头到金属合金、碳纤维。轮子的组成和比例在变化，从厚实饱满、粗糙到精细镂空、带有数百个轮辐。轮胎和轮轴在变化，所以轮子也得重新设计。轮子滚动的路面和使用轮子的机械装置在变化，所以轮子也跟着变。即使是轮子的形状也难逃改变的命运，甚至出现了方形的轮子。 人们之所以如此不厌其烦地重复发明轮子，是因为轮子的用途一直在变。轮子的作用从最开始的节省劳动力到让飞机安全着陆，再到运载具有超级杀伤力的武器。现如今，轮子既可以小到人类感觉不到它们的存在，也可以大到载着巨型坦克在任意路面上行驶，既可以坚固到载着时速 500 公里的高速列车飞驰，也可以智能到让机器人在外星球上行走探险。 重复发明轮子与编程如果把“重复发明轮子”这个比喻放到计算机领域，也不见得太恰当，因为有很多广泛流传的软件本身就是被重复发明的“轮子”，不能说它们是无谓的重复劳动。 Linux 是对 Unix 的重新发明，MariaDB 是对 MySQL（MySQL 是对 PostgreSQL 和 Oracle 的重新发明，而 PostgreSQL 是对 Oracle 的重新发明）的重新发明，现代 C++ 是对老版 C++ 的重新发明，C++ 是对 C 语言（C 语言是对 B 语言的重新发明，而 B 语言是对 BCPL 的重新发明）的重新发明，Rust 是对 C++ 和 C 语言的重新发明，Clojure 是对 LISP 的重新发明，LISP 是对 IPL 和 Lambda Calculus 的重新发明，Haskell 是对 System FC 的重新发明，System FC 是对 System F 的重新发明，System F 是对 Labmda Calculus 的重新发明，DOT 是对 OO 的重新发明，Kotlin 是对 Java 的重新发明……我可以举无数个这样的例子。Vim 是对 Vi 的重新发明，Wayland 是对 Xorg 的重新发明，Ubuntu 是对 Debian 的重新发明。 很多优秀的软件并不只是简单地往已有代码库中添加新特性而已，而是通过不断迭代，创造出比以往更好的东西。GitHub 上很多流行的代码库都有数百个分支，而对于每一类软件工具，我们又有很多不同的选择。 人们经常说“不要重复发明轮子”，但他们忽略了这样的一个事实：大部分优秀的计算机软件实际上就是被重复发明的轮子，而并非是全新的东西。 这些变化是循序渐进的，我们基于已有的概念逐步迭代，慢慢修改它们，让它们变得更好。这是个无穷尽的过程，甚至我们忘记了自己是从哪里出发的，也不知道终点在哪里。我们唯一要付出的是时间，也许这就是计算机编程的神奇之处。在这里，没有所谓的资源短缺，也不管我们如何疯狂，我们总能创造出一些东西。 重复发明轮子不是罪，只是我们要知道在何时以及如何重复发明轮子。 当没有合适的轮子可用时在找不到可用的工具时，就自己开发一个，而不是基于已有的库开发一个不那么好用的“次品”。或许其他人也有同样的需求，那么就可以把你开发的工具分享给他们。自己开发可能需要更长时间，但会更有趣，而且开发出来的工具可能更好用。 当然，具体要怎么做，完全取决于你自己。你可以“勤快”得像某些 C 语言开发者一样，连 list 和 vector 都要自己实现，也可以“懒惰”得像某些 JavaScript 开发者一样，连最简单的判断奇数的函数都要从网上下载（比如日下载量超过十万的“is_odd”包，地址如下： https://www.npmjs.com/package/is-odd。 以 Julia 为例，Julia 是一门与 Python 非常像的编程语言，只是它更容易部署，不需要虚拟环境就可以运行，它运行更快，而且支持大规模的并发。Julia 就是一个被重复发明的轮子，因为从理论上说，它所能做的事情，Cython 也能做到，只要使用恰当的 C/C++ 库，修改一点代码，再加上一点耐心就可以。但 Julia 与生俱来就提供了便利性，为开发人员节省了大量时间，还让开发变得更有趣。或许，它会是 21 世纪最让人瞩目的编程语言之一。 当现有的轮子停滞不前时当很久没有人重复发明轮子，就可以考虑重新发明一个。出现这种情况，可能是因为现在的轮子已经够好了，没必要做出大的改进，但更有可能是因为大多数人希望有更好的轮子，只是他们没有时间去做。比如，有些问题虽然暂时得到了解决，但并不完美，因为当前的技术或框架无法提供更好的解决方案。这就留有余地，等待更好的时机出现。数年之后，或许技术发展到可以更好地解决这些问题。 以图像识别为例，图像识别属于经典的分类器问题。人们在分类器问题上不断努力改进，直到 2010 年，通过使用 Fisher Kernel 这类算法才让分类器得到了非常精确的结果。当然，这些成果还不足以用于检测癌症肿瘤或汽车自动驾驶，从精确度和训练时间方面来看，它们的水平还只是处在鹦鹉和大象之间。直到有人重新发明了并不太流行的卷积神经网络，还使用了现代的 GPU 来训练那些早在 90 年代就开发出来的图像识别模型。2012 年出现了著名的 AlexNet&amp;Co，而几年之后，图像识别技术发展到令人惊诧的地步，在中型数据集上训练出来的分类器甚至可以打败人类。 当轮子受到所有权限制时比如 Linux、GCC 和 Git，它们都是对已有版权软件系统的重新发明。在某些方面，它们比版权软件更好，而且它们是开源的。这意味着有更多的人在使用，有更多的人参与开发，这让它们能够以惊人的速度发展演化。 当你觉得这样做很有趣时对一个已经很完美的软件来一次重新发明，这样做也没什么错。你可能会失败，但你会从中学到很多。尽管别人已经解决了大部分问题，但你仍然能够从解决同样的问题中获得有趣的体验。数百万人想证明勾股定理或重新发明新的 LISP，虽说他们最终不过是在重复发明相似的轮子，但他们所做的并没有什么错，只要他们能够从中获得乐趣。而如果你重新发明的轮子哪怕只是比原先的好那么一点点，都算是在造福人类。 写在后面尽管放手去做吧，重复发明轮子不是罪。如果有人说重复发明轮子是无用功，那就告诉他们，你所做的其实是领域发展的基石。还记得那位在 31 岁就成为硅谷亿万富豪的马斯克吗，他对天体物理学和数学也只是懂点皮毛，却凭着数千万美金就让多国的航天局“颜面扫地”。要知道，这些航天局动不动就有数千亿的资金预算，还有数不清的博士和工程师为他们工作。 马斯克发明了一个更便宜、更强大、更安全、更简便、更快的“轮子”。或许，你也可以开发出一个更直观、更优雅的 JavaScript 库，或者一个更快的 Python 编译器，或者一个更便宜的计算单元，或者一个更好的 Spotify，或者一个更高效的查找表……谁知道呢，一切皆有可能！ 英文原文","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/tags/杂记/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"Netty组件介绍","slug":"Netty组件介绍","date":"2018-04-11T09:39:03.000Z","updated":"2018-04-17T09:51:34.453Z","comments":true,"path":"2018/04/11/Netty组件介绍/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/11/Netty组件介绍/","excerpt":"","text":"在学习Netty之前，建议首先学习一个NIO，对关键的NIO组件有一个清醒认识 Buffer Selector 总览 Bootstrap or ServerBootstrap EventLoop EventLoopGroup ChannelPipeline Future or ChannelFuture ChannelInitializer ChannelHandler ByteToMessageDecoder MessageToByteEncoder ChannelPipline Channel ChannelHandlerContext ServerBootstrap一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。 option() 针对boss线程,用于连接 childOption() 针对work线程,用于处理数据 BootStrap123456789101112131415161718192021222324252627EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .remoteAddress(new InetSocketAddress(host, port)) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new SimpleChannelInboundHandler&lt;ByteBuf&gt;() &#123; //在连接的时候将数据发送给 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.channel().writeAndFlush(request); &#125; //接受信息 @Override protected void messageReceived(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf) throws Exception &#123; result = new byte[byteBuf.readableBytes()]; byteBuf.readBytes(result); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect().sync(); future.addListener(ChannelFutureListener.CLOSE).sync(); EventLoop一个EventLoop可以为多个Channel服务。 EventLoopGroup会包含多个EventLoop ChannelPipeline,ChannelHandler从PipeLine这个单词中可以看出来，是一个管道，处理连接。我们的业务代码handler一般都是放在这个管道中的 那么疑问来了，这个管道中的处理顺序是什么样呢？ 1234ChannelPipeline cp = channel.pipeline(); cp.addLast(\"encoder\", new HttpResponseEncoder());//1.负责输出cp.addLast(\"decoder\", new HttpRequestDecoder());//2.负责把客户端的数据解码cp.addLast(\"handler\", new HttpDispatchServerHandler());//3.自定义的业务处理器 按照我们执行顺序肯定不是根据添加顺序来处理的，应该是:2,把客户端的数据解码-&gt;3.对解码数据处理-&gt;1.加密返回给客户端。 那么 Netty 是怎么处理的呢？ ChannelHandler有两个子类ChannelInboundHandler和ChannelOutboundHandler，这两个类对应了两个数据流向，如果数据是从外部流入我们的应用程序，我们就看做是inbound，相反便是outbound ChannelInitializer顾名思义,这个就是channel初始化的容器，在这个里面设置处理器 123456789101112131415161718192021222324ServerBootstrap bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup();//负责绑定channel到selector workerGroup = new NioEventLoopGroup();//负责从selector中读取事件 bootstrap.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) .localAddress(6969).option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000) .childOption(ChannelOption.SO_KEEPALIVE, true).childHandler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel channel) throws Exception &#123; ChannelPipeline cp = channel.pipeline(); cp.addLast(\"idleStateHandler\", new IdleStateHandler(5, 5, 5, TimeUnit.SECONDS)); cp.addLast(\"decoder\", new HttpRequestDecoder()); cp.addLast(\"encoder\", new HttpResponseEncoder()); cp.addLast(\"aggregator\", new HttpObjectAggregator(1048576)); cp.addLast(\"deflater\", new HttpContentCompressor()); cp.addLast(\"handler\", new HttpDispatchServerHandler()); cp.addLast(\"out\", new AcceptorIdleStateTrigger()); &#125; &#125;).option(ChannelOption.SO_BACKLOG, 128); try &#123; channel = bootstrap.bind().awaitUninterruptibly().channel(); showBanner(6969); &#125; catch (Exception ie) &#123; throw new RuntimeException(ie); &#125; ###ChannelFuture Netty中的连接都可以是异步的，但是也可以设置为非异步 ChannelFutureChannel 每个操作都会返回一个 ChannelFutrue 因为是异步的，所以我们为每个异步的结果，添加一个监听,比如: 12345678# 当完成关闭动作，就执行监听器内容f = f.channel().closeFuture().await(); f.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; System.out.println(\"success complete!!ok!!\"); &#125; &#125;); 当然还有一种方法， 就是await()，此返回会等待上一个操作完成，在进行下一个操作。但是推荐使用第一种。 ByteToMessageDecoder解密器，可以自定义协议，通过集成改接口，重写 decode 方法把二进制，转换为我们系统可以处理的对象 12345678910111213141516171819202122import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.handler.codec.ByteToMessageDecoder;import java.util.List;/** * 把字节转换为int * 继承抽象类ByteToMessageDecoder实现解码器 */public class ByteToIntegerDecoder extends ByteToMessageDecoder &#123; @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; if (in.readableBytes() &gt;= 4) &#123; // Check if there are at least 4 bytes readable int n = in.readInt(); System.err.println(\"ByteToIntegerDecoder decode msg is \" + n); out.add(n); //Read integer from inbound ByteBuf, add to the List of decodec messages &#125; &#125;&#125; 编码器将我们系统处理完的信息，编码成，二进制，传出，给调用者 123456789101112import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.handler.codec.MessageToByteEncoder;public class IntegerToByteEncoder extends MessageToByteEncoder&lt;Integer&gt; &#123; @Override public void encode(ChannelHandlerContext ctx, Integer msg, ByteBuf out) throws Exception &#123; System.err.println(\"IntegerToByteEncoder encode msg is \" + msg); out.writeInt(msg); &#125;&#125; 解码后的数据怎么使用对于加密后的数据，可以直接强制转换为我们解码的对象 123456789public class BusinessHandler extends ChannelInboundHandlerAdapter &#123;trueprivate Logger logger = LoggerFactory.getLogger(BusinessHandler.class);true@Overridetruepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;true//因为我们的解码其中指定是Int类型，所以我们就可以，强制转换为Int，这里为了好理解，假如我们的解码器，中是转换了Person，那么在我们的处理器中就，可以强制换换为PersontruetruePerson person = (Person) msg;truetruelogger.info(\"BusinessHandler read msg from client :\" + person);true&#125; ChannelPipline 管道 管道中包括(ChannleInBoundHandler)入栈的和(ChannelOutBoundHandler)出栈的当连接发生,由ChannelPipline协调将消息给ChannelHandler处理 当一个ChannelHandler被绑定在了多个ChannelPipeline实例上,为了线程安全会报错.要使用@Sharable注解 Channel 消息的传载实体ChannelHandlerContext ChannelHandlerContext将Channel和ChannelHandler做一个关联因为一个Channel可能与多个ChannelHandler绑定 注意ChannelHandler与下一个ChannelHandler…的交互并不是他们直接产生的,而是有ChannelHandlerContext调用的 从中学习到一个编程技巧,就是当一个实体与多个处理器产生关系的时候,可以定义一个上下文,用来管理关系","categories":[{"name":"通信","slug":"通信","permalink":"https://lxchinesszz.github.io/categories/通信/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/tags/Netty/"}],"keywords":[{"name":"通信","slug":"通信","permalink":"https://lxchinesszz.github.io/categories/通信/"}]},{"title":"SpringBoot整合Data-Jpa","slug":"SpringBoot整合Data-Jpa","date":"2018-01-12T08:00:43.000Z","updated":"2018-04-14T04:38:53.464Z","comments":true,"path":"2018/01/12/SpringBoot整合Data-Jpa/","link":"","permalink":"https://lxchinesszz.github.io/2018/01/12/SpringBoot整合Data-Jpa/","excerpt":"","text":"最近开辟了一个新项目,因为初期考虑到可能会调整数据库的风险,所以orm,在设计之初就考虑为Spring Data Jpa, 以下是工程data层数据,整体是参照配置多数据源的方案,进行配置的 目录 因为阿里数据源Druid 整合数据源及其他事务配置 pom依赖 整合QueryDSl 整合事务123456789@EnableAutoConfiguration@SpringBootApplication@EnableTransactionManagement@ComponentScan(basePackages = &#123;\"com.inn.developer\"&#125;)public class CodeApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder().web(true).sources(CodeApplication.class).run(args); &#125;&#125; 创建DruidProperties配置123456@Data@AllArgsConstructor@NoArgsConstructor@ConfigurationProperties(prefix = \"druid\")public class DruidProperties &#123;... 数据库参数可以参考: 参数 默认值 解释 initialSize 3 初始化配置 minIdle 3 最小连接数 maxActive 15 最大连接数 maxWait 5000 获取连接超时时间（单位：ms） timeBetweenEvictionRunsMillis 90000 连接有效性检测时间(单位:ms) testOnBorrow false 获取连接检测 testOnReturn false 归还连接检测 minEvictableIdleTimeMillis 1800000 最大空闲时间(单位ms) testWhileIdle true 在获取连接后，确定是否要进行连接空间时间的检查 配置说明： 1：minEvictableIdleTimeMillis(最大空闲时间)：默认为30分钟，配置里面不进行设置。 2：testOnBorrow ,testOnReturn 默认为关闭，可以设置为不配置。 3：testWhileIdle(在获取连接后，确定是否要进行连接空闲时间的检查)。默认为true。配置里面不再进行设置。 流程说明： 1：在第一次调用connection的时候，才会进行 initialSize的初始化。 2：心跳检测时间线程，会休眠timeBetweenEvictionRunsMillis时间，然后只对(没有borrow的线程 减去 minIdle)的线程进行检查，如果空闲时间大于minEvictableIdleTimeMillis则进行close。 3：testWhileIdle必须设置为true，在获取到连接后，先检查testOnBorrow，然后再判定testwhileIdle，如果连接空闲时间大于timeBetweenEvictionRunsMillis，则会进行心跳检测。 4：不需要配置validationQuery，如果不配置的情况下会走ping命令，性能更高。 5：连接保存在数组里面，获取连接的时候，获取数组的最后一位。在imeBetweenEvictionRunsMillis时是从前往后进行检查连接的有效性。 配置数据源及hibernate适配数据源对象创建还是和之前一样,笔者不太喜欢xml的方式,所以还是采用配置类 DruidAutoJpaConfiguration 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Configuration@EnableConfigurationProperties(DruidProperties.class)//开启属性注入,通过@autowired注入@ConditionalOnClass(DruidDataSource.class)//表示对应的类在classpath目录下存在时，才会去解析对应的配置文件@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@EnableJpaRepositories(basePackages = \"com.inn.developer.model.dao\",transactionManagerRef = \"jpaTransactionManager\", entityManagerFactoryRef = \"localContainerEntityManagerFactoryBean\")public class DruidAutoJpaConfiguration &#123; @Autowired private DruidProperties properties; @Bean(name = \"druidDataSource\") @Primary public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); dataSource.setValidationQuery(\"select version()\"); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125; /** * hibernate 适配器,定制方言为mysql,并打印sql * * @return */ @Bean(name = \"hibernateJpaVendorAdapter\") @Primary public HibernateJpaVendorAdapter hibernateJpaVendorAdapter() &#123; HibernateJpaVendorAdapter hibernateJpaVendorAdapter = new HibernateJpaVendorAdapter(); hibernateJpaVendorAdapter.setShowSql(true); hibernateJpaVendorAdapter.setDatabasePlatform(\"org.hibernate.dialect.MySQL5Dialect\"); return hibernateJpaVendorAdapter; &#125; @Bean(name = \"localContainerEntityManagerFactoryBean\") @Primary public LocalContainerEntityManagerFactoryBean entityManagerFactoryBean(@Qualifier(\"druidDataSource\") DataSource dataSource ,@Qualifier(\"hibernateJpaVendorAdapter\") HibernateJpaVendorAdapter hibernateJpaVendorAdapter) &#123; LocalContainerEntityManagerFactoryBean local = new LocalContainerEntityManagerFactoryBean(); local.setDataSource(dataSource); local.setJpaVendorAdapter(hibernateJpaVendorAdapter); local.setPackagesToScan(\"com.inn.developer.model.domain\"); Properties properties = new Properties(); properties.put(\"hibernate.format_sql\", true); properties.put(\"hibernate.hbm2ddl.auto\", \"update\"); local.setJpaProperties(properties); return local; &#125; @Bean(name = \"jpaTransactionManager\") @Primary public JpaTransactionManager jpaTransactionManager(@Qualifier(\"localContainerEntityManagerFactoryBean\") LocalContainerEntityManagerFactoryBean entityManagerFactoryBean) &#123; JpaTransactionManager jpaTransactionManager = new JpaTransactionManager(); EntityManagerFactory object = entityManagerFactoryBean.getObject(); jpaTransactionManager.setEntityManagerFactory(object); return jpaTransactionManager; &#125; pom依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.11&lt;/version&gt; &lt;/dependency&gt; &lt;!--依赖Spring 4.3.6之core、context、aop、beans、tx、orm和spring data commons --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.11.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--hibernate 实现JPA的框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;5.2.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;5.2.11.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-annotations --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-annotations&lt;/artifactId&gt; &lt;version&gt;3.5.6-Final&lt;/version&gt; &lt;/dependency&gt; 整合QueryDSLpom依赖1234567891011&lt;!--引入query-dsl--&gt; &lt;dependency&gt; &lt;groupId&gt;com.querydsl&lt;/groupId&gt; &lt;artifactId&gt;querydsl-apt&lt;/artifactId&gt; &lt;version&gt;$&#123;querydsl.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.querydsl&lt;/groupId&gt; &lt;artifactId&gt;querydsl-jpa&lt;/artifactId&gt; &lt;version&gt;$&#123;querydsl.version&#125;&lt;/version&gt; &lt;/dependency&gt; 插件 123456789101112131415161718&lt;!--引入queryDsl:https://spring.io/blog/2011/04/26/advanced-spring-data-jpa-specifications-and-querydsl/--&gt; &lt;plugin&gt; &lt;groupId&gt;com.mysema.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-apt-plugin&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;process&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;target/generated-sources&lt;/outputDirectory&gt; &lt;processor&gt;com.querydsl.apt.jpa.JPAAnnotationProcessor&lt;/processor&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 使用方法,继承JpaSpecificationExecutor或QueryDslPredicateExecutor123@Repositorypublic interface IUserJpaDslReponsitory extends CrudRepository&lt;User, Long&gt;, JpaSpecificationExecutor&lt;User&gt;,QueryDslPredicateExecutor&lt;User&gt; &#123;&#125; 注意点:使用插件后,要mvn compile编译生成Q+entityName,不需要移动到项目","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"StringBoot集成Rabbit根据业务返回ACK","slug":"StringBoot集成Rabbit根据业务返回ACK","date":"2018-01-12T07:56:28.000Z","updated":"2018-04-14T04:40:17.647Z","comments":true,"path":"2018/01/12/StringBoot集成Rabbit根据业务返回ACK/","link":"","permalink":"https://lxchinesszz.github.io/2018/01/12/StringBoot集成Rabbit根据业务返回ACK/","excerpt":"","text":"为了维护消息的有效性，当消费消息时候处理失败时候，不进行消费，需要我们根据业务区返回ACK，本项目我使用Redis和ack机制双重保险,保障消息一定能够正确的消费 首先,接着上部分内容，使用Topic,机制(不明白的,可以回顾上部分内容) 上部分内容，我们使用SpringBoot注解,去实现，但是控制权不完全账务，当进行大规模项目时候，不太建议使用 1234567891011@RabbitListener(queues = TopicRabbitConfig.USER_QUEUE) @RabbitHandler public void processUser(String message) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; logger.info(\"用户侧流水:&#123;&#125;\",message); &#125; &#125;); &#125; 根据源码分析，当然这里不分析源码，有兴趣的可以多失败几次就ok明白了 在配置类中定义监听器，监听这个序列（AcknowledgeMode.MANUAL是必须的哦） 1234567891011121314151617/** * 接受消息的监听，这个监听客户交易流水的消息 * 针对消费者配置 * @return */@Beanpublic SimpleMessageListenerContainer messageContainer1(ConnectionFactory connectionFactory, TransactionConsumeImpl transactionConsume) &#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); container.setQueues(queueMessage()); container.setExposeListenerChannel(true); container.setMaxConcurrentConsumers(1); container.setConcurrentConsumers(1); container.setAcknowledgeMode(AcknowledgeMode.MANUAL); //设置确认模式手工确认 container.setMessageListener(transactionConsume); return container;&#125; 这个 TransactionConsumeImpl 要继承ChannelAwareMessageListener，主要说的手动返回ACK就是channel。调用 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class TransactionConsumeImpl implements ChannelAwareMessageListener &#123; private static final Logger logger = LoggerFactory.getLogger(TransactionConsumeImpl.class); private static final Gson gson = new Gson(); @Autowired JedisShardInfo jedisShardInfo; @Autowired ExecutorService threadPool; @Autowired BoluomeFlowService boluomeFlowService; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; String boby = new String(message.getBody(), \"utf-8\");//转换消息，我们是使用json数据格式 threadPool.execute(new Runnable() &#123; //多线程处理 @Override public void run() &#123; Jedis jedis = jedisShardInfo.createResource(); jedis.sadd(TopicRabbitConfig.TRANSACTION_QUEUE, boby);//添加到key为当前消息类型的集合里面，防止丢失消息 BoluomeFlow flow = gson.fromJson(boby, BoluomeFlow.class); String json = gson.toJson(flow); if (boluomeFlowService.insert(flow)) &#123; //当添加成功时候返回成功 logger.info(\"客户交易流水添加1条记录:&#123;&#125;\", json); jedis.srem(TopicRabbitConfig.TRANSACTION_QUEUE, boby);//从当前消息类型集合中移除已经消费过的消息 try &#123; channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);//手工返回ACK，通知此消息已经争取消费 &#125; catch (IOException ie) &#123; logger.error(\"消费成功回调成功，io操作异常\"); &#125; &#125; else &#123; logger.info(\"客户交易流水添加失败记录:&#123;&#125;\", json); &#125; &#125; &#125;); &#125;&#125; 12channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); // 消息的标识，false只确认当前一个消息收到，true确认所有consumer获得的消息channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true); // ack返回false，并重新回到队列，api里面解释得很清楚 channel.basicReject(message.getMessageProperties().getDeliveryTag(), true); // 拒绝消息 true 发送给下一个消费者 false 谁都不接受，从队列中删除","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot整合Sentry监控项目日志","slug":"SpringBoot整合Sentry监控项目日志","date":"2018-01-12T07:47:41.000Z","updated":"2018-04-13T09:51:15.116Z","comments":true,"path":"2018/01/12/SpringBoot整合Sentry监控项目日志/","link":"","permalink":"https://lxchinesszz.github.io/2018/01/12/SpringBoot整合Sentry监控项目日志/","excerpt":"","text":"Sentry Java版使用简介基本概念Sentry是什么Sentry 是一个开源的实时错误报告工具，支持 web 前后端、移动应用以及游戏，支持 Python、OC、Java、Go、Node、Django、RoR 等主流编程语言和框架 ，还提供了 GitHub、Slack、Trello 等常见开发工具的集成。 DSN（Data Source Name）Sentry 服务支持多用户、多团队、多应用管理，每个应用都对应一个 PROJECT_ID，以及用于身份认证的 PUBLIC_KEY 和 SECRET_KEY。由此组成一个这样的 DSN： ‘{PROTOCOL}://{PUBLIC_KEY}:{SECRET_KEY}@{HOST}/{PATH}{PROJECT_ID}’ PROTOCOL 通常会是 http 或者 https，HOST 为 Sentry 服务的主机名和端口，PATH 通常为空。为方便管理，每个应用生成一个 DSN，具体可咨询虎大师 或者 我。 使用 Sentry SDKSentry 的 SDK 通常在各语言的包管理器中成为 Raven，使用起来也非常简单。以 Java版本为例（使用SpringBoot框架）： 1.首先项目中pom文件安装 Raven 1234567 &lt;!--导入Sentry--&gt; &lt;dependency&gt; &lt;groupId&gt;com.getsentry.raven&lt;/groupId&gt; &lt;artifactId&gt;raven-logback&lt;/artifactId&gt; &lt;version&gt;8.0.2&lt;/version&gt;&lt;/dependency&gt; 2.在项目配置文件中建立logback.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;configuration&gt; &lt;!-- 彩色日志 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(--)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt;/&gt; &lt;appender name=\"Console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--&lt;pattern&gt; %d&#123;YYYY-MM-dd HH:mm:ss.SSS&#125; [%-5level] -&amp;#45;&amp;#45; %logger&#123;36&#125; [%thread] \\t- %msg%n%nopex&lt;/pattern&gt;--&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"Sentry\" class=\"com.getsentry.raven.logback.SentryAppender\"&gt; &lt;!--每个项目生成不通的key--&gt; &lt;dsn&gt;http://d73b23c481654b9ca0e4e8a9db310169:daaf5dc2edef462690791ef324316738@sentry.boluome.com/7&lt;/dsn&gt; &lt;!-- 设置拦截的最低级别为warn 警告--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;logger name=\"logback.SentryAppenderIT\" level=\"INFO\"&gt; &lt;appender-ref ref=\"Sentry\"/&gt; &lt;/logger&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"Console\"/&gt; &lt;appender-ref ref=\"Sentry\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 3.application.propertes中添加导入日志配置【主要要提前在pom文件中添加包含*.xml，否则会报错,not found file】 logging.config=classpath:logback.xml 4.接口层,正常使用logger等方法。Raven会自动把warn级别通过tcp发送到日志中心，并通知相关人员查看信息 12345@RequestMapping(value = \"/testlog\", method = RequestMethod.GET) public void testLog() &#123; logger.info(\"test接口\");//最低拦截级别为warn，所以info不会输出发送到日志中心 logger.error(\"error\"); //会显示在日志中心，并邮件通知相关联系人 &#125; 这样就可以使用 Raven 对象向 Sentry 服务器中提交日志信息了。 使用 Sentry web 服务主要是登录后台查看，后续有时间更新此部分文档。开通账号可找虎大师。 附录sentry 官方文档 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!-- scan=\"true\" 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 --&gt;&lt;!-- scanPeriod=\"30 seconds\" 设置每30秒自动扫描,若没有指定具体单位则以milliseconds为标准(单位:milliseconds, seconds, minutes or hours) --&gt;&lt;!-- debug=\"false\"当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;&lt;configuration scan=\"true\" scanPeriod=\"30 seconds\"&gt; &lt;!-- 上下文名称 --&gt; &lt;contextName&gt;test&lt;/contextName&gt; &lt;!-- 存放日志文件路径 --&gt; &lt;property name=\"Log_Home\" value=\"mylogs/test\"/&gt; &lt;!-- ch.qos.logback.core.ConsoleAppender 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 --&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- DEBUG级别 --&gt; &lt;appender name=\"FILE_DEBUG\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/debug/debug.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/debug/debug.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- INFO级别 --&gt; &lt;appender name=\"FILE_INFO\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/info/info.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/info/info.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- WARN级别 --&gt; &lt;appender name=\"FILE_WARN\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/warn/warn.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/warn/warn.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- ERROR级别 --&gt; &lt;appender name=\"FILE_ERROR\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 设置过滤级别 --&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;!-- 用于配置符合过滤条件的操作 --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 用于配置不符合过滤条件的操作 --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;Encoding&gt;UTF-8&lt;/Encoding&gt; &lt;File&gt;$&#123;Log_Home&#125;/error/error.log&lt;/File&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt; $&#123;Log_Home&#125;/error/error.%d&#123;yyyy-MM-dd&#125;.%i.log &lt;/FileNamePattern&gt; &lt;!-- 多久后自动清楚旧的日志文件,单位:月 --&gt; &lt;MaxHistory&gt;1&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- 默认值是 10MB,文档最大值 --&gt; &lt;MaxFileSize&gt;2MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;Pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 控制java下面包的打印,没设置等级,将继承上级root的等级 --&gt; &lt;logger name=\"rattlesnake.callback\"/&gt; &lt;!-- 当前日志总级别为TRACE、DEBUG、INFO、 WARN、ERROR、ALL和 OF --&gt; &lt;!-- the level of the root level is set to DEBUG by default. --&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"STDOUT\"/&gt; &lt;appender-ref ref=\"FILE_DEBUG\"/&gt; &lt;appender-ref ref=\"FILE_INFO\"/&gt; &lt;appender-ref ref=\"FILE_WARN\"/&gt; &lt;appender-ref ref=\"FILE_ERROR\"/&gt; &lt;/root&gt;&lt;/configuration&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot定义事件和监听器","slug":"SpringBoot定义事件和监听器","date":"2017-09-12T07:58:43.000Z","updated":"2018-04-14T04:38:47.621Z","comments":true,"path":"2017/09/12/SpringBoot定义事件和监听器/","link":"","permalink":"https://lxchinesszz.github.io/2017/09/12/SpringBoot定义事件和监听器/","excerpt":"","text":"继承事件 ApplicationEvent 定义监听 ApplicationListener 继承事件 ApplicationEvent1234567891011121314151617181920212223public class EmailEvent extends ApplicationEvent &#123; /** * &lt;p&gt;Description：&lt;/p&gt; */ private static final long serialVersionUID = 1L; public String address; public String text; public EmailEvent(Object source) &#123; super(source); &#125; public EmailEvent(Object source, String address, String text) &#123; super(source); this.address = address; this.text = text; &#125; public void print()&#123; System.out.println(\"hello spring event!\"); &#125;&#125; 定义监听 ApplicationListener123456789101112131415@Componentpublic class EmailListener implements ApplicationListener&#123; public void onApplicationEvent(ApplicationEvent event) &#123; if(event instanceof EmailEvent)&#123; EmailEvent emailEvent = (EmailEvent)event; emailEvent.print(); System.out.println(\"the source is:\"+emailEvent.getSource()); System.out.println(\"the address is:\"+emailEvent.address); System.out.println(\"the email's context is:\"+emailEvent.text); &#125; &#125;&#125; 代码测试12345public static void main(String[] args) &#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(Application.class, args); EmailEvent emailEvent=new EmailEvent(\"hello\",\"lxchinesszz@163.com\",\"this is a email text\"); applicationContext.publishEvent(emailEvent); &#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot之自定义Servlet","slug":"SpringBoot之自定义Servlet","date":"2017-07-12T07:56:57.000Z","updated":"2018-04-14T04:38:14.337Z","comments":true,"path":"2017/07/12/SpringBoot之自定义Servlet/","link":"","permalink":"https://lxchinesszz.github.io/2017/07/12/SpringBoot之自定义Servlet/","excerpt":"","text":"生产中我们有时候需要自定义servlet比如,对一些特定的资源路径进来的请求,做一些特殊处理，本文，介绍两种自定义的方法。 目录 @WebServlet 注解方式 注册ServletRegistrationBean 1.@WebServlet 注解方式使用该方式注意一点，就是要与 @ServletComponentScan 配合使用 123456789101112131415161718@WebServlet(urlPatterns = \"/api\", description = \"api进来的通过该servlet\")public class ApiGateWayServlet extends HttpServlet &#123; private ApplicationContext applicationContext; private ApiGateWayHandler apiGateWayHandler; @Override public void init() throws ServletException &#123; super.init(); applicationContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); apiGateWayHandler = applicationContext.getBean(ApiGateWayHandler.class); &#125; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; apiGateWayHandler.handle(req,resp); &#125;&#125; 在启动类，添加ServeltComponentScan 123456789@ServletComponentScan@SpringBootApplicationpublic class SpringBootSampleApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext configurableApplicationContext = SpringApplication.run(SpringBootSampleApplication.class, args); SpringContextUtils.setApplicationContext(configurableApplicationContext); &#125;&#125; 2. 注册ServletRegistrationBean1234567891011@SpringBootApplicationpublic class SpringBootSampleApplication &#123; @Bean public ServletRegistrationBean servletRegistrationBean() &#123; return new ServletRegistrationBean(new ApiGateWayServlet(), \"/*\"); &#125; public static void main(String[] args) &#123; ConfigurableApplicationContext configurableApplicationContext = SpringApplication.run(SpringBootSampleApplication.class, args); SpringContextUtils.setApplicationContext(configurableApplicationContext); &#125;&#125; 3.check是否配置成功122017-09-19 10:44:28.313 INFO 6761 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: 'apiGateWayServlet' to [/*]2017-09-19 10:44:28.315 INFO 6761 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/]","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot中JMX-RPC-JNDI关键字解释","slug":"SpringBoot中JMX-RPC-JNDI关键字解释","date":"2017-06-12T07:59:48.000Z","updated":"2018-04-14T04:37:57.383Z","comments":true,"path":"2017/06/12/SpringBoot中JMX-RPC-JNDI关键字解释/","link":"","permalink":"https://lxchinesszz.github.io/2017/06/12/SpringBoot中JMX-RPC-JNDI关键字解释/","excerpt":"","text":"SpringBoot中JMX监控 SpringBoot自带调用JMX监控 rpc协议 rmi 远程方法调用 JMX Jndi rpc（Remote Procedure Call ProtocolRPC（Remote Procedure Call Protocol）——远程过程调用协议 rmi (Remote Method Invocation)RMI:远程方法调用(Remote Method Invocation)。能够让在某个java虚拟机上的对象像调用本地对象一样调用另一个java 虚拟机中的对象上的方法。 JMX （Java Management）JMX是“Java管理扩展的（Java Management Extensions）”的缩写，是一种类似J2EE的规范，这样就可以灵活的扩展系统的监控、管理功能。实时监控RPC服务器线程池任务的执行情况，具体JMX监控度量线程池关键指标代码 比如jndi (Java Naming and Directory Interface）JNDI(Java Naming and Directory Interface,Java命名和目录接口)是SUN公司提供的一种标准的Java命名系统接口，JNDI提供统一的客户端API，通过不同的访问提供者接口 通过目录，定义到接口比如，com.mysql.jdbc.Driver这个是一个约束性的 在JBoss的 D:/jboss420GA/docs/examples/jca 文件夹下面，有很多不同数据库引用的数据源定义模板 Get Ready在BookPub应用的pom文件中添加jolokia-core依赖 12345&lt;!-- JMX monitor --&gt;&lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot多数据源配置事务","slug":"SpringBoot多数据源配置事务","date":"2017-06-12T07:55:09.000Z","updated":"2018-04-14T04:38:44.226Z","comments":true,"path":"2017/06/12/SpringBoot多数据源配置事务/","link":"","permalink":"https://lxchinesszz.github.io/2017/06/12/SpringBoot多数据源配置事务/","excerpt":"","text":"在多数据源中配置事务，其实对于SpringBoot来很简单，当然这个的前提是首先把多数据源都配好的情况下，如果不会多数据源配置，请看该系列 SpringBoot整合多数据源 首先在启动类配置 12345678@SpringBootApplication@EnableTransactionManagementpublic class AccountApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AccountApplication.class, args); &#125;&#125; 当配置了这个事务注解，会自动去加载我们的事务Bean。 配置多个事务 事务1 123456@Bean(name = \"accountTransactionManager\") @Primary public PlatformTransactionManager testTransactionManager(@Qualifier(\"accountDataSource\") DataSource dataSource) &#123; DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(dataSource); return dataSourceTransactionManager; &#125; 事务2 12345@Bean(name = \"otoSaaSTransactionManager\")public PlatformTransactionManager testTransactionManager(@Qualifier(\"otoSaaSDataSource\") DataSource dataSource) &#123; DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(dataSource); return dataSourceTransactionManager;&#125; 这个是时候就可以指定用哪个事务处理 使用事务1 12345@Override@Transactional(value = \"accountTransactionManager\",rollbackFor = Exception.class)public boolean insertAddMoney(String account, String quota) &#123; ...&#125; 使用事务2 12345@Override@Transactional(value = \"otoSaaSTransactionManager\",rollbackFor = Exception.class)public boolean insertAddMoney(String account, String quota) &#123; ...&#125; 那么此时就产生了一个疑惑，在多数据源和事务管理器中，如果不指定默认返回的事务呢？怎么配置默认事务处理器呢？很简。添加一个配置类，实现 TransactionManagementConfigurer重写 annotationDrivenTransactionManager 方法 返回默认返回的处理器，就OK 12345678910111213141516171819202122232425262728293031@Configuration // 开启注解事务管理，等同于xml配置文件中的 &lt;tx:annotation-driven /&gt;public class AccountApplication implements TransactionManagementConfigurer &#123; @Resource(name=\"txManager2\") private PlatformTransactionManager txManager2; // 创建事务管理器1 @Bean(name = \"txManager1\") public PlatformTransactionManager txManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; // 创建事务管理器2 @Bean(name = \"txManager2\") public PlatformTransactionManager txManager2(EntityManagerFactory factory) &#123; return new JpaTransactionManager(factory); &#125; // 实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器 @Override public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return txManager2; &#125; public static void main(String[] args) &#123; SpringApplication.run(AccountApplication.class, args); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot动态修改日志级别","slug":"SpringBoot动态修改日志级别","date":"2017-06-12T07:51:05.000Z","updated":"2018-04-14T04:38:34.004Z","comments":true,"path":"2017/06/12/SpringBoot动态修改日志级别/","link":"","permalink":"https://lxchinesszz.github.io/2017/06/12/SpringBoot动态修改日志级别/","excerpt":"","text":"SpringBoot1.5新特性目录 安装依赖 测试显示日志级别 测试修改日志级别 1.在pom中添加依赖1234567891011121314151617&lt;parent&gt;true&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;true&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;true&lt;version&gt;1.5.1.RELEASE&lt;/version&gt;true&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt;true&lt;dependency&gt;truetrue&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;truetrue&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;true&lt;/dependency&gt;true&lt;dependency&gt;truetrue&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;truetrue&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;true&lt;/dependency&gt;&lt;/dependencies&gt; 2.开始测试http://localhost:8080/loggers 服务: 1s.b.a.e.m.MvcEndpointSecurityInterceptor : Full authentication is required to access actuator endpoints. Consider adding Spring Security or set 'management.security.enabled' to false. 需要手动设置management.security.enabled=false 继续测试 http://localhost:8080/loggers 服务返回: 12345678910111213141516171819&#123;levels: [\"OFF\",\"ERROR\",\"WARN\",\"INFO\",\"DEBUG\",\"TRACE\"],loggers: &#123;ROOT: &#123;configuredLevel: \"INFO\",effectiveLevel: \"INFO\"&#125;,elephant: &#123;configuredLevel: \"DEBUG\",effectiveLevel: \"DEBUG\"&#125;,... 3.修改日志级别POST请求http://localhost:8080/loggers/{elephant} {}中根据/loggers方法返回的目录级别添加 eg: 我要修改elephant.zybank.rest目录下级别 就使用下面请求方法 http://localhost:8080/loggers/elephant.zybank.rest 请求体中使用json 123&#123; \"configuredLevel\": \"DEBUG\"&#125; 登录服务器1234567curl -H \"Content-Type: application/json\" -X POST --data '&#123; \"configuredLevel\": \"DEBUG\"&#125;' http://localhost:8080/loggers/elephant.zybank.rest","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot使用Async实现异步调用","slug":"SpringBoot中使用-Async实现异步调用","date":"2017-06-12T07:27:59.000Z","updated":"2018-04-14T04:38:04.525Z","comments":true,"path":"2017/06/12/SpringBoot中使用-Async实现异步调用/","link":"","permalink":"https://lxchinesszz.github.io/2017/06/12/SpringBoot中使用-Async实现异步调用/","excerpt":"","text":"本文引用地址大神程序员DD link 什么是“异步调用”？ “异步调用”对应的是“同步调用”，同步调用指程序按照定义顺序依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用指程序在顺序执行时，不等待异步调用的语句返回结果就执行后面的程序。 同步调用下面通过一个简单示例来直观的理解什么是同步调用： 定义Task类，创建三个处理函数分别模拟三个执行任务的操作，操作消耗时间随机取（10秒内） 12345678910111213141516171819202122232425@Componentpublic class Task &#123; public static Random random =new Random(); public void doTaskOne() throws Exception &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务一，耗时：\" + (end - start) + \"毫秒\"); &#125; public void doTaskTwo() throws Exception &#123; System.out.println(\"开始做任务二\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：\" + (end - start) + \"毫秒\"); &#125; public void doTaskThree() throws Exception &#123; System.out.println(\"开始做任务三\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务三，耗时：\" + (end - start) + \"毫秒\"); &#125;&#125; 在单元测试用例中，注入Task对象，并在测试用例中执行doTaskOne、doTaskTwo、doTaskThree三个函数 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = Application.class)public class ApplicationTests &#123;true@Autowiredtrueprivate Task task;true@Testtruepublic void test() throws Exception &#123;truetruetask.doTaskOne();truetruetask.doTaskTwo();truetruetask.doTaskThree();true&#125;&#125; 执行单元测试，可以看到类似如下输出： 123456开始做任务一完成任务一，耗时：4256毫秒开始做任务二完成任务二，耗时：4957毫秒开始做任务三完成任务三，耗时：7173毫秒 任务一、任务二、任务三顺序的执行完了，换言之doTaskOne、doTaskTwo、doTaskThree三个函数顺序的执行完成。 异步调用上述的同步调用虽然顺利的执行完了三个任务，但是可以看到执行时间比较长，若这三个任务本身之间不存在依赖关系，可以并发执行的话，同步调用在执行效率方面就比较差，可以考虑通过异步调用的方式来并发执行。 在Spring Boot中，我们只需要通过使用@Async注解就能简单的将原来的同步函数变为异步函数，Task类改在为如下模式： 123456789101112131415@Componentpublic class Task &#123; @Async public void doTaskOne() throws Exception &#123; // 同上内容，省略 &#125; @Async public void doTaskTwo() throws Exception &#123; // 同上内容，省略 &#125; @Async public void doTaskThree() throws Exception &#123; // 同上内容，省略 &#125;&#125; 为了让@Async注解能够生效，还需要在Spring Boot的主程序中配置@EnableAsync，如下所示： 1234567@SpringBootApplication@EnableAsyncpublic class Application &#123;truepublic static void main(String[] args) &#123;truetrueSpringApplication.run(Application.class, args);true&#125;&#125; 此时可以反复执行单元测试，您可能会遇到各种不同的结果，比如： 没有任何任务相关的输出 有部分任务相关的输出 乱序的任务相关的输出原因是目前doTaskOne、doTaskTwo、doTaskThree三个函数的时候已经是异步执行了。主程序在异步调用之后，主程序并不会理会这三个函数是否执行完成了，由于没有其他需要执行的内容，所以程序就自动结束了，导致了不完整或是没有输出任务相关内容的情况。 注： @Async所修饰的函数不要定义为static类型，这样异步调用不会生效异步回调为了让doTaskOne、doTaskTwo、doTaskThree能正常结束，假设我们需要统计一下三个任务并发执行共耗时多少，这就需要等到上述三个函数都完成调动之后记录时间，并计算结果。 那么我们如何判断上述三个异步调用是否已经执行完成呢？我们需要使用Future来返回异步调用的结果，就像如下方式改造doTaskOne函数： 123456789@Asyncpublic Future&lt;String&gt; doTaskOne() throws Exception &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(\"完成任务一，耗时：\" + (end - start) + \"毫秒\"); return new AsyncResult&lt;&gt;(\"任务一完成\");&#125; 按照如上方式改造一下其他两个异步函数之后，下面我们改造一下测试用例，让测试在等待完成三个异步调用之后来做一些其他事情。 12345678910111213141516@Testpublic void test() throws Exception &#123;truelong start = System.currentTimeMillis();trueFuture&lt;String&gt; task1 = task.doTaskOne();trueFuture&lt;String&gt; task2 = task.doTaskTwo();trueFuture&lt;String&gt; task3 = task.doTaskThree();truewhile(true) &#123;truetrueif(task1.isDone() &amp;&amp; task2.isDone() &amp;&amp; task3.isDone()) &#123;truetruetrue// 三个任务都调用完成，退出循环等待truetruetruebreak;truetrue&#125;truetrueThread.sleep(1000);true&#125;truelong end = System.currentTimeMillis();trueSystem.out.println(\"任务全部完成，总耗时：\" + (end - start) + \"毫秒\");&#125; 看看我们做了哪些改变： 在测试用例一开始记录开始时间 在调用三个异步函数的时候，返回Future类型的结果对象 在调用完三个异步函数之后，开启一个循环，根据返回的Future对象来判断三个异步函数是否都结束了。若都结束，就结束循环；若没有都结束，就等1秒后再判断。 跳出循环之后，根据结束时间 - 开始时间，计算出三个任务并发执行的总耗时。执行一下上述的单元测试，可以看到如下结果： 执行一下上述的单元测试，可以看到如下结果： 1234567开始做任务一开始做任务二开始做任务三完成任务三，耗时：37毫秒完成任务二，耗时：3661毫秒完成任务一，耗时：7149毫秒任务全部完成，总耗时：8025毫秒 异步调用的异常处理 在异步方法中，如果出现异常，对于调用者caller而言，是无法感知的。如果确实需要进行异常处理，则按照如下方法来进行处理： 1. 自定义实现AsyncTaskExecutor的任务执行器 在这里定义处理具体异常的逻辑和方式。 2. 配置由自定义的TaskExecutor替代内置的任务执行器 示例步骤1，自定义的TaskExecutor 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ExceptionHandlingAsyncTaskExecutor implements AsyncTaskExecutor &#123; private AsyncTaskExecutor executor; public ExceptionHandlingAsyncTaskExecutor(AsyncTaskExecutor executor) &#123; this.executor = executor; &#125; ////用独立的线程来包装，@Async其本质就是如此 public void execute(Runnable task) &#123; executor.execute(createWrappedRunnable(task)); &#125; public void execute(Runnable task, long startTimeout) &#123; /用独立的线程来包装，@Async其本质就是如此 executor.execute(createWrappedRunnable(task), startTimeout); &#125; public Future submit(Runnable task) &#123; return executor.submit(createWrappedRunnable(task)); //用独立的线程来包装，@Async其本质就是如此。 &#125; public Future submit(final Callable task) &#123; //用独立的线程来包装，@Async其本质就是如此。 return executor.submit(createCallable(task)); &#125; private Callable createCallable(final Callable task) &#123; return new Callable() &#123; public T call() throws Exception &#123; try &#123; return task.call(); &#125; catch (Exception ex) &#123; handle(ex); throw ex; &#125; &#125; &#125;; &#125; private Runnable createWrappedRunnable(final Runnable task) &#123; return new Runnable() &#123; public void run() &#123; try &#123; task.run(); &#125; catch (Exception ex) &#123; handle(ex); &#125; &#125; &#125;; &#125; private void handle(Exception ex) &#123; //具体的异常逻辑处理的地方 System.err.println(\"Error during @Async execution: \" + ex); &#125; &#125; 分析： 可以发现其是实现了AsyncTaskExecutor, 用独立的线程来执行具体的每个方法操作。在createCallable和createWrapperRunnable中，定义了异常的处理方式和机制。handle()就是未来我们需要关注的异常处理的地方。 @Async调用中的事务处理机制 在@Async标注的方法，同时也适用了@Transactional进行了标注；在其调用数据库操作之时，将无法产生事务管理的控制，原因就在于其是基于异步处理的操作。 那该如何给这些操作添加事务管理呢？可以将需要事务管理操作的方法放置到异步方法内部，在内部被调用的方法上添加@Transactional. 例如： 方法A，使用了@Async/@Transactional来标注，但是无法产生事务控制的目的。 方法B，使用了@Async来标注， B中调用了C、D，C/D分别使用@Transactional做了标注，则可实现事务控制的目的。","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot第三方配置绑定","slug":"SpringBoot第三方配置绑定","date":"2017-05-22T05:53:53.000Z","updated":"2018-04-14T04:39:23.398Z","comments":true,"path":"2017/05/22/SpringBoot第三方配置绑定/","link":"","permalink":"https://lxchinesszz.github.io/2017/05/22/SpringBoot第三方配置绑定/","excerpt":"","text":"使用@ConfigurationProperties注释类，还可以在公共@Bean方法上使用它。当您想要将属性绑定到控件之外的第三方组件时，这可能特别有用。 首先要导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 要从属性配置bean Environment 1234567891011121314@ConfigurationProperties（prefix =“person.info”） public class OwnerProperties &#123; private String firstName;//会自动从配置中绑定 public String getFirstName（）&#123; return this .firstName; &#125;&#125; public void setFirstName（String firstName）&#123; this .firstName = firstName; &#125;&#125;&#125;&#125; application.properties1person.info.firstName=name Spring Boot使用一些放松的规则来绑定 eg: 例如context-path绑定到contextPath） 大写（例如PORT绑定到port ConfigurationProperties验证 为了验证嵌套属性的值，必须注释相关字段@Validated以触发其验证 - @NotNull - @NotEmpty","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot整合Rabbitmq设置消息请求头","slug":"SpringBoot整合Rabbitmq设置消息请求头","date":"2017-04-12T07:55:59.000Z","updated":"2018-04-14T04:39:07.933Z","comments":true,"path":"2017/04/12/SpringBoot整合Rabbitmq设置消息请求头/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot整合Rabbitmq设置消息请求头/","excerpt":"","text":"设置请求头，编码，唯一id 12345678Message message = MessageBuilder.withBody(context.getBytes()).setContentType(MessageProperties.CONTENT_TYPE_JSON).setContentEncoding(\"utf-8\").setMessageId(UUID.randomUUID()+\"\").build();this.rabbitTemplate.convertAndSend(\"retry_payment\", \"retry_payment\", message);","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot集成Rabbit使用TopicRabbit指定发送集合","slug":"SpringBoot集成Rabbit使用TopicRabbit指定发送集合","date":"2017-04-12T07:47:07.000Z","updated":"2018-04-14T04:39:56.756Z","comments":true,"path":"2017/04/12/SpringBoot集成Rabbit使用TopicRabbit指定发送集合/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot集成Rabbit使用TopicRabbit指定发送集合/","excerpt":"","text":"Rabbitmq中绑定exchange:flow routing-key:user bind-queue:flow_user 白话文就是,把user绑定到flow_user序列 发送方使用routing-key推送： 12//把routing-key发送给名为flow的exchenge，然后exchenge负责向绑定的这个Queue推送 amqpTemplate.convertAndSend(\"flow\",\"user\", context); Rabbit配置 添加exchange（这里类型type应该是topic,截图时候没有注意） 添加Queue 添加这个User 到exchange(注意routing-key) SpringBoot集成Rabbitmq 注册配置bean 12345678910111213141516171819202122@Configurablepublic class TopicRabbitConfig &#123; public final static String FLOW = \"flow\"; public final static String USER = \"user\"; public final static String USER_QUEUE = \"flow_user\"; @Bean public Queue queueMessages3() &#123; return new Queue(USER_QUEUE); &#125; @Bean TopicExchange exchange() &#123; return new TopicExchange(FLOW); &#125; @Bean Binding bindingExchangeMessages3(Queue queueMessages3, TopicExchange exchange) &#123; return BindingBuilder.bind(queueMessages3).to(exchange).with(FLOW); &#125;&#125; 发送方代码 123456789101112131415161718192021222324252627/** * @Package: pterosaur.account.service.impl * @Description: 模拟发送消息,测试使用 * @author: liuxin * @date: 17/4/19 下午3:17 */@Componentpublic class AccountSentImpl &#123; @Autowired private AmqpTemplate amqpTemplate; private ExecutorService threadPool = Executors.newFixedThreadPool(8); public void send() &#123; for (int i=0;i&lt;10;i++)&#123; String context = \"hello :\" + DateUtil.formatDatetime(System.currentTimeMillis())+\",当前线程:\"+Thread.currentThread().getName(); System.out.println(\"Sender : \" + context); threadPool.execute(new Runnable() &#123; @Override public void run() &#123; amqpTemplate.convertAndSend(TopicRabbitConfig.FLOW,TopicRabbitConfig.USER, context); &#125; &#125;); &#125; &#125;&#125; 接受方代码 1234567891011121314151617181920212223242526272829303132/** * @Package: pterosaur.account.service.impl * @Description: mq信息处理实现类 * @author: liuxin * @date: 17/4/19 下午2:55 */@Componentpublic class AccountReceiverImpl implements AccountReceiver &#123; private static final Logger logger = LoggerFactory.getLogger(AccountReceiverImpl.class); @Autowired ExecutorService threadPool; /** * 用户流水 * * @param message */ @RabbitListener(queues = TopicRabbitConfig.USER_QUEUE) @RabbitHandler public void processUser(String message) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; logger.info(\"用户侧流水:&#123;&#125;\",message); &#125; &#125;); &#125;&#125; 测试代码 123456789101112Sender : hello :2017-04-25 17:44:15,当前线程:mainSender : hello :2017-04-25 17:44:20,当前线程:main2017-04-25 17:44:25.754 INFO 67685 --- [pool-1-thread-1] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:20,当前线程:mainSender : hello :2017-04-25 17:44:25,当前线程:mainSender : hello :2017-04-25 17:44:30,当前线程:main2017-04-25 17:44:32.048 INFO 67685 --- [pool-1-thread-2] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:30,当前线程:mainSender : hello :2017-04-25 17:44:32,当前线程:mainSender : hello :2017-04-25 17:44:33,当前线程:main2017-04-25 17:44:35.556 INFO 67685 --- [pool-1-thread-3] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:33,当前线程:mainSender : hello :2017-04-25 17:44:35,当前线程:mainSender : hello :2017-04-25 17:44:37,当前线程:main2017-04-25 17:44:38.797 INFO 67685 --- [pool-1-thread-1] p.a.service.impl.AccountReceiverImpl : 用户侧流水:hello :2017-04-25 17:44:37,当前线程:main","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot整合多数据源xml方式","slug":"SpringBoot整合多数据源xml方式","date":"2017-04-12T07:46:23.000Z","updated":"2018-04-14T04:39:16.076Z","comments":true,"path":"2017/04/12/SpringBoot整合多数据源xml方式/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot整合多数据源xml方式/","excerpt":"","text":"项目中遇到需要连接多个数据库，本来使用SpringBoot默认配置连接是非常简单的，但是由于涉及多个数据库，不得不再自定义配置了，一次性整明白，下次就之间copy使用。 1.首先学习一个注解@ConfigurationProperties(prefix = &quot;druid&quot;) 默认注入，配置文件中druid开头的属性。eg: druid.url=jdbc:postgresql://139.198.x.x:1x020/account druid.url2=jdbc:postgresql://139.198.x.x:1x020/oto_saas druid.driver-class=org.postgresql.Driver druid.username=root druid.password=Boluome123 druid.initial-size=1 druid.min-idle=1 druid.max-active=20 druid.test-on-borrow=true druid.timeBetweenEvictionRunsMillis=9000 /** * * @author liuxin * @since 2017/4/19 */ @ConfigurationProperties(prefix = &quot;druid&quot;) public class DruidProperties { private String url; private String url2; private String username; private String password; private String driverClass; private int maxActive;//最大连接数 private int minIdle;//最小连接数 private int initialSize;//初始化数量和 private boolean testOnBorrow; private Long timeBetweenEvictionRunsMillis;//心跳 2.添加数据源配置A 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * @Package: pterosaur.account.config.druid * @Description: account 数据源1 * @author: liuxin * @date: 17/4/21 下午7:11 */@Configuration@EnableConfigurationProperties(DruidProperties.class) //开启属性注入,通过@autowired注入 //注入DruidProerties,就是根据第一个注解，创建的配置类@ConditionalOnClass(DruidDataSource.class)//判断这个类是否在classpath中存在@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@MapperScan(basePackages = \"pterosaur.account.mapper.account\", sqlSessionTemplateRef = \"accountSqlSessionTemplate\")//配置实体类包public class DruidAutoConfiguration1 &#123; @Autowired private DruidProperties properties; @Bean(name = \"accountDataSource\") @Primary //DataSource 是一个接口，因为是两个数据源，所以用Primary标记其中一个，防止报错 public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125; @Bean(name = \"accountSqlSessionFactory\") @Primary //同上 public SqlSessionFactory testSqlSessionFactory(@Qualifier(\"accountDataSource\") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\"classpath:mapper/account/*.xml\")); return bean.getObject(); //配置映射文件地址 &#125; @Bean(name = \"accountTransactionManager\") @Primary public DataSourceTransactionManager testTransactionManager(@Qualifier(\"accountDataSource\") DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = \"accountSqlSessionTemplate\") @Primary public SqlSessionTemplate testSqlSessionTemplate(@Qualifier(\"accountSqlSessionFactory\") SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 3.添加数据源配置B 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package pterosaur.account.config.druid;import com.alibaba.druid.pool.DruidDataSource;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.SqlSessionTemplate;import org.mybatis.spring.annotation.MapperScan;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.autoconfigure.AutoConfigureBefore;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import javax.sql.DataSource;import java.sql.SQLException;/** * @Package: pterosaur.account.config.druid * @Description: otosaas 数据源2 * @author: liuxin * @date: 17/4/21 下午7:11 */@Configuration@EnableConfigurationProperties(DruidProperties.class)@ConditionalOnClass(DruidDataSource.class)@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@MapperScan(basePackages = \"pterosaur.account.mapper.otosaas\", sqlSessionTemplateRef = \"otoSaaSSqlSessionTemplate\")public class DruidAutoConfiguration2 &#123; @Autowired private DruidProperties properties; @Bean(name = \"otoSaaSDataSource\") public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl2()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125; @Bean(name = \"otoSaaSSqlSessionFactory\") public SqlSessionFactory testSqlSessionFactory(@Qualifier(\"otoSaaSDataSource\") DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\"classpath:mapper/otosaas/*.xml\")); return bean.getObject(); &#125; @Bean(name = \"accountTransactionManager\") public DataSourceTransactionManager testTransactionManager(@Qualifier(\"otoSaaSDataSource\") DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean(name = \"otoSaaSSqlSessionTemplate\") public SqlSessionTemplate testSqlSessionTemplate(@Qualifier(\"otoSaaSSqlSessionFactory\") SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 参考地址代码地址 @ConditionalOnBean（仅仅在当前上下文中存在某个对象时，才会实例化一个Bean）@ConditionalOnClass（某个class位于类路径上，才会实例化一个Bean）@ConditionalOnExpression（当表达式为true的时候，才会实例化一个Bean）@ConditionalOnMissingBean（仅仅在当前上下文中不存在某个对象时，才会实例化一个Bean）@ConditionalOnMissingClass（某个class类路径上不存在的时候，才会实例化一个Bean）","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot自动生成Mapper映射","slug":"SpringBoot自动生成Mapper映射","date":"2017-04-12T07:45:42.000Z","updated":"2018-04-14T04:39:29.377Z","comments":true,"path":"2017/04/12/SpringBoot自动生成Mapper映射/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot自动生成Mapper映射/","excerpt":"","text":"项目结构 项目中如果使用关系型数据库，配合ibatis使用，只需要建立数据库表就ok，其他的就交给插件去做了。 1.pom文件中添加 12345678910111213&lt;build&gt;truetruetrue&lt;plugin&gt;truetruetruetrue&lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;truetruetruetrue&lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;truetruetruetrue&lt;version&gt;1.3.2&lt;/version&gt;truetruetruetrue&lt;configuration&gt;truetruetruetruetrue&lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt;truetruetruetruetrue&lt;overwrite&gt;true&lt;/overwrite&gt;truetruetruetruetrue&lt;verbose&gt;true&lt;/verbose&gt;truetruetruetrue&lt;/configuration&gt;truetruetrue&lt;/plugin&gt;truetrue&lt;/plugins&gt;true&lt;/build&gt; 2.在resources中添加配置文件 123resource|____generator| |____generatorConfig.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\" &gt;&lt;!--使用方法:mvn mybatis-generator:generate--&gt;&lt;generatorConfiguration&gt;&lt;!--读取配置文件地址--&gt; &lt;properties resource=\"application-test.properties\"/&gt; &lt;!--连接驱动要确定地址--&gt; &lt;classPathEntry location=\"/Users/liuxin/Desktop/postgresql-42.0.0.jre6 2.jar\"/&gt; &lt;context id=\"context1\" targetRuntime=\"MyBatis3Simple\" defaultModelType=\"flat\"&gt; &lt;property name=\"beginningDelimiter\" value=\"`\"/&gt; &lt;property name=\"endingDelimiter\" value=\"`\"/&gt; &lt;jdbcConnection driverClass=\"org.postgresql.Driver\" connectionURL=\"$&#123;druid.url&#125;\" userId=\"$&#123;druid.username&#125;\" password=\"$&#123;druid.password&#125;\"&gt; &lt;/jdbcConnection&gt; &lt;!--实体类也不用提前，建立，会自动根据数据库生成，对应数据库中字段--&gt; &lt;javaModelGenerator targetPackage=\"pterosaur.account.domain\" targetProject=\"src/main/java\"/&gt; &lt;!--映射的mapper.xml文件--&gt; &lt;sqlMapGenerator targetPackage=\"mapper\" targetProject=\"src/main/resources\"/&gt; &lt;!--映射文件，目标不必提前生成，会自动生成--&gt; &lt;javaClientGenerator targetPackage=\"pterosaur.account.mapper\" targetProject=\"src/main/java\" type=\"XMLMAPPER\"/&gt; &lt;!--输入表明，表名不用对应实体，会自动判断--&gt; &lt;table tableName=\"boluome_flow\" &gt;&lt;/table&gt; &lt;table tableName=\"boluome_refund_flow\"&gt;&lt;/table&gt; &lt;table tableName=\"boluome_refund_seettlement\"&gt;&lt;/table&gt; &lt;table tableName=\"boluome_settlement\"&gt;&lt;/table&gt; &lt;table tableName=\"boss_settlement_account\"&gt;&lt;/table&gt; &lt;table tableName=\"boss_transaction_flow\"&gt;&lt;/table&gt; &lt;table tableName=\"settlement_account\"&gt;&lt;/table&gt; &lt;table tableName=\"user_settlement_account\"&gt;&lt;/table&gt; &lt;table tableName=\"user_transcation_flow\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot整合druid数据源及添加Druid监控页面","slug":"SpringBoot整合druid数据源及添加Druid监控页面","date":"2017-04-12T07:45:13.000Z","updated":"2018-04-14T04:38:57.236Z","comments":true,"path":"2017/04/12/SpringBoot整合druid数据源及添加Druid监控页面/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot整合druid数据源及添加Druid监控页面/","excerpt":"","text":"不是不会，只是没见过，代码只是一种工具，首先要会用，应用中使用druid连接池，并添加监控 1.首先引入druid坐标 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.11&lt;/version&gt;&lt;/dependency&gt; 2.添加druid配置参数 参考: 数据库连接池优化配置(druid,dbcp,c3p0) 参数 默认值 解释 initialSize 3 初始化配置 minIdle 3 最小连接数 maxActive 15 最大连接数 maxWait 5000 获取连接超时时间（单位：ms） timeBetweenEvictionRunsMillis 90000 连接有效性检测时间(单位:ms) testOnBorrow false 获取连接检测 testOnReturn false 归还连接检测 minEvictableIdleTimeMillis 1800000 最大空闲时间(单位ms) testWhileIdle true 在获取连接后，确定是否要进行连接空间时间的检查 配置说明： 1：minEvictableIdleTimeMillis(最大空闲时间)：默认为30分钟，配置里面不进行设置。 2：testOnBorrow ,testOnReturn 默认为关闭，可以设置为不配置。 3：testWhileIdle(在获取连接后，确定是否要进行连接空闲时间的检查)。默认为true。配置里面不再进行设置。 流程说明： 1：在第一次调用connection的时候，才会进行 initialSize的初始化。 2：心跳检测时间线程，会休眠timeBetweenEvictionRunsMillis时间，然后只对(没有borrow的线程 减去 minIdle)的线程进行检查，如果空闲时间大于minEvictableIdleTimeMillis则进行close。 3：testWhileIdle必须设置为true，在获取到连接后，先检查testOnBorrow，然后再判定testwhileIdle，如果连接空闲时间大于timeBetweenEvictionRunsMillis，则会进行心跳检测。 4：不需要配置validationQuery，如果不配置的情况下会走ping命令，性能更高。 5：连接保存在数组里面，获取连接的时候，获取数组的最后一位。在imeBetweenEvictionRunsMillis时是从前往后进行检查连接的有效性。 在applicatioin.properties中添加配置 123456789druid.url=jdbc:postgresql://139.198.1.168:11020/accountdruid.driver-class=org.postgresql.Driverdruid.username=rootdruid.password=Boluome123druid.initial-size=1druid.min-idle=1druid.max-active=20druid.test-on-borrow=truedruid.timeBetweenEvictionRunsMillis=9000 3.定义配置类，启动读取druid开头的参数 driver-class有和driverClass是不一样的，所以要引入，参数容错坐标 123456&lt;!--配置命名容错处理--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 123456789101112@ConfigurationProperties(prefix = \"druid\")public class DruidProperties &#123; private String url; private String username; private String password; private String driverClass; private int maxActive;//最大连接数 private int minIdle;//最小连接数 private int initialSize;//初始化数量和 private boolean testOnBorrow; private Long timeBetweenEvictionRunsMillis;//心跳&#125; 4.注入 1234567891011121314151617181920212223242526272829303132333435@Configuration@EnableConfigurationProperties(DruidProperties.class)@ConditionalOnClass(DruidDataSource.class)@ConditionalOnProperty(prefix = \"druid\", name = \"url\")@AutoConfigureBefore(DataSourceAutoConfiguration.class)public class DruidAutoConfiguration &#123; @Autowired private DruidProperties properties; @Bean public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); if (properties.getInitialSize() &gt; 0) &#123; dataSource.setInitialSize(properties.getInitialSize()); &#125; if (properties.getMinIdle() &gt; 0) &#123; dataSource.setMinIdle(properties.getMinIdle()); &#125; if (properties.getMaxActive() &gt; 0) &#123; dataSource.setMaxActive(properties.getMaxActive()); &#125; dataSource.setTestOnBorrow(properties.isTestOnBorrow()); try &#123; dataSource.init(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; return dataSource; &#125;&#125; 5.添加拦截器，拦截器druid性能监控 12345678910111213141516171819202122232425262728293031/** * @Package: pterosaur.account.config.druid * @Description: 监控数据库性能 * @author: liuxin * @date: 17/4/21 上午11:23 */@SuppressWarnings(\"serial\")@WebServlet(urlPatterns = \"/druid/*\", initParams=&#123; @WebInitParam(name=\"allow\",value=\"192.168.16.110,127.0.0.1\"),// IP白名单 (没有配置或者为空，则允许所有访问) @WebInitParam(name=\"deny\",value=\"192.168.16.111\"),// IP黑名单 (存在共同时，deny优先于allow) @WebInitParam(name=\"loginUsername\",value=\"test\"),// 用户名 @WebInitParam(name=\"loginPassword\",value=\"test\"),// 密码 @WebInitParam(name=\"resetEnable\",value=\"false\")// 禁用HTML页面上的“Reset All”功能 &#125;)public class DruidStatViewServlet extends StatViewServlet&#123;&#125;/** * @Package: pterosaur.account.config.filter * @Description: 拦截druid监控请求 * @author: liuxin * @date: 17/4/21 上午11:24 */@WebFilter(filterName=\"druidWebStatFilter\",urlPatterns=\"/*\", initParams=&#123; @WebInitParam(name=\"exclusions\",value=\"*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*\")// 忽略资源 &#125;)public class DruidStatFilter extends WebStatFilter&#123;&#125; 6.最终要一步，启动扫描Servlet 12345678910@SpringBootApplication@MapperScan(basePackages = \"pterosaur.account.mapper\")@EnableCaching@ServletComponentScan //这个public class AccountApplication &#123;truepublic static void main(String[] args) &#123;truetrueSpringApplication.run(AccountApplication.class, args);true&#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot序列化名称自定义","slug":"SpringBoot序列化名称自定义","date":"2017-04-12T07:40:35.000Z","updated":"2018-04-14T04:38:50.498Z","comments":true,"path":"2017/04/12/SpringBoot序列化名称自定义/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot序列化名称自定义/","excerpt":"","text":"SpringBoot 序列化名称自定义 有时候在使用序列化的时候，因为JavaBean中,已经定义好的名称，但是在接口返回的时候，可能需要不是这个，比如： 1234567891011public class User &#123; public final String name; public final String des; public final String age; public User(String name, String age) &#123; this.name = name; this.age = age; this.des = \"\"; &#125;&#125; 在生成json时候是这样的12345&#123; name: \"liuxin\", des: \"\", age: \"23\"&#125; 但是可能我需要的不是这样的json，比如需求是，name换成userName,des换成Password，那么如何在不改变JavaBean,不自定义序列化器的时候，就能实现呢，其实很简单，就是一个注解。撸代码一起看。 12345678@JsonProperty(\"userName\")public void setName(String name) &#123; this.name = name;&#125;@JsonProperty(\"Password\")public void setDes(String des) &#123; this.des = des;&#125; 12345&#123; age: \"23\", userName: \"SpringBoot\", Password: \"\"&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot项目中自定义注解的使用","slug":"SpringBoot项目中自定义注解的使用","date":"2017-04-12T07:39:34.000Z","updated":"2018-04-14T04:40:00.866Z","comments":true,"path":"2017/04/12/SpringBoot项目中自定义注解的使用/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot项目中自定义注解的使用/","excerpt":"","text":"Spring Boot项目中自定义注解的使用 项目中常常要打印日志，尤其是在做接口开发中，因为要面临着对前台数据的检查，在这种情况下，如果还是只使用普通的日志方式，如果配置为INFO 那么明显打印的东西是在太多了，在无奈的压迫下，小编我最终还是选择自己使用Aop的方式去记录日志信息，以下是实战演练。 作者：@lxchinesszz 本文为作者原创，转载请注明出处 1.定义注解接口123456789101112/** * @Package: com.example.config * @Description: 定制一个接口 * @author: liuxin * @date: 17/2/23 下午4:20 */@Documented@Retention(RUNTIME)@Target(METHOD)public @interface MyLog &#123; String value() default \"日志注解\";&#125; [^Documented 注解]: Documented 注解表明这个注解应该被 javadoc工具记录. 默认情况下,javadoc是不包括注解的. 但如果声明注解时指定了 @Documented,则它会被 javadoc 之类的工具处理, 所以注解类型信息也会被包括在生成的文档中[^Inherited 注解]: 它指明被注解的类会自动继承. 更具体地说,如果定义注解时使用了 @Inherited 标记,然后用定义的注解来标注另一个父类, 父类又有一个子类(subclass),则父类的所有属性将被继承到它的子类中[^Target注解]: 注解的作用目标 @Target(ElementType.TYPE) //接口、类、枚举、注解 @Target(ElementType.FIELD) //字段、枚举的常量 @Target(ElementType.METHOD) //方法 @Target(ElementType.PARAMETER) //方法参数 @Target(ElementType.CONSTRUCTOR) //构造函数 @Target(ElementType.LOCAL_VARIABLE)//局部变量 @Target(ElementType.ANNOTATION_TYPE)//注解 @Target(ElementType.PACKAGE) ///包 1.RetentionPolicy.SOURCE —— 这种类型的Annotations只在源代码级别保留,编译时就会被忽略 2.RetentionPolicy.CLASS —— 这种类型的Annotations编译时被保留,在class文件中存在,但JVM将会忽略 3.RetentionPolicy.RUNTIME —— 这种类型的Annotations将被JVM保留,所以他们能在运行时被JVM或其他使用反射机制的代码所读取和使用. 2.通过切面来实现注解1234567891011121314151617181920212223242526272829303132333435363738/** * @Package: com.example.config * @Description: MyLog的实现类 * @author: liuxin * @date: 17/2/23 下午4:22 */@Component@Aspectpublic class LogAspect &#123; @Pointcut(\"@annotation(com.example.config.MyLog)\") private void cut() &#123; &#125; /** * 定制一个环绕通知 * @param joinPoint */ @Around(\"cut()\") public void advice(ProceedingJoinPoint joinPoint)&#123; System.out.println(\"环绕通知之开始\"); try &#123; joinPoint.proceed(); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; System.out.println(\"环绕通知之结束\"); &#125; //当想获得注解里面的属性，可以直接注入改注解 @Before(\"cut()&amp;&amp;@annotation(myLog)\") public void record(JoinPoint joinPoint, MyLog myLog) &#123; System.out.println(myLog.value()); &#125; @After(\"recordLog()\") public void after() &#123; this.printLog(\"已经记录下操作日志@After 方法执行后\"); &#125;&#125; 因为Aspect作用在bean上，所以先用Component把这个类添加到容器中 @Pointcut 定义要拦截的注解 至于切面表达式，不需要你记住，小编我也记不住，用的时候查一下就可以了 切面表达式link @After @Before @Around 就不用解释了。 2.1 获得注解中的变量12345//当想获得注解里面的属性，可以直接注入改注解 @Before(\"cut()&amp;&amp;@annotation(myLog)\") public void record(JoinPoint joinPoint, MyLog myLog) &#123; System.out.println(myLog.value()); &#125; 2.2 注解中的ProceedingJoinPoint和JoinPoint说明 AspectJ使用org.aspectj.lang.JoinPoint接口表示目标类连接点对象，如果是环绕增强时，使用org.aspectj.lang.ProceedingJoinPoint表示连接点对象，该类是JoinPoint的子接口。任何一个增强方法都可以通过将第一个入参声明为JoinPoint访问到连接点上下文的信息。我们先来了解一下这两个接口的主要方法： 1.JoinPoint  java.lang.Object[] getArgs()：获取连接点方法运行时的入参列表；  Signature getSignature() ：获取连接点的方法签名对象；  java.lang.Object getTarget() ：获取连接点所在的目标对象；  java.lang.Object getThis() ：获取代理对象本身； 2.ProceedingJoinPoint ProceedingJoinPoint继承JoinPoint子接口，它新增了两个用于执行连接点方法的方法：  java.lang.Object proceed() throws java.lang.Throwable：通过反射执行目标对象的连接点处的方法；  java.lang.Object proceed(java.lang.Object[] args) throws java.lang.Throwable：通过反射执行目标对象连接点处的方法，不过使用新的入参替换原来的入参。 3.演示123456789101112@RestControllerpublic class JsonRest &#123; @MyLog @RequestMapping(\"/log\") public String getLog()&#123; return \"&lt;h1&gt;Hello World&lt;/h1&gt;\"; &#125;&#125;当访问的时候会打印出：[因为小编只用了环绕通知] 环绕通知之开始 环绕通知之结束","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot配置拦截器","slug":"SpringBoot配置拦截器","date":"2017-04-12T07:38:40.000Z","updated":"2018-04-14T04:39:47.451Z","comments":true,"path":"2017/04/12/SpringBoot配置拦截器/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot配置拦截器/","excerpt":"","text":"SpringBoot拦截器 最近项目中有一个需求，对来访的请求，进行计算，记录下业务处理时间。Spring Boot项目中使用拦截器，超级简单，再次说明一下用法。相信大家一看便懂。 1.继承 HandlerInterceptor 实现具体的处理逻辑1234567public interface HandlerInterceptor &#123; boolean preHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; //是否放行 void postHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3, ModelAndView var4) throws Exception; //处理结束 void afterCompletion(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4) throws Exception; //在处理结束后执行，最后执行的方法&#125; 以下是我的处理逻辑 12345678910111213141516171819202122232425262728293031/** * @Package: foxlife.base.interceptor * @Description: 处理时间拦截器，记录下，接口处理时间 * @author: liuxin * @date: 17/2/22 上午10:58 */@Componentpublic class ChanelInterceptor implements HandlerInterceptor &#123; private static Logger logger = LoggerFactory.getLogger(ChanelInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object o) throws Exception &#123; logger.info(\"============================拦截器启动==============================\"); request.setAttribute(\"starttime\",System.currentTimeMillis()); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object o, ModelAndView modelAndView) throws Exception &#123; logger.info(\"===========================执行处理完毕=============================\"); long starttime = (long) request.getAttribute(\"starttime\"); request.removeAttribute(\"starttime\"); long endtime = System.currentTimeMillis(); logger.info(\"============请求地址：\"+request.getRequestURI()+\"：处理时间：&#123;&#125;\",(endtime-starttime)+\"ms\"); &#125; @Override public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception &#123; logger.info(\"============================拦截器关闭==============================\"); &#125;&#125; 2.配置拦截器到应用中12345678910111213/** * @Package: foxlife.base.config * @Description: 配置拦截器 * @author: liuxin * @date: 17/2/22 上午11:04 */@Configurationpublic class MyInterceptorConfig extends WebMvcConfigurerAdapter&#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new ChanelInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; [^注解]: Spring Boot的项目建议使用配置类,addPathPatterns(&quot;/**&quot;) 3.演示12342017-02-23 15:40:43.619 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ============================拦截器启动==============================2017-02-23 15:40:43.621 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ===========================执行处理完毕=============================2017-02-23 15:40:43.621 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ============请求地址：/error：处理时间：2ms2017-02-23 15:40:43.621 INFO 64568 --- [io-31024-exec-3] f.base.interceptor.ChanelInterceptor : ============================拦截器关闭==============================","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot创建maven多模块项目","slug":"SpringBoot创建maven多模块项目","date":"2017-04-12T07:38:11.000Z","updated":"2018-04-14T04:38:30.893Z","comments":true,"path":"2017/04/12/SpringBoot创建maven多模块项目/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot创建maven多模块项目/","excerpt":"","text":"SpringBoot创建maven多模块项目(实战) 工作中一直都是一个人奋战一人一个项目，使用maven管理，看这个也挺好，但是总感觉没有充分发挥maven的功能，于是研究了一下这个，网上关于这个的文章很多，虽然不是很好，但我从中收获了很多，在这集百家所长，写一份实战记录，大家跟着我一块做吧！ 声明：构建多模块不是最难的，难点是如果把多模块打包成一个执行jar。SpringBoot官方推崇的是富jar，也就是jar文件启动项目，所以如果在这里打war包我不具体介绍，如果需要的朋友可以给我留言，我回复。 建议clone项目后，在看教程（有不足的地方希望大家保函，指出来，我们一起学习改进） github：https://github.com/lxchinesszz/multi-boluome.git 构建工程 1.首先第一步，在github上创建一个公共项目项目名 multi-boluome 2.把仓库同步到本地，使用Intellij idea打开，把普通项目转换为maven项目【右键：Add Frameworks Support】 3.删除除了pom文件之外的文件也就是src删除 4.然后新建File-&gt;New-&gt;module以此创建（此时会看到pom文件的变化） web dao domain service ==提示：一定要把外面的pom文件中的pom== 5.引入SpringBoot依赖 这个我在外面写的（这个根据个人） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111true外面的pom文件内容true&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;blm.server&lt;/groupId&gt; &lt;artifactId&gt;multi-boluome&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;web&lt;/module&gt; &lt;module&gt;service&lt;/module&gt; &lt;module&gt;dao&lt;/module&gt; &lt;module&gt;domain&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;kotlin.version&gt;1.0.6&lt;/kotlin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!--引入mock框架--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-core&lt;/artifactId&gt; &lt;version&gt;1.10.19&lt;/version&gt; &lt;/dependency&gt; &lt;!--rabbitmq--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- The plugin rewrites your manifest --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;configuration&gt;&lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;iflyer.IflyerApplication&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;!--可以生成不含依赖包的不可执行Jar包--&gt; &lt;!-- configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;/configuration&gt; --&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 6.开始编写domain层（这里我用mongodb数据库） 7.dao层我要用到数据库，所以在resource中添加配置信息 8.service层中我有用到freemarker的模板引擎，所以添加配置信息 9.web层编写启动类，main方法，main方法要放到目录外层，根据约定哦！ 10.每个层及都有自己的依赖 123456eg： dao层依赖domain service依赖dao和domain web层依赖service、dao、domain这个关系层次一定要告诉，编辑器，如下设置 右键：Open Module Settings打开 idea修改依赖 ![](https://raw.githubusercontent.com/lxchinesszz/multi-boluome/master/web/src/main/resources/static/image/6.web%E5%B1%82%E4%BE%9D%E8%B5%963%E4%B8%AA.png) 11.run一下启动类吧！工程可以启动了 如果出现一下错误Error:java: Annotation processing is not supported for module cycles. Please ensure that all modules说明依赖关系错了，继续看第10步骤吧。 打包发布jar文件 1.在启动类中修改pom文件(也就是web层的) 1234567891011&lt;build&gt; &lt;!-- 为jar包取名 --&gt; &lt;finalName&gt;blm-start&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2.在外层pom中构建插件 12345678910111213141516171819202122232425&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- The plugin rewrites your manifest --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;configuration&gt;&lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;com.Application&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;!--可以生成不含依赖包的不可执行Jar包--&gt; &lt;!-- configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;/configuration&gt; --&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 3.打包吧，mvn package —Dmaven.test.skip=true 跳过测试 12345678910111213141516[INFO] multi-boluome ...................................... SUCCESS [ 1.707 s][INFO] domain ............................................. SUCCESS [ 2.463 s][INFO] dao ................................................ SUCCESS [ 0.592 s][INFO] service ............................................ SUCCESS [ 0.606 s][INFO] web ................................................ SUCCESS [ 1.135 s][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 7.290 s[INFO] Finished at: 2017-01-20T17:05:14+08:00[INFO] Final Memory: 42M/265M[INFO] ------------------------------------------------------------------------KK-MINI:multi-boluome liuxin$ INFO] Building jar: /Users/liuxin/git/模仿项目/multi-boluome/web/target/blm-start.jar构建文件在这个目录下 very Good！开始飞吧==提醒：所有模块里面的父节点都是一样的哦，不然会报错 unknow.version== WARNING] ‘parent.relativePath’ of POM blm.server:domain:[unknown-version] 类似","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot使用日志接口UI","slug":"SpringBoot使用日志接口UI","date":"2017-04-12T07:37:39.000Z","updated":"2018-04-14T04:38:26.705Z","comments":true,"path":"2017/04/12/SpringBoot使用日志接口UI/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot使用日志接口UI/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 &lt;!--加入Swagger2的依赖实现api文档--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;/dependency&gt;package butterfly.shjf;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Scope;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;/** * Created by liuxin on 16/12/9. * 创建api文档访问信息 * url：http://localhost:8080/swagger-ui.html */@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.shjf\")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(\"shjf-Api文档\") .description(\"blm付费通项目api文档\") .contact(\"liuxin\") .version(\"1.0\") .build(); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot配置异常处理类","slug":"SpringBoot配置异常处理类","date":"2017-04-12T07:36:39.000Z","updated":"2018-04-14T04:39:44.159Z","comments":true,"path":"2017/04/12/SpringBoot配置异常处理类/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot配置异常处理类/","excerpt":"","text":"首先定义一个异常12345public class MyException extends Exception &#123; public MyException(String message) &#123; super(message); &#125;&#125; 当在control类中throw此异常1234567@Controllerpublic class HelloController &#123; @RequestMapping(\"/json\") public String json() throws MyException &#123; throw new MyException(\"发生错误2\"); &#125;&#125; 处理该异常12345678910111213141516171819202122@ControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(value = MyException.class) //这个注解，接受异常 @ResponseBody //返回json public ErrorInfo&lt;String&gt; jsonErrorHandler(HttpServletRequest req, MyException e) throws Exception &#123; ErrorInfo&lt;String&gt; r = new ErrorInfo&lt;&gt;(); r.setMessage(e.getMessage()); r.setCode(ErrorInfo.ERROR); r.setData(\"Some Data\"); r.setUrl(req.getRequestURL().toString()); return r; &#125;&#125;应用启动：响应&#123; code: 100， data: \"Some Data\"， message: \"发生错误2\"， url: \"http://localhost:8080/json\"&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot配置多套环境","slug":"SpringBoot配置多套环境","date":"2017-04-12T07:36:12.000Z","updated":"2018-04-14T04:39:40.483Z","comments":true,"path":"2017/04/12/SpringBoot配置多套环境/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot配置多套环境/","excerpt":"","text":"生产中会经历，开发，测试，到上线。三个阶段 这个三个阶段，都有各自的配置文件，如果只是一个配置文件来回改 会很容易出现错误的，那么springboot提供了很简答的解决办法 使用spring.profiles.active=test 定义一个application.properties 里面写上 spring.profiles.active=test 默认启动test文件 定义application-dev.properties 定义application-test.properties 定义application-prod.properties 使用java -jar mm.jar –spring.profiles.active=dev 运行启动dev环境 可以看到启动的是dev122017-01-04 18:54:11.095 INFO 43026 --- [ restartedMain] dragonfly.DragonflyApplication : Starting DragonflyApplication on KK-MINI.local with PID 43026 (/Users/liuxin/git/oto_saas_mybosc_pay/target/classes started by liuxin in /Users/liuxin/git/oto_saas_mybosc_pay)2017-01-04 18:54:11.100 INFO 43026 --- [ restartedMain] dragonfly.DragonflyApplication : The following profiles are active: dev","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot在启动类配置端口号","slug":"SpringBoot在启动类配置端口号","date":"2017-04-12T07:35:40.000Z","updated":"2018-04-14T04:38:41.199Z","comments":true,"path":"2017/04/12/SpringBoot在启动类配置端口号/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot在启动类配置端口号/","excerpt":"","text":"1234567891011@SpringBootApplicationpublic class DragonflyApplication extends SpringBootServletInitializer implements EmbeddedServletContainerCustomizer &#123; public static void main(String[] args) &#123; SpringApplication.run(DragonflyApplication.class, args); &#125; @Override public void customize(ConfigurableEmbeddedServletContainer configurableEmbeddedServletContainer) &#123; configurableEmbeddedServletContainer.setPort(10087); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot联调日志输出","slug":"SpringBoot联调日志输出","date":"2017-04-12T07:35:12.000Z","updated":"2018-04-14T04:39:26.370Z","comments":true,"path":"2017/04/12/SpringBoot联调日志输出/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot联调日志输出/","excerpt":"","text":"在日常生产中，在和前端联合调试的时候，可能会遇到很多情况，在出现问题时候，很不容易找到，那么如果能够检测前后台的交互数据，应该就很容易快速解决问题，哪么可以使用Aop去解析。 首先因为aop包 123456 &lt;!--aop依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;version&gt;1.3.3.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置切面类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 @Aspect@Componentpublic class WebLogAspect &#123; private final static Logger logger = LoggerFactory.getLogger(WebLogAspect.class); private final static ThreadLocal&lt;Long&gt; prcoessTimeList = new ThreadLocal&lt;&gt;(); /** * rest包和子包里面的所有方法 */ @Pointcut(\"execution(public * safety.bankpay.rest..*.*(..))\") public void weblog() &#123; &#125; @Before(\"weblog()\") public void doBefore(JoinPoint joinpoint) throws Throwable &#123; // 接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); Enumeration&lt;String&gt; headerNames = request.getParameterNames(); Map map = MapFactory.newMap(); String parameterType = \"parameter\"; // 记录下请求内容 String method = request.getMethod(); logger.info(\"----------\" + joinpoint.getSignature().getName() + \"方法开始执行----------------------------\"); logger.info(\"&#123;&#125; : &#123;&#125; \", method.toUpperCase(), request.getRequestURL().toString()); logger.info(\"方法 : \" + joinpoint.getSignature().getDeclaringTypeName() + \".\" + joinpoint.getSignature().getName()); while (headerNames.hasMoreElements()) &#123; String key = headerNames.nextElement(); String parameter = request.getParameter(key); map.put(key, parameter); &#125; if (map.size() == 0) &#123; ServletInputStream inputStream = request.getInputStream(); String requestBoby = StreamUtils.convertStreamToString(inputStream); parameterType = \"body\"; logger.info(\"参数类型:&#123;&#125; 参数列表:&#123;&#125; \", parameterType, requestBoby); &#125; else &#123; logger.info(\"参数类型:&#123;&#125; 参数列表:&#123;&#125; \", parameterType, JsonUtils.toJson(map)); &#125; prcoessTimeList.set(System.currentTimeMillis()); &#125; @AfterReturning(returning = \"ret\", pointcut = \"weblog()\") public void doAfterReturning(Object ret) throws Throwable &#123; ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); Long startTime = prcoessTimeList.get(); Long endTime = System.currentTimeMillis(); prcoessTimeList.remove(); // 处理完请求，返回内容 logger.info(\"返回参数 : \" + ret); logger.info(\"-----------------方法执行完毕,耗时:&#123;&#125;ms-------------------\", (endTime - startTime)); &#125;&#125; 哦了。 123452017-04-12T15:28:39.736 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:50 ----------bindUser方法开始执行----------------------------]2017-04-12T15:28:39.736 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:51 GET : http://dev-zjrcu.otosaas.com/bindUser/v1 ]2017-04-12T15:28:39.737 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:52 方法 : safety.bankpay.rest.OtoRestController.bindUser]2017-04-12T15:28:39.737 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:64 参数类型:parameter 参数列表:&#123;\"openId\":\"a9a0565027b34312871f25901cfe9e04\",\"accessToken\":\"564d5b9514884d669cc6651893a4cf39\",\"clientId\":\"2018030700000000001005\",\"categoryCode\":\"dianying\"&#125; ]2017-04-12T15:28:40.617 INFO oto_saas_zjrcu_pay http-nio-32028-exec-1 safety.bankpay.config.aop.WebLogAspect [line:78 -----------------方法执行完毕,耗时:880ms-------------------]","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot使用maven打包，加载不到配置文件原因","slug":"SpringBoot使用maven打包，加载不到配置文件原因","date":"2017-04-12T07:31:41.000Z","updated":"2018-04-14T04:38:22.478Z","comments":true,"path":"2017/04/12/SpringBoot使用maven打包，加载不到配置文件原因/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot使用maven打包，加载不到配置文件原因/","excerpt":"","text":"病情使用idea工具，测试没有问题，使用maven可以打包，但是运行，错误。 通过反编译分析，原因就是打包后的文件，没有包配置文件输入，解决办法 123456789101112131415&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt;&lt;/resources&gt;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot自动扫描启动配置文件问题","slug":"SpringBoot自动扫描启动配置文件问题","date":"2017-04-12T07:29:57.000Z","updated":"2018-04-14T04:39:32.487Z","comments":true,"path":"2017/04/12/SpringBoot自动扫描启动配置文件问题/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot自动扫描启动配置文件问题/","excerpt":"","text":"1.SpringBoot会自动扫描resource下面的application配置文件， 2.然后是config下面当，config有多个配置文件时候，SpringBoot会找不到application文件， 3.当使用 12@Configuration@ConfigurationProperties(locations = \"classpath:config/callbackurl.properties\")","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)","slug":"Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)","date":"2017-04-12T07:29:14.000Z","updated":"2018-04-14T04:43:09.648Z","comments":true,"path":"2017/04/12/Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)/","excerpt":"","text":"==前文==，Quartz中迭代后，变化很大，让我走了很多的误区，这里简单解释一点，希望大家可以跳过误区，建议大家从下往上读（希望对大家有点帮助），我是一只爱分享的小菜鸟 JobDetail和Trigger和Schedule都是接口，统统不能new 1.如果只是执行一些自定义的类，其实使用SpringBoot的自带的任务就可以完成，简单的不能想象。这个可以看-&gt;我的另一篇SpringBoot原生定时任务解析。2.如果要是要动态的执行一些有Spring管理的bean，可能要稍微费点功夫了，网上有很多的教程，那部分都是xml形式配置的，本人菜鸟一枚（十分迷惑），十分不喜欢xml配置，看着眼花，当程序读取的时候还是要解析java对象来执行的，那么为何不直接配置成配置类呢？这个问题先方下，以后会详细解释如何使用Spring Boot配置类。开始代码展示1234567891011121314151617181920212223242526 //job是一个接口，当定时任务执行的时候，就要运行这个方法，那么可以推测 JobExecutionContext这个对象中包含了我们可能使用的关于这个定时任务的所有细节，请看代码public interface Job &#123; void execute(JobExecutionContext var1) throws JobExecutionException;&#125;/** * Created by liuxin on 16/12/21. * 方案1：反射执行类和执行方法（不解析，没有用，刚开始走了误区，自己反射方法执行，大家尽量不要用） * 方案2：读取bean（这个才是重点） */public class ScheduledTasks implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(\"------进入定时方法区域-------\"); try &#123; ConfigurableApplicationContext cac = (ConfigurableApplicationContext) jobExecutionContext.getJobDetail().getJobDataMap().get(\"ConfigurableApplicationContext\"); HelloService helloService = (HelloService) cac.getBean(\"helloService\"); helloService.hh(); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 上面的代码中看到这个JobExecutionContext可以得到JobDetail，而这个JobDetail对象是我们自己创建的用来详细介绍我们定时任务的，也就是我们要执行的方法的详细在这个里存放，123jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);这个是我们在main方法中测试时候，提前放进去，的在执行execute方法时候，取到的上下文对象，用来得到bean的这么说是不是很清楚了？接着看代码 测试的bean对象1234567@Servicepublic class HelloService &#123; static int i=0; public void hh()&#123; System.out.println(++i); &#125;&#125; 为了证明这个bean在上下文中，我们打印一下，上下文中的所有的bean 123456789101112131415161718192021222324252627282930313233@SpringBootApplicationpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean 可以看到helloService在倒数3 &#125;&#125; . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.2.RELEASE)org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorytestQuartzApplicationorg.springframework.boot.autoconfigure.internalCachingMetadataReaderFactoryorg.springframework.context.annotation.ConfigurationClassPostProcessor.importAwareProcessororg.springframework.context.annotation.ConfigurationClassPostProcessor.enhancedConfigurationProcessorhelloServiceredisConfigjedis 那么现在的任务就是把，这个上下文对象防盗JobDetil的map中，2.2.1的区别来了，不在是一起new的jobDetail了,由JobBuilder和TriggerBuilder构建1234567891011121314151617@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(\"testkey\", \"testvalue\").withDescription(\"一个测试的类\").build(); jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);//重点是这句话 Trigger trigger = TriggerBuilder.newTrigger().startNow().withSchedule(CronScheduleBuilder.cronSchedule(\"0/1 * * * * ?\")).startNow().build(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring整合Quartz","slug":"Spring整合Quartz","permalink":"https://lxchinesszz.github.io/tags/Spring整合Quartz/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Spring整合Quartz2.1.1","slug":"Spring整合Quartz2-1-1","date":"2017-04-12T07:29:14.000Z","updated":"2018-04-14T04:40:11.165Z","comments":true,"path":"2017/04/12/Spring整合Quartz2-1-1/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/Spring整合Quartz2-1-1/","excerpt":"","text":"==前文==，Quartz中迭代后，变化很大，让我走了很多的误区，这里简单解释一点，希望大家可以跳过误区，建议大家从下往上读（希望对大家有点帮助），我是一只爱分享的小菜鸟 JobDetail和Trigger和Schedule都是接口，统统不能new 1.如果只是执行一些自定义的类，其实使用SpringBoot的自带的任务就可以完成，简单的不能想象。这个可以看-&gt;我的另一篇SpringBoot原生定时任务解析。2.如果要是要动态的执行一些有Spring管理的bean，可能要稍微费点功夫了，网上有很多的教程，那部分都是xml形式配置的，本人菜鸟一枚（十分迷惑），十分不喜欢xml配置，看着眼花，当程序读取的时候还是要解析java对象来执行的，那么为何不直接配置成配置类呢？这个问题先方下，以后会详细解释如何使用Spring Boot配置类。开始代码展示1234567891011121314151617181920212223242526 //job是一个接口，当定时任务执行的时候，就要运行这个方法，那么可以推测 JobExecutionContext这个对象中包含了我们可能使用的关于这个定时任务的所有细节，请看代码 public interface Job &#123; void execute(JobExecutionContext var1) throws JobExecutionException;&#125;/** * Created by liuxin on 16/12/21. * 方案1：反射执行类和执行方法（不解析，没有用，刚开始走了误区，自己反射方法执行，大家尽量不要用） * 方案2：读取bean（这个才是重点） */public class ScheduledTasks implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(\"------进入定时方法区域-------\"); try &#123; ConfigurableApplicationContext cac = (ConfigurableApplicationContext) jobExecutionContext.getJobDetail().getJobDataMap().get(\"ConfigurableApplicationContext\"); HelloService helloService = (HelloService) cac.getBean(\"helloService\"); helloService.hh(); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 上面的代码中看到这个JobExecutionContext可以得到JobDetail，而这个JobDetail对象是我们自己创建的用来详细介绍我们定时任务的，也就是我们要执行的方法的详细在这个里存放，123jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);这个是我们在main方法中测试时候，提前放进去，的在执行execute方法时候，取到的上下文对象，用来得到bean的这么说是不是很清楚了？接着看代码 测试的bean对象1234567@Servicepublic class HelloService &#123; static int i=0; public void hh()&#123; System.out.println(++i); &#125;&#125; 为了证明这个bean在上下文中，我们打印一下，上下文中的所有的bean 123456789101112131415161718192021222324252627282930313233@SpringBootApplicationpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean 可以看到helloService在倒数3 &#125;&#125; . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.2.RELEASE)org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorytestQuartzApplicationorg.springframework.boot.autoconfigure.internalCachingMetadataReaderFactoryorg.springframework.context.annotation.ConfigurationClassPostProcessor.importAwareProcessororg.springframework.context.annotation.ConfigurationClassPostProcessor.enhancedConfigurationProcessorhelloServiceredisConfigjedis 那么现在的任务就是把，这个上下文对象防盗JobDetil的map中，2.2.1的区别来了，不在是一起new的jobDetail了,由JobBuilder和TriggerBuilder构建1234567891011121314151617@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(\"testkey\", \"testvalue\").withDescription(\"一个测试的类\").build(); jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);//重点是这句话 Trigger trigger = TriggerBuilder.newTrigger().startNow().withSchedule(CronScheduleBuilder.cronSchedule(\"0/1 * * * * ?\")).startNow().build(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Spring Cloud初步理解","slug":"Spring Cloud初步理解","date":"2017-04-12T07:29:14.000Z","updated":"2018-04-14T04:43:33.532Z","comments":true,"path":"2017/04/12/Spring Cloud初步理解/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/Spring Cloud初步理解/","excerpt":"","text":"Ribbon实现负载均衡 关键字：Feign、Ribbon、eureka、负载均衡 大致：步骤，启动eureka服务(注册中心) 使用Spring Cloud Netflix中的Eureka实现服务注册中心，以及服务注册发现； 将service(port:2222,port:2223)注册到eureka服务中 使用Ribbon代理去访问service 会实现负载均衡 服务间通过Ribbon或Feign实现服务的消费以及均衡负载 通过Spring Cloud Config实现应用多环境的外部化配置及版本管理 使得服务集群更为健壮，使用Hystrix熔断机制避免微服务架构中个别服务出现异常引起的故障蔓延 引入断路器 Rabbion中引入Hystrix 123456789101112@Servicepublic class ComputeService &#123; @Autowired RestTemplate restTemplate; @HystrixCommand(fallbackMethod = \"addServiceFallback\") public String addService() &#123; return restTemplate.getForEntity(\"http://COMPUTE-SERVICE/add?a=10&amp;b=20\", String.class).getBody(); &#125; public String addServiceFallback() &#123; return \"error\"; &#125;&#125;","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://lxchinesszz.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://lxchinesszz.github.io/tags/Spring-Cloud/"}],"keywords":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://lxchinesszz.github.io/categories/Spring-Cloud/"}]},{"title":"SpringBoot整合Quartz-动态读取任务执行","slug":"SpringBoot整合Quartz-动态读取任务执行","date":"2017-04-12T07:28:33.000Z","updated":"2018-04-14T04:39:00.990Z","comments":true,"path":"2017/04/12/SpringBoot整合Quartz-动态读取任务执行/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot整合Quartz-动态读取任务执行/","excerpt":"","text":"本次使用redis作为数据库，存储定时任务类redis的连接不是重点，重点是解析序列化处理过的任务数组和Quartz如何添加任务 1. JobEntity 用来保存执行任务类123456789101112131415public class JobEntity implements Serializable &#123; //cron表达式 private String cronExpression; //组名 private String jobGroup = Scheduler.DEFAULT_GROUP; private String jobName; private String className; // 执行任务的类(完整路径 包含包名) private String methodName;//执行任务的方法名 set ... get ...&#125; 2.任务类12345678910public class Test &#123; public void xun()&#123; System.out.println(\"--------定时任务2-------\"); &#125;&#125;public class Test2 &#123; public void test()&#123; System.out.println(\"--------定时任务1-------\"); &#125;&#125; 3.存入redis1234567891011121314151617181920212223public void start2() &#123; Gson gson = new Gson(); JobEntity jobEntity = new JobEntity(); jobEntity.setMethodName(\"test\"); jobEntity.setJobName(\"MyJob2\"); jobEntity.setClassName(\"zebra.shjf.schedule.Test2\"); jobEntity.setCronExpression(\"0/1 * * * * ?\"); jobEntity.setJobGroup(\"MyGroup2\"); JobEntity jobEntity2 = new JobEntity(); jobEntity2.setMethodName(\"xun\"); jobEntity2.setJobName(\"MyJob\"); jobEntity2.setClassName(\"zebra.shjf.schedule.Test\"); jobEntity2.setCronExpression(\"0/1 * * * * ?\"); jobEntity2.setJobGroup(\"MyGroup\"); ArrayList&lt;JobEntity&gt; list = new ArrayList&lt;JobEntity&gt;(); list.add(jobEntity); list.add(jobEntity2); jedis.set(\"jobEntity\", gson.toJson(list)); &#125; 127.0.0.1:6379&gt; get \"jobEntity\" \"[&#123;\\\"cronExpression\\\":\\\"0/1 * * * * ?\\\",\\\"jobGroup\\\":\\\"MyGroup2\\\",\\\"jobName\\\":\\\"MyJob2\\\",\\\"className\\\":\\\"zebra.shjf.schedule.Test2\\\",\\\"methodName\\\":\\\"test\\\"&#125;,&#123;\\\"cronExpression\\\":\\\"0/1 * * * * ?\\\",\\\"jobGroup\\\":\\\"MyGroup\\\",\\\"jobName\\\":\\\"MyJob\\\",\\\"className\\\":\\\"zebra.shjf.schedule.Test\\\",\\\"methodName\\\":\\\"xun\\\"&#125;]\" 3.重点解析(注释解释)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Test public void start3() throws Exception &#123; //准备添加从redis中得到的实体类，目的是遍历，然后添加到定时容器中，去执行 ArrayList&lt;JobEntity&gt;arrayList=new ArrayList&lt;JobEntity&gt;(); Gson gson = new Gson(); //从redis中得到json数组对象 String str = jedis.get(\"jobEntity\"); //json解析器 JsonParser parser = new JsonParser(); //解析出json元素，jsonElement对象中有一些方法判断是对象还是数组，各对应不同的处理 JsonElement jsonElement = parser.parse(str); //如果是json数组就转换为jsonArray JsonArray jsonArray = null; if (jsonElement.isJsonArray()) &#123; jsonArray = jsonElement.getAsJsonArray(); &#125; //遍历 Iterator it= jsonArray.iterator(); while (it.hasNext())&#123; JsonElement e = (JsonElement)it.next(); //把获得的数组中每一个对象，重新添加到数组中 arrayList.add(gson.fromJson(e,JobEntity.class)); &#125; //容器 Scheduler scheduler=null; //遍历数组 for(JobEntity jobEntity:arrayList)&#123; //遍历获得每个job对象 JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(jobEntity.getJobName(), jobEntity.getJobGroup()).// usingJobData(\"className\", jobEntity.getClassName()) .usingJobData(\"methodName\", jobEntity.getMethodName()).build(); //jobDetail.getJobDataMap().put(\"test\", jobEntity); //为每个任务动态构建表达式 CronScheduleBuilder cron = CronScheduleBuilder.cronSchedule(jobEntity.getCronExpression()); //构建触发器 CronTrigger trigger = TriggerBuilder.newTrigger().withIdentity(jobEntity.getJobName(), jobEntity.getJobGroup()).withSchedule(cron).build(); SchedulerFactory schedulerFactory = new StdSchedulerFactory(); scheduler = schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); &#125; scheduler.start(); Thread thread = new Thread(); thread.sleep(10000); &#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot+Quartz整合定时任务","slug":"SpringBoot-Quartz整合定时任务","date":"2017-04-12T07:27:59.000Z","updated":"2018-04-14T04:37:52.764Z","comments":true,"path":"2017/04/12/SpringBoot-Quartz整合定时任务/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot-Quartz整合定时任务/","excerpt":"","text":"概念： 当处理一些，简单的，固定时间，重复次数的任务可以使用简单触发器 当处理一些，负载的任务，可以使用Cron表达式（触发器的name字段一定要写）1.一个jobDetail就是一个业务。也就是准备定时的任务12345@Bean public JobDetail jobDetail()&#123; JobDetail jobDetail=new JobDetail(\"scheduledTasks2s\", Scheduler.DEFAULT_GROUP, ScheduledTasks2.class); return jobDetail; &#125; 2.SimpleTrigger简单触发器，设置多久触发一次，触发次数12345678 @Beanpublic SimpleTrigger simpleTrigger()&#123; SimpleTrigger simpleTrigger=new SimpleTrigger(\"simpleTrigger\",Scheduler.DEFAULT_GROUP); simpleTrigger.setStartTime(new Date(System.currentTimeMillis())); simpleTrigger.setRepeatInterval(5000);//没 simpleTrigger.setRepeatCount(10);//执行10次 return simpleTrigger;&#125; 2.1可以使用cron表达式的触发器/** * 触发器名字一定要写 * @return * @throws Exception */ @Bean public CronTrigger cronTrigger() throws Exception { CronTrigger cronTrigger = new CronTrigger(); cronTrigger.setName(&quot;MyCronTrigger&quot;); cronTrigger.setCronExpression(&quot;0/1 * * * * ? &quot;); return cronTrigger; } 3.Scheduler调度器，这个调度器由SchedulerFactory工厂获得设置定时任务和触 发器1234567@Bean public Scheduler scheduler(JobDetail jobDetail,SimpleTrigger simpleTrigger)throws Exception&#123; SchedulerFactory schedulerFactory=new StdSchedulerFactory(); Scheduler scheduler=schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, simpleTrigger); return scheduler; &#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot项目中整合dubbo实战","slug":"SpringBoot项目中整合dubbo实战","date":"2017-04-12T07:25:52.000Z","updated":"2018-04-14T04:39:56.765Z","comments":true,"path":"2017/04/12/SpringBoot项目中整合dubbo实战/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot项目中整合dubbo实战/","excerpt":"","text":"“看看星空，会觉得自己很渺小，可能我们在宇宙中从来就是一个偶然。所以，无论什么事情，仔细想一想，都没有什么大不了的。这能帮助自己在遇到挫折时稳定心态，想得更开。”– 《腾讯传》 摘要: 原创出处:www.bysocket.com 泥瓦匠BYSocket 本文跟着我学习的脚步，进行一步一步的探索。 一、下载zookeeper服务注册管理器 下载ZooKeeper地址：http://www.apache.org/dyn/closer.cgi/zookeeper12345678910 liuxin@KK-MINI  ~  cd zookeeper-3.5.2-alpha\\ 2 liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2  lsCHANGES.txt README_packaging.txt contrib ivysettings.xml src zookeeper-3.5.2-alpha.jar.md5LICENSE.txt bin dist-maven lib zookeeper zookeeper-3.5.2-alpha.jar.sha1NOTICE.txt build.xml docs logs zookeeper-3.5.2-alpha.jarREADME.txt conf ivy.xml recipes zookeeper-3.5.2-alpha.jar.asc liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2  cd conf liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2/conf  lsconfiguration.xsl log4j.properties zoo.cfg zoo_sample.cfg liuxin@KK-MINI  ~/zookeeper-3.5.2-alpha 2/conf  在conf中创建输入zoo.cfg 123456tickTime=2000#这个地址自定义dataDir=/javaee/zookeeper/data #这个地址自定义dataLogDir=/javaee/zookeeper/logclientPort=2181 然后在bin目录中./zkServer.sh start启动 二、创建生产者 在pom文件中引入dubbo 12345 &lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-spring-boot&#125;&lt;/version&gt;&lt;/dependency&gt; application.properties 1234567## Dubbo 服务提供者配置spring.dubbo.application.name=providerspring.dubbo.registry.address=zookeeper://127.0.0.1:2181spring.dubbo.protocol.name=dubbospring.dubbo.protocol.port=20880spring.dubbo.scan=org.spring.springboot.dubboserver.port=8082 向原来创建SpringBoot项目中一样，不过注意一个注解@Service使用dubbo提供的 123456789import com.alibaba.dubbo.config.annotation.Service;@Service(version = \"1.0.1\")public class UserDubboServiceImpl implements UserDubboService &#123; @Override public User getUserByName(String name) &#123; return new User(name,\"shanghai\"); &#125;&#125; 当项目启动的时候，会把这个服务注册到zookeeper中。等到消费 三、创建消费者 pom文件中和上面引入的一样。 application.properties 1234567## 避免和 server 工程端口冲突server.port=8081## Dubbo 服务消费者配置spring.dubbo.application.name=consumerspring.dubbo.registry.address=zookeeper://127.0.0.1:2181spring.dubbo.scan=org.spring.springboot.dubbo 创建在服务提供中一样的JavaBean对象 User和UserDubboService 使用@Reference(version = &quot;1.0.1&quot;)注解引入服务 123456789@Componentpublic class UserDubboConsumerService &#123; @Reference(version = \"1.0.1\") UserDubboService userDubboService; public void getUserByName()&#123; System.out.println(userDubboService.getUserByName(\"周杰伦\")); &#125;&#125; 当项目其中的时候，会想zookeeper中查询服务生产者地址，然后直接，调用生产者服务中的服务。zookeeper是提供软负载均衡。比nginx中需要手动配置服务地址，来看，好多了。 码云地址:https://git.oschina.net/chinesszz/springboot-learning-example.git 三、引入zkui视图查看zookeeper 上面服务生产和消费都创建成功了，那么我们需要看一下。此时需要下载 zkui 地址：https://github.com/DeemOpen/zkui 开发环境中安装好maven，mvn package打包，然后将config.cfg中的zookeeper地址改为自己的zkServer=localhost:2181,localhost:2181 12345678910111213141516171819 liuxin@KK-MINI  ~/git/模仿项目/zkui/target   master  lsarchive-tmp nohup.out zkui-2.0-SNAPSHOT.jarclasses surefire-reports zkui-out.loggenerated-sources test-classesmaven-archiver zkui-2.0-SNAPSHOT-jar-with-dependencies.jar liuxin@KK-MINI  ~/git/模仿项目/zkui/target   master  java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jarPlease create config.cfg properties file and then execute the program! ✘ liuxin@KK-MINI  ~/git/模仿项目/zkui/target   master  java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.metadatatable.MetaDataTableImpl createIfNotExists信息: Creating Metadata table: \"PUBLIC\".\"schema_version\"三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.command.DbMigrate migrate信息: Current version of schema \"PUBLIC\": &lt;&lt; Empty Schema &gt;&gt;三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.command.DbMigrate applyMigration信息: Migrating schema \"PUBLIC\" to version 1三月 15, 2017 2:03:35 下午 com.googlecode.flyway.core.command.DbMigrate logSummary信息: Successfully applied 1 migration to schema \"PUBLIC\" (execution time 00:00.143s).log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. 用户账号和密码都在配置文件中… 默认 { &quot;username&quot;:&quot;admin&quot; , &quot;password&quot;:&quot;manager&quot;,&quot;role&quot;: &quot;ADMIN&quot; } 参考: 基于Zookeeper的服务注册与发现 http://www.cnblogs.com/ASPNET2008/p/5622005.html","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot项目调试之热加载","slug":"SpringBoot项目调试之热加载","date":"2017-04-12T07:25:52.000Z","updated":"2018-04-14T04:40:04.196Z","comments":true,"path":"2017/04/12/SpringBoot项目调试之热加载/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot项目调试之热加载/","excerpt":"","text":"现代IDE（Eclipse，IDEA等）都支持热交换的字节码，所以如果你做一个不影响类或方法签名的更改，它应该重新加载干净没有副作用。Spring Loaded有点进一步，它可以重新加载类定义与方法签名中的更改。有一些自定义它可以强制ApplicationContext刷新自己（但没有一般的机制，以确保对于一个正在运行的应用程序是安全的，所以它只会是一个开发时间的伎俩）。 重新加载Java类，而不重新启动容器配置用于Maven的Spring Loaded 要使用Spring Loaded与Maven命令行，只需添加它作为Spring Boot插件声明中的依赖关系，例如 123456789101112131415161718&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;version&gt;1.2.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt;## 或者是下面这个依赖 &lt;dependency&gt; &lt;groupId&gt; org.springframework.boot &lt;/ groupId&gt; &lt;artifactId&gt; spring-boot-devtools &lt;/ artifactId&gt; &lt;optional&gt; true &lt;/ optional&gt; &lt;/ dependency&gt; 这通常适用于Eclipse和IntelliJ IDEA，只要他们的构建配置与Maven默认值（Eclipse m2e这是开箱即用）一致","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot配置视图","slug":"SpringBoot配置视图","date":"2017-04-12T07:25:52.000Z","updated":"2018-04-14T04:39:50.668Z","comments":true,"path":"2017/04/12/SpringBoot配置视图/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/SpringBoot配置视图/","excerpt":"","text":"1234567891011121314151617@Configuration@EnableWebMvcpublic class ApplicationConfigurerAdapter extends WebMvcConfigurerAdapter &#123; @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; configurer.enable(); &#125; @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix(\"WEB-INF/html\"); resolver.setSuffix(\".html\"); return resolver; &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"TCP-Keepalive解读","slug":"TCP-Keepalive解读","date":"2017-04-12T05:33:55.000Z","updated":"2018-04-17T09:51:43.286Z","comments":true,"path":"2017/04/12/TCP-Keepalive解读/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/TCP-Keepalive解读/","excerpt":"","text":"Netty 扩展TCP是无感知的虚拟连接，中间断开两端不会立刻得到通知。一般在使用长连接的环境下，需要心跳保活机制可以勉强感知其存活。业务层面有心跳机制，TCP协议也提供了心跳保活机制。 TCP 活性探测理解因为TCP是无感知的虚拟连接，所以在设计底层编程的时候，如果客户端和服务端互相不知道是否中断，那么服务端可能会一直等下去，==默认情况下使用keepalive周期为2个小时，如不选择更改，属于误用范畴，造成资源浪费== Java/netty服务器如何使用只需要在服务器端一方设置即可，客户端完全不用设置，比如基于netty 4服务器程序： 12345678910111213141516171819ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .childOption(ChannelOption.SO_KEEPALIVE, true) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast( new EchoServerHandler()); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(port).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); Java程序只能做到设置SO_KEEPALIVE选项，至于TCP_KEEPCNT，TCP_KEEPIDLE，TCP_KEEPINTVL等参数配置，只能依赖于sysctl配置，系统进行读取。 具体为： ChannelOption.SO_BACKLOG, 1024BACKLOG用于构造服务端套接字ServerSocket对象，标识当服务器请求处理线程全满时，用于临时存放已完成三次握手的请求的队列的最大长度。如果未设置或所设置的值小于1，Java将使用默认值50。 ChannelOption.SO_KEEPALIVE, true是否启用心跳保活机制。在双方TCP套接字建立连接后（即都进入ESTABLISHED状态）并且在两个小时左右上层没有任何数据传输的情况下，这套机制才会被激活。 ChannelOption.TCP_NODELAY, true在TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。这里就涉及到一个名为Nagle的算法，该算法的目的就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。 TCP_NODELAY就是用于启用或关于Nagle算法。如果要求高实时性，有数据发送时就马上发送，就将该选项设置为true关闭Nagle算法；如果要减少发送次数减少网络交互，就设置为false等累积一定大小后再发送。默认为false。 系统内核参数配置以下环境是在Linux服务器上进行。应用程序若想使用，需要设置SO_KEEPALIVE套接口选项才能够生效。 tcp_keepalive_time，在TCP保活打开的情况下，最后一次数据交换到TCP发送第一个保活探测包的间隔，即允许的持续空闲时长，或者说每次正常发送心跳的周期，默认值为7200s（2h）。 tcp_keepalive_probes 在tcp_keepalive_time之后，没有接收到对方确认，继续发送保活探测包次数，默认值为9（次） tcp_keepalive_intvl，在tcp_keepalive_time之后，没有接收到对方确认，继续发送保活探测包的发送频率，默认值为75s。发送频率tcp_keepalive_intvl乘以发送次数tcp_keepalive_probes，就得到了从开始探测到放弃探测确定连接断开的时间 若设置，服务器在客户端连接空闲的时候，每90秒发送一次保活探测包到客户端，若没有及时收到客户端的TCP Keepalive ACK确认，将继续等待15秒*2=30秒。总之可以在90s+30s=120秒（两分钟）时间内可检测到连接失效与否。 以下改动，需要写入到/etc/sysctl.conf文件： 123456net.ipv4.tcp_keepalive_time=90net.ipv4.tcp_keepalive_intvl=15net.ipv4.tcp_keepalive_probes=2保存退出，然后执行sysctl -p生效。可通过 sysctl -a | grep keepalive 命令检测一下是否已经生效。针对已经设置SO_KEEPALIVE的套接字，应用程序不用重启，内核直接生效。 引用TCP Keepalive笔记","categories":[{"name":"通信","slug":"通信","permalink":"https://lxchinesszz.github.io/categories/通信/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/tags/Netty/"}],"keywords":[{"name":"通信","slug":"通信","permalink":"https://lxchinesszz.github.io/categories/通信/"}]},{"title":"SpringBoot原生定时任务解析","slug":"SpringBoot原生定时任务解析","date":"2017-04-11T07:29:14.000Z","updated":"2018-04-14T04:45:05.509Z","comments":true,"path":"2017/04/11/SpringBoot原生定时任务解析/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/11/SpringBoot原生定时任务解析/","excerpt":"","text":"#SpringBoot原生定时任务，不需要引入任何依赖 ==只要了解，几个注解就可以使用== 1.在启动类上加入@EnableScheduling标签 2.在定时任务方法上加入@Schedule(fixedDelay=5000) 3.就是如此简单，简单的不可想象 123456789101112131415161718192021222324package zebra.shjf;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.scheduling.annotation.EnableScheduling;@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TestQuartzApplication.class, args); &#125;&#125;@Componentpublic class ScheduledTasks&#123; @Scheduled(fixedDelay = 5000) public void execute() &#123; System.out.println(\"当前时间：\" + new Date()); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring定时器","slug":"Spring定时器","permalink":"https://lxchinesszz.github.io/tags/Spring定时器/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot优化方案","slug":"SpringBoot优化方案","date":"2017-03-12T08:00:13.000Z","updated":"2018-04-14T04:38:14.327Z","comments":true,"path":"2017/03/12/SpringBoot优化方案/","link":"","permalink":"https://lxchinesszz.github.io/2017/03/12/SpringBoot优化方案/","excerpt":"","text":"Bean优化1.当使用@SpringBootApplication会默认注册pom文件中拥有的为bean 默认情况下自动获取应用配置信息，会加载一些不需要的beans 增加cpu消耗 beanNames个数：261 堆内存：150-220M 2.使用@Configuration和@EnableAutoConfiguration beanNames个数：158 3.使用【不建议使用】 使用mvn spring-boot:run -Ddebug 只用装配30个左右组件就能启动 注解解释： @EnableAutoConfiguration会自动加载可能需要的配置信息 在知道需要的beans的情况下，可以使用@Import方式去配置 4.生产环境下禁止xml校验 继承XmlWebApplicationContext复写init 在web.xml文件中配置 &lt;context-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt;com.example.CustomXmlWebApplicationContext&lt;/param-value&gt; &lt;/context-param&gt; 5.减少自动扫描，尽量使用配置形式，减少初始化扫描时间 6.使用延迟初始化的bean 【Using Lazy-Initialized Beans】 lazy-init属性为true spring初始化bean就能立即发现其错误，并进行错误处理，造成的负面效应增加了应用程序的加 载时间 优化方案： 【jvisualvm】 1.不适用默认方式，采用第二种减少注册bean数量，项目中需要 的bean，采用注解方式在配置类中注册。 2.tomcat8，新特性8.5.6 Servlet 3.1、JSP 2.3、EL 3.0 Servlet 3.1实现了非阻塞式的I/O通信，性能得到 巨大的改进 参考资料： 阿里云栖社区link 51CTO开发频道link Spring Boot性能优化link Google Cloud Platform优化link Spring Boot内存优化-DZonelink","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot事务注解详解","slug":"SpringBoot事务注解详解","date":"2017-02-12T07:48:32.000Z","updated":"2018-04-14T04:38:17.191Z","comments":true,"path":"2017/02/12/SpringBoot事务注解详解/","link":"","permalink":"https://lxchinesszz.github.io/2017/02/12/SpringBoot事务注解详解/","excerpt":"","text":"关系型数据库多用到事务，在传统项目中使用xml配置，配置虽然也还好，但是看着很不美观，在使用SpringBoot框架，就简单的多了，以实战为准，直接上代码 @Transactionalspring 事务注解 1.简单开启事务管理1@EnableTransactionManagement // 启注解事务管理，等同于xml配置方式的 &lt;tx:annotation-driven /&gt; 2.事务注解详解默认遇到throw new RuntimeException(“…”);会回滚需要捕获的throw new Exception(“…”);不会回滚 指定回滚 12345@Transactional(rollbackFor=Exception.class) public void methodName() &#123; // 不会回滚 throw new Exception(\"...\"); &#125; 指定不回滚 12345@Transactional(noRollbackFor=Exception.class) public ItimDaoImpl getItemDaoImpl() &#123; // 会回滚 throw new RuntimeException(\"注释\"); &#125; 如果有事务,那么加入事务,没有的话新建一个(不写的情况下) 1@Transactional(propagation=Propagation.REQUIRED) 容器不为这个方法开启事务 1@Transactional(propagation=Propagation.NOT_SUPPORTED) 不管是否存在事务,都创建一个新的事务,原来的挂起,新的执行完毕,继续执行老的事务 1@Transactional(propagation=Propagation.REQUIRES_NEW) 必须在一个已有的事务中执行,否则抛出异常 1@Transactional(propagation=Propagation.MANDATORY) 必须在一个没有的事务中执行,否则抛出异常(与Propagation.MANDATORY相反) 1@Transactional(propagation=Propagation.NEVER) 如果其他bean调用这个方法,在其他bean中声明事务,那就用事务.如果其他bean没有声明事务,那就不用事务. 1234567891011121314@Transactional(propagation=Propagation.SUPPORTS) /*public void methodName()&#123; // 本类的修改方法 1 update(); // 调用其他类的修改方法 otherBean.update(); // 本类的修改方法 2 update();&#125;other失败了不会影响 本类的修改提交成功本类update的失败,other也失败*/ @Transactional(propagation=Propagation.NESTED) readOnly=true只读,不能更新,删除 1@Transactional (propagation = Propagation.REQUIRED,readOnly=true) 设置超时时间 1@Transactional (propagation = Propagation.REQUIRED,timeout=30) 设置数据库隔离级别 1@Transactional (propagation = Propagation.REQUIRED,isolation=Isolation.DEFAULT) 3.指定事务管理器spring Boot 使用事务非常简单，首先使用注解 @EnableTransactionManagement 开启事务支持后，然后在访问数据库的Service方法上添加注解 @Transactional 便可。 关于事务管理器，不管是JPA还是JDBC等都实现自接口 PlatformTransactionManager 如果你添加的是 spring-boot-starter-jdbc 依赖，框架会默认注入 DataSourceTransactionManager 实例。如果你添加的是 spring-boot-starter-data-jpa 依赖，框架会默认注入 JpaTransactionManager 实例。 你可以在启动类中添加如下方法，Debug测试，就能知道自动注入的是 PlatformTransactionManager 接口的哪个实现类。 3.1 打印项目事务管理器1234567891011121314@EnableTransactionManagement // 启注解事务管理，等同于xml配置方式的 &lt;tx:annotation-driven /&gt;@SpringBootApplicationpublic class ProfiledemoApplication &#123; @Bean public Object testBean(PlatformTransactionManager platformTransactionManager)&#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\" + platformTransactionManager.getClass().getName()); return new Object(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ProfiledemoApplication.class, args); &#125;&#125; 这些SpringBoot为我们自动做了，这些对我们并不透明，如果你项目做的比较大，添加的持久化依赖比较多，我们还是会选择人为的指定使用哪个事务管理器。代码如下： 3.2 指定事务管理器1234567891011121314151617181920@EnableTransactionManagement@SpringBootApplicationpublic class ProfiledemoApplication &#123; // 其中 dataSource 框架会自动为我们注入 @Bean public PlatformTransactionManager txManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean public Object testBean(PlatformTransactionManager platformTransactionManager) &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\" + platformTransactionManager.getClass().getName()); return new Object(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ProfiledemoApplication.class, args); &#125;&#125; 在Spring容器中，我们手工注解@Bean 将被优先加载，框架不会重新实例化其他的 PlatformTransactionManager 实现类。 然后在Service中，被 @Transactional 注解的方法，将支持事务。如果注解在类上，则整个类的所有方法都默认支持事务。 对于同一个工程中存在多个事务管理器要怎么处理，请看下面的实例，具体说明请看代码中的注释。 3.1 使用指定的事务管理器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@EnableTransactionManagement // 开启注解事务管理，等同于xml配置文件中的 &lt;tx:annotation-driven /&gt;@SpringBootApplicationpublic class ProfiledemoApplication implements TransactionManagementConfigurer &#123; @Resource(name=\"txManager2\") private PlatformTransactionManager txManager2; // 创建事务管理器1 @Bean(name = \"txManager1\") public PlatformTransactionManager txManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; // 创建事务管理器2 @Bean(name = \"txManager2\") public PlatformTransactionManager txManager2(EntityManagerFactory factory) &#123; return new JpaTransactionManager(factory); &#125; // 实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器 @Override public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return txManager2; &#125; public static void main(String[] args) &#123; SpringApplication.run(ProfiledemoApplication.class, args); &#125;&#125;@Componentpublic class DevSendMessage implements SendMessage &#123; // 使用value具体指定使用哪个事务管理器 @Transactional(value=\"txManager1\") @Override public void send() &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;Dev Send()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\"); send2(); &#125; // 在存在多个事务管理器的情况下，如果使用value具体指定 // 则默认使用方法 annotationDrivenTransactionManager() 返回的事务管理器 @Transactional public void send2() &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;Dev Send2()&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\"); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"线程数究竟设多少合理","slug":"线程数究竟设多少合理","date":"2017-02-12T03:34:53.000Z","updated":"2018-04-14T04:40:43.166Z","comments":true,"path":"2017/02/12/线程数究竟设多少合理/","link":"","permalink":"https://lxchinesszz.github.io/2017/02/12/线程数究竟设多少合理/","excerpt":"","text":"分享一篇，关于线程的经典文章。 一、需求缘起Web-Server通常有个配置，最大工作线程数，后端服务一般也有个配置，工作线程池的线程数量，这个线程数的配置不同的业务架构师有不同的经验值，有些业务设置为CPU核数的2倍，有些业务设置为CPU核数的8倍，有些业务设置为CPU核数的32倍。“工作线程数”的设置依据是什么，到底设置为多少能够最大化CPU性能，是本文要讨论的问题。 二、一些共性认知在进行进一步深入讨论之前，先以提问的方式就一些共性认知达成一致。 提问：工作线程数是不是设置的越大越好？回答：肯定不是的 1）一来服务器CPU核数有限，同时并发的线程数是有限的，1核CPU设置10000个工作线程没有意义 2）线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低 提问：调用sleep()函数的时候，线程是否一直占用CPU？ 回答：不占用，等待时会把CPU让出来，给其他需要CPU资源的线程使用 不止调用sleep()函数，在进行一些阻塞调用，例如网络编程中的阻塞accept()【等待客户端连接】和阻塞recv()【等待下游回包】也不占用CPU资源 提问：如果CPU是单核，设置多线程有意义么，能提高并发性能么？ 回答：即使是单核，使用多线程也是有意义的1）多线程编码可以让我们的服务/代码更加清晰，有些IO线程收发包，有些Worker线程进行任务处理，有些Timeout线程进行超时检测 2）如果有一个任务一直占用CPU资源在进行计算，那么此时增加线程并不能增加并发，例如这样的一个代码 while(1){ i++; } 该代码一直不停的占用CPU资源进行计算，会使CPU占用率达到100% 3）通常来说，Worker线程一般不会一直占用CPU进行计算，此时即使CPU是单核，增加Worker线程也能够提高并发，因为这个线程在休息的时候，其他的线程可以继续工作 三、常见服务线程模型了解常见的服务线程模型，有助于理解服务并发的原理，一般来说互联网常见的服务线程模型有如下两种 IO线程与工作线程通过队列解耦类模型 如上图，大部分Web-Server与服务框架都是使用这样的一种“IO线程与Worker线程通过队列解耦”类线程模型： 1）有少数几个IO线程监听上游发过来的请求，并进行收发包（生产者） 2）有一个或者多个任务队列，作为IO线程与Worker线程异步解耦的数据传输通道（临界资源） 3）有多个工作线程执行正真的任务（消费者） 这个线程模型应用很广，符合大部分场景，这个线程模型的特点是，工作线程内部是同步阻塞执行任务的（回想一下tomcat线程中是怎么执行Java程序的，dubbo工作线程中是怎么执行任务的），因此可以通过增加Worker线程数来增加并发能力，今天要讨论的重点是“该模型Worker线程数设置为多少能达到最大的并发”。 纯异步线程模型任何地方都没有阻塞，这种线程模型只需要设置很少的线程数就能够做到很高的吞吐量，Lighttpd有一种单进程单线程模式，并发处理能力很强，就是使用的的这种模型。该模型的缺点是： 1）如果使用单线程模式，难以利用多CPU多核的优势 2）程序员更习惯写同步代码，callback的方式对代码的可读性有冲击，对程序员的要求也更高 3）框架更复杂，往往需要server端收发组件，server端队列，client端收发组件，client端队列，上下文管理组件，有限状态机组件，超时管理组件的支持however，这个模型不是今天讨论的重点。 四、工作线程的工作模式了解工作线程的工作模式，对量化分析线程数的设置非常有帮助： 上图是一个典型的工作线程的处理过程，从开始处理start到结束处理end，该任务的处理共有7个步骤： 1）从工作队列里拿出任务，进行一些本地初始化计算，例如http协议分析、参数解析、参数校验等 2）访问cache拿一些数据 3）拿到cache里的数据后，再进行一些本地计算，这些计算和业务逻辑相关 4）通过RPC调用下游service再拿一些数据，或者让下游service去处理一些相关的任务 5）RPC调用结束后，再进行一些本地计算，怎么计算和业务逻辑相关 6）访问DB进行一些数据操作 7）操作完数据库之后做一些收尾工作，同样这些收尾工作也是本地计算，和业务逻辑相关 分析整个处理的时间轴，会发现： 1）其中1，3，5，7步骤中【上图中粉色时间轴】，线程进行本地业务逻辑计算时需要占用CPU 2）而2，4，6步骤中【上图中橙色时间轴】，访问cache、service、DB过程中线程处于一个等待结果的状态，不需要占用CPU，进一步的分解，这个“等待结果”的时间共分为三部分： 2.1）请求在网络上传输到下游的cache、service、DB 2.2）下游cache、service、DB进行任务处理 2.3）cache、service、DB将报文在网络上传回工作线程 五、量化分析并合理设置工作线程数最后一起来回答工作线程数设置为多少合理的问题。 通过上面的分析，Worker线程在执行的过程中，有一部计算时间需要占用CPU，另一部分等待时间不需要占用CPU，通过量化分析，例如打日志进行统计，可以统计出整个Worker线程执行过程中这两部分时间的比例，例如： 1）时间轴1，3，5，7【上图中粉色时间轴】的计算执行时间是100ms 2）时间轴2，4，6【上图中橙色时间轴】的等待时间也是100ms 得到的结果是，这个线程计算和等待的时间是1：1，即有50%的时间在计算（占用CPU），50%的时间在等待（不占用CPU）： 1）假设此时是单核，则设置为2个工作线程就可以把CPU充分利用起来，让CPU跑到100% 2）假设此时是N核，则设置为2N个工作现场就可以把CPU充分利用起来，让CPU跑到N*100% 结论：N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。 经验：一般来说，非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务），瓶颈都在后端数据库，本地CPU计算的时间很少，所以设置几十或者几百个工作线程也都是可能的。 六、结论N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。 开源中国原文","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://lxchinesszz.github.io/tags/线程/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"HEXO之博客搭建","slug":"HEXO之博客搭建","date":"2016-09-14T03:49:42.000Z","updated":"2018-04-14T04:37:30.092Z","comments":false,"path":"2016/09/14/HEXO之博客搭建/","link":"","permalink":"https://lxchinesszz.github.io/2016/09/14/HEXO之博客搭建/","excerpt":"","text":"HEXO 安装hexo博客工具1npm install -g hexo-cli 初始化目录1hexo init 生成静态页面1hexo g 清理缓存1hexo clean 推送到服务器推送时候要先: npm install hexo-deployer-git –save安装依赖 修改 123456# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://lxchinesszz.gitee.io/chinesszz/ 访问地址root: /chinesszz 访问项目permalink: :year/:month/:day/:title/permalink_defaults: 1hexo d 本地服务预览1hexo s 查看1浏览器: http://127.0.0.1:4000/ 绑定码云 修改配置项目根目录_config.yml 文件，修改deploy的值然后保存 1234deploy: type: git repo: https://gitee.com/lxchinesszz/chinesszz.git branch: 分支 在oschina中点击服务,启动pages静态访问 绑定到GITHUB 当绑定到github上需要常见仓库为 用户名.github.io 购买域名并转发到github 购买域名,并备案 配置域名转发 在github上仓库点击Setting设置域名","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://lxchinesszz.github.io/tags/博客搭建/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"SpringBoot之开始and销毁注解","slug":"SpringBoot之开始and销毁注解","date":"2016-06-12T08:02:37.000Z","updated":"2018-04-14T04:38:07.924Z","comments":true,"path":"2016/06/12/SpringBoot之开始and销毁注解/","link":"","permalink":"https://lxchinesszz.github.io/2016/06/12/SpringBoot之开始and销毁注解/","excerpt":"","text":"12345678910111213141516@Componentpublic class InitMain &#123; @PostConstruct public void init()&#123; System.out.println(\"执行初始化方法\"); &#125; public void say()&#123; System.out.println(\"正常方法\"); &#125; @PreDestroy public void destory()&#123; System.out.println(\"执行销毁方法\"); &#125;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Logback高级用法","slug":"Logback高级用法","date":"2016-06-12T05:26:12.000Z","updated":"2018-04-14T04:37:34.876Z","comments":true,"path":"2016/06/12/Logback高级用法/","link":"","permalink":"https://lxchinesszz.github.io/2016/06/12/Logback高级用法/","excerpt":"","text":"在日常的生产中，尤其是在微服务盛行的今天,我们的服务很可能是作为分布式应用上的一个点，会接受来自不同客户端的请求，那么在服务的为每行日志标记出来自的客户端呢？本篇我们通过介绍Logback的高级用法，来为大家实现。 日志扩展 扩展知识 在分布式应用的今天，如何通过日志把客户端请求的不同应用的日志串起来，展示呢 首先分析原理其实很简单，就是为每个线程保存点私有变量，这个私有变量的值，由我们自定义，用于区分不同的应用。 说到线程的私有变量，可能老程序猿，就想到这个类及 ThreadLocal ,关于个类的源码分析，小编已经写过了，这里就不解释了，继续… ,我们今天用到的这个 MDC 就是为每个线程请求保存私有变量，然后在输出日志的时候打印出来，这样就能标识出，每一行日志的来源。 代码实现Logback 框架已经为我们实现了一套常用的请求，今天我们就用，这个来演示。MDCInsertingServletFilter 我们看一下该类的源码分析一下: 12345678910111213141516171819202122232425262728public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; this.insertIntoMDC(request); try &#123; chain.doFilter(request, response); &#125; finally &#123; this.clearMDC(); &#125; &#125; void insertIntoMDC(ServletRequest request) &#123; MDC.put(\"req.remoteHost\", request.getRemoteHost()); if(request instanceof HttpServletRequest) &#123; HttpServletRequest httpServletRequest = (HttpServletRequest)request; MDC.put(\"req.requestURI\", httpServletRequest.getRequestURI()); StringBuffer requestURL = httpServletRequest.getRequestURL(); if(requestURL != null) &#123; MDC.put(\"req.requestURL\", requestURL.toString()); &#125; MDC.put(\"req.method\", httpServletRequest.getMethod()); MDC.put(\"req.queryString\", httpServletRequest.getQueryString()); MDC.put(\"req.userAgent\", httpServletRequest.getHeader(\"User-Agent\")); MDC.put(\"req.xForwardedFor\", httpServletRequest.getHeader(\"X-Forwarded-For\")); &#125; &#125; 就是利用 MDC 为每个处理请求的线程添加上私有变量。就是如此，不过我们要注意的是为了让MDC中的信息在任何时候都是正确有效的，我们需要在request被处理之前，就讲相关信息放入mdc，再在处理完后，clear掉。大家看到其实这个类是继承了 Filter 就是一个过滤器，在这里小编用的是 SpringBoot实现的 那么如何使用呢？ 12345678910111213141516171819/** * @Package: firebird.logger.config.filter * @Description: 应用配置 * @author: liuxin * @date: 2017/8/29 下午5:32 */@Componentpublic class ApplicationConfig &#123; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); Filter actionFilter = new MDCInsertingServletFilter(); registrationBean.setFilter(actionFilter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add(\"/*\"); registrationBean.setUrlPatterns(urlPatterns); return registrationBean; &#125;&#125; Loback打印日志该教程还是参考了我之前写的日志错误提醒框架，所以注释部分包括了使用 Sentry的部分代码，如果对错误收集框架感兴趣的同学，可以看我的另一篇博客SpringBoot整合Sentry 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;configuration&gt; &lt;!-- 彩色日志 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(--)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt;/&gt; &lt;property name=\"MDC_LOG_PATTERN\" value=\"IP:%X&#123;req.remoteHost&#125; -url:%X&#123;req.requestURI&#125; -Method:%X&#123;req.method&#125; - QueryString:%X&#123;req.queryString&#125; - device:%X&#123;req.userAgent&#125; -ips:%X&#123;req.xForwardedFor&#125; - %m%n \"&gt;&lt;/property&gt; &lt;appender name=\"Console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;layout&gt; &lt;pattern&gt;$&#123;MDC_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!--&lt;appender name=\"Sentry\" class=\"com.getsentry.raven.logback.SentryAppender\"&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;每个项目生成不通的key&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;dsn&gt;http://d73b23c481654b9ca0e4e8a9db310169:daaf5dc2edef462690791ef324316738@sentry.boluome.com/7&lt;/dsn&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash; 设置拦截的最低级别为warn 警告&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;--&gt; &lt;!--&lt;level&gt;WARN&lt;/level&gt;--&gt; &lt;!--&lt;/filter&gt;--&gt; &lt;!--&lt;/appender&gt;--&gt; &lt;!--&lt;logger name=\"logback.SentryAppenderIT\" level=\"INFO\"&gt;--&gt; &lt;!--&lt;appender-ref ref=\"Sentry\"/&gt;--&gt; &lt;!--&lt;/logger&gt;--&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"Console\"/&gt; &lt;!--&lt;appender-ref ref=\"Sentry\"/&gt;--&gt; &lt;/root&gt;&lt;/configuration&gt; 可以看到 MDC_LOG_PATTERN 中获取了从MDC过滤器中的参数，这样我们就能打印出来了 代码测试12345678910111213141516171819IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - URL : http://localhost:10111/loggerIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 请求类型 : GETIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 请求IP : 0:0:0:0:0:0:0:1IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 方法 : firebird.logger.rest.OtoRestController.testLoggerIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 参数列表 : []IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - hello world !!!IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - hello world !!!IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 返回参数 : 请查看日志IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - -----------------方法执行完毕,耗时:1ms-------------------IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - ----------testLogger方法开始执行----------------------------IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - URL : http://192.168.199.235:10111/loggerIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 请求类型 : GETIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 请求IP : 192.168.199.191IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 方法 : firebird.logger.rest.OtoRestController.testLoggerIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 参数列表 : []IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - hello world !!!IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - hello world !!!IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 返回参数 : 请查看日志IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - -----------------方法执行完毕,耗时:0ms------------------- 扩展方法如何实现呢? 不积跬步无以至千里,接下来还有要学习如何使用 Logstash kibana elasticsearch","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://lxchinesszz.github.io/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"SpringBoot之AutoConfig自动配置","slug":"SpringBoot之AutoConfig自动配置","date":"2016-05-12T08:03:13.000Z","updated":"2018-04-14T04:38:01.083Z","comments":true,"path":"2016/05/12/SpringBoot之AutoConfig自动配置/","link":"","permalink":"https://lxchinesszz.github.io/2016/05/12/SpringBoot之AutoConfig自动配置/","excerpt":"","text":"1. @XxxxAuto在SpringBoot中有很多以XxxxAutoConfiguration注解，其实他的作用就是,自动配置当前模块要依赖的类 例如: @EnableAutoConfiguration 就告诉SpringBoot需要加载那些类,spring-boot-1.5.1.RELEASE.jar/META-INF/spring.factories 在该文件中 2. @Enable@SpringBootApplication其实也是有以下三个注解组成的 @EnableAutoConfiguration 自动依赖当前所有模块的配置类org/springframework/boot/spring-boot-autoconfigure/1.5.2.RELEASE/spring-boot-autoconfigure-1.5.2.RELEASE.jar!/META-INF/spring.factories @ComponentScan 扫描class @Configuration 配置 当我们不在启动类添加@EnableAutoConfiguration时候,我们要自定义要依赖的模块,就要使用 @EnableAsync @EnableScheduling @EnableWebMVC @EnableConfigurationProperties @EnableJpaRepositories @EnableTransactionManagement @EnableCaching 其实@EnableAutoConfiguration这个注解,都是从自己的模块中查询spring.factories文件,所以当应用启动就加载spring-boot-autoconfigure中的Spring.factories 代码中是12345678910类:AutoConfigurationImportSelector方法:public String[] selectImports(AnnotationMetadata annotationMetadata)AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader)public static AutoConfigurationMetadata loadMetadata(ClassLoader classLoader) &#123; return loadMetadata(classLoader, \"META-INF/spring-autoconfigure-metadata.properties\"); &#125; 具体的模块会导入不同的EnableConfigurationPropertiesImportSelector,然后复写selectImports方法,从当前类名中拿到包名+中依赖的信息,然后加载 1234567891011Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123; Class&lt;? extends Annotation&gt; annotation() default Annotation.class; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; 生注册Bean或者是添加配置时候我们可以更加细化 @ConditionalOnClass ： classpath中存在该类时起效 @ConditionalOnMissingClass ： classpath中不存在该类时起效 @ConditionalOnBean ： DI容器中存在该类型Bean时起效 @ConditionalOnMissingBean ： DI容器中不存在该类型Bean时起效 @ConditionalOnSingleCandidate ： DI容器中该类型Bean只有一个或@Primary的只有一个时起效 @ConditionalOnExpression ： SpEL表达式结果为true时 @ConditionalOnProperty ： 参数设置或者值一致时起效 @ConditionalOnResource ： 指定的文件存在时起效 @ConditionalOnJndi ： 指定的JNDI存在时起效 @ConditionalOnJava ： 指定的Java版本存在时起效 @ConditionalOnWebApplication ： Web应用环境下起效 @ConditionalOnNotWebApplication ： 非Web应用环境下起效 执行顺序 @AutoConfigureAfter：在指定的配置类初始化后再加载 @AutoConfigureBefore：在指定的配置类初始化前加载 @AutoConfigureOrder：数越小越先初始化 自定义Conditional约束类12345678910111213141516171819202122232425public class ConditionalOtoSaasApplication extends SpringBootCondition &#123; @Override public ConditionOutcome getMatchOutcome(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; Object name = annotatedTypeMetadata.getAnnotationAttributes(ConditionalOnMyProperties.class.getName()).get(\"name\"); conditionContext.getEnvironment(); if (((String) name).equalsIgnoreCase(\"test\")) &#123; return new ConditionOutcome(true, \"get name properties\"); &#125; return new ConditionOutcome(false, \"no get name properties\"); &#125;&#125;@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(ConditionalOtoSaasApplication.class)public @interface ConditionalOnMyProperties &#123; String name();&#125;@Configuration@ConditionalOnMyProperties(name = \"test\")public class BlmConfig &#123; private String url; private String name;&#125;","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot添加过滤器-两种实现方式","slug":"SpringBoot添加过滤器-两种实现方式","date":"2016-04-12T08:01:58.000Z","updated":"2018-04-14T04:39:19.540Z","comments":true,"path":"2016/04/12/SpringBoot添加过滤器-两种实现方式/","link":"","permalink":"https://lxchinesszz.github.io/2016/04/12/SpringBoot添加过滤器-两种实现方式/","excerpt":"","text":"集成Filter接口 public class MDCInsertingServletFilter implements Filter { /** * @Package: firebird.logger.config.filter * @Description: 应用配置 * @author: liuxin * @date: 2017/8/29 下午5:32 */ @Component public class ApplicationConfig { @Bean public FilterRegistrationBean filterRegistrationBean() { FilterRegistrationBean registrationBean = new FilterRegistrationBean(); Filter actionFilter = new MDCInsertingServletFilter(); registrationBean.setFilter(actionFilter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add(&quot;/*&quot;); registrationBean.setUrlPatterns(urlPatterns); return registrationBean; } } 使用注解 @WebFilter(filterName=”AppCodeInsertServletFilter”,urlPatterns={“/*”}) @ServletComponentScan 在启动类添加注解 @ServletComponentScan 扫描Servlet注解 @ServletComponentScan @SpringBootApplication public class OtoSaasApplication { public static void main(String[] args) { SpringApplication.run(OtoSaasApplication.class, args); } } 2.继承Filter 并添加 @WebFilter @WebFilter(filterName=&quot;HttpServletRequestReplacedFilter&quot;,urlPatterns={&quot;/*&quot;}) public class HttpServletRequestReplacedFilter implements Filter { ... } 验证是否添加成功 2017-11-15T14:05:14.144 INFO oto_saas__pay o.s.boot.web.servlet.FilterRegistrationBean [line:271 Mapping filter: &apos;HttpServletRequestReplacedFilter&apos; to urls: [/*]]","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"SpringBoot读取两种格式的配置文件","slug":"SpringBoot读取两种格式的配置文件","date":"2016-04-12T07:54:36.000Z","updated":"2018-04-14T04:39:36.046Z","comments":true,"path":"2016/04/12/SpringBoot读取两种格式的配置文件/","link":"","permalink":"https://lxchinesszz.github.io/2016/04/12/SpringBoot读取两种格式的配置文件/","excerpt":"","text":"一般情况下我们常用Enventment读取配置，读取.properties，本篇文章主要从.properties和.yml文件来分析如何使用.也谈不上分析，直接上代码，一看就会了。如果不会yml的同学，直接看代码也能看懂了(规则是死的会用就ok) 首先引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 读取.propertiesmaster.ds.url=jdbc:mysql://localhost:3306/testmaster.ds.username=rootmaster.ds.password=root 1234567@ConfigurationProperties(prefix = \"master.ds\",locations = \"classpath:application.properties\") public class PropsConfig &#123; private String url; private String username; private String password; &#125; 读取yml1234567891011121314myProps: #自定义的属性和值 simpleProp: simplePropValue arrayProps: 1,2,3,4,5 listProp1: - name: abc value: abcValue - name: efg value: efgValue listProp2: - config2Value1 - config2Vavlue2 mapProps: key1: value1 key2: value2 1234567@ConfigurationProperties(prefix=\"myProps\") //application.yml中的myProps下的属性 public class YmlConfig &#123; private String simpleProp; private String[] arrayProps; private List&lt;Map&lt;String, String&gt;&gt; listProp1 = new ArrayList&lt;&gt;(); //接收prop1里面的属性值 private List&lt;String&gt; listProp2 = new ArrayList&lt;&gt;(); //接收prop2里面的属性值 private Map&lt;String, String&gt; mapProps = new HashMap&lt;&gt;(); //接收prop1里面的属性值","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"RequestMapper参数说明","slug":"RequestMapper参数说明","date":"2016-04-12T07:52:27.000Z","updated":"2018-04-14T04:37:45.052Z","comments":true,"path":"2016/04/12/RequestMapper参数说明/","link":"","permalink":"https://lxchinesszz.github.io/2016/04/12/RequestMapper参数说明/","excerpt":"","text":"1234567891011/*** @param account 账户id* @param quota 充钱金额(元)* @return*/@RequestMapping(value = \"/&#123;account&#125;/account/quota\", method = RequestMethod.POST,consumes = \"application/json\")//方法仅处理request Content-Type为“application/json”类型的请求。@RequestMapping(value = \"/&#123;account&#125;/account/quota\", method = RequestMethod.POST, produces=\"application/json\",params=\"myParam=myValue\",headers=\"Referer=http://www.ifeng.com/\")//方法仅处理request请求中Accept头中包含了\"application/json\"的请求，同时暗示了返回的内容类型为application/json;//仅处理请求中包含了名为“myParam”，值为“myValue”的请求；//headers 请求头中包含这个的地址 consumes = “application/json” 请求头 produces=”application/json” 响应头","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Tomcat7和Tomcat8的区别","slug":"Tomcat7和Tomcat8的区别","date":"2016-03-12T05:12:59.000Z","updated":"2018-04-14T04:40:26.131Z","comments":true,"path":"2016/03/12/Tomcat7和Tomcat8的区别/","link":"","permalink":"https://lxchinesszz.github.io/2016/03/12/Tomcat7和Tomcat8的区别/","excerpt":"","text":"因为一次意外的原意，我部署了两个web容器 本地mac上是tomcat8 远程服务器是tomcat7 同时这两个web容器都使用nginx代理,项目打包在本地没有任何问题 但是在远程服务器就会出现图片加载不出来，应该是以汉字结尾的数据，不能够加载，刚开始是找到不到问题，原因。 因为所有以中文命名的图片和表格都是在一个文件夹，下面，所以以为，改文件夹没有被编译进去，但是最后发现确实是在。 然后我手动在远程服务器改文件夹，下面touch dadfa&gt;1.txt然后去访问1.txt结果却能访问，忽然豁然开朗，找到原因就是因为汉字不能够解析，然后搜索解决办法 tomcat7:URIEncodingThis specifies the character encoding used to decode the URI bytes, after %xx decoding the URL. If not specified, ISO-8859-1 will be used 这个参数用来设置解码url参数，如果没指定，默认是ISO-8859-1。 tomcat8:URIEncodingThis specifies the character encoding used to decode the URI bytes, after %xx decoding the URL. If not specified, UTF-8 will be used unless the org.apache.catalina.STRICT_SERVLET_COMPLIANCE system property is set to true in which case ISO-8859-1 will be used.这个参数用来设置解码url参数，如果没指定，默认是UTF-8，除非设置了org.apache.catalina.STRICT_SERVLET_COMPLIANCE这个系统参数为true，这个时候会使用ISO-8859-1。 123456&lt;Connector port=\"8080\" URIEncoding=\"utf-8\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"StringBoot整合Shiro","slug":"StringBoot整合Shiro","date":"2016-01-12T07:52:56.000Z","updated":"2018-04-14T04:40:14.640Z","comments":true,"path":"2016/01/12/StringBoot整合Shiro/","link":"","permalink":"https://lxchinesszz.github.io/2016/01/12/StringBoot整合Shiro/","excerpt":"","text":"首先第一步引入12345&lt;!--shiro权限控制框架--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; 添加配置类 安全管理器(在管理器中添加自己的验证密码和权限的方法) 123456@Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(myShiroRealm()); return securityManager; &#125; 配置拦截链 拦截链的意思，就是给url赋值权限 12345678910111213141516171819202122232425262728293031/** * ShiroFilterFactoryBean 处理拦截资源文件问题。 * 注意：单独一个ShiroFilterFactoryBean配置是或报错的，以为在 * 初始化ShiroFilterFactoryBean的时候需要注入：SecurityManager * * Filter Chain定义说明 1、一个URL可以配置多个Filter，使用逗号分隔 2、当设置多个过滤器时，全部验证通过，才视为通过 * 3、部分过滤器可指定参数，如perms，roles * */ @Bean public ShiroFilterFactoryBean shirFilter(SecurityManager securityManager) &#123; ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); // 必须设置 SecurityManager shiroFilterFactoryBean.setSecurityManager(securityManager); // 如果不设置默认会自动寻找Web工程根目录下的\"admin登录页面\"页面 shiroFilterFactoryBean.setLoginUrl(\"/admin/login\"); // 登录成功后要跳转的链接 shiroFilterFactoryBean.setSuccessUrl(\"/index\"); // 未授权界面; shiroFilterFactoryBean.setUnauthorizedUrl(\"/403\"); // 拦截器. Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;String, String&gt;(); filterChainDefinitionMap.put(\"/admin/login\", \"anon\");//登录页面 //TODO 跟登录权限,添加权限test测试。 filterChainDefinitionMap.put(\"/admin/index\", \"authc,perms[\" +\"test\" + \"]\");//校验密码和权限 // 配置退出过滤器,其中的具体的退出代码Shiro已经替我们实现了 filterChainDefinitionMap.put(\"/logout\", \"logout\"); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; &#125; 实现Realm doGetAuthenticationInfo 校验密码 1234567891011121314151617181920212223/** * 校验用户名和密码 * * @param authcToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authcToken) throws AuthenticationException &#123; logger.debug(\"身份认证方法：MyShiroRealm.doGetAuthenticationInfo()\"); UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) authcToken; //TODO 根据用户名和用户密码判断用户，用户验证成功，就把用户名和用户密码放行 String userName = usernamePasswordToken.getUsername(); Admin user = mongoDao.findOneByQuery(Admin.class, \"userName\", usernamePasswordToken.getUsername()); String pwd = String.valueOf(usernamePasswordToken.getPassword()); if (ObjectUtils.isEmpty(user))&#123; throw new IncorrectCredentialsException(); &#125; if (StringUtils.endsWithIgnoreCase(user.getPassword(), pwd)) &#123; return new SimpleAuthenticationInfo(userName, pwd, getName()); &#125; return null; &#125; doGetAuthorizationInfo 在本方法中,查询用户的所有权限，然后添加 123456789101112131415161718192021/** * 权限链配置 * 在shiro配置类中把资源对应的权限都加载到应用中 * * 在本方法中,查询用户的所有权限，然后添加 * * @param principals * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; logger.debug(\"##################执行Shiro权限认证##################\"); //获取当前登录输入的用户名，等价于 String userName = (String) super.getAvailablePrincipal(principals); logger.debug(\"##################开始查询用户【\" + userName + \"】的权限##################\"); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); //根据每个用户名获得对应的权限列表 //根据用户名获取用户的权限 info.addStringPermission(\"test\"); return info; &#125; ​","categories":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/tags/Spring-Boot/"}],"keywords":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"ELK服务搭建之Kibana使用说明","slug":"ELK服务搭建之Kibana使用说明","date":"2016-01-12T03:29:04.000Z","updated":"2018-04-14T04:16:05.594Z","comments":true,"path":"2016/01/12/ELK服务搭建之Kibana使用说明/","link":"","permalink":"https://lxchinesszz.github.io/2016/01/12/ELK服务搭建之Kibana使用说明/","excerpt":"","text":"前言logstash 通过配置文件把收集到的日志文件，通过正则匹配分析，发送到es服务器构建索引，并通过Kibana展示 目录 Logstash正则构建 查询语句 量化分析 Visualize 仪表盘 Dashboard Logstash正则匹配正则工具官方文档 在logstash目录 mkdir patterns 12# contents of ./patterns/postfix:STR [a-zA-Z]&#123;1,&#125; 12345678910111213141516171819input &#123; file &#123; type =&gt; \"order_shenghuojiaofei\"truepath =&gt; \"/Users/liuxin/rabbitmql_pro.log\" &#125; &#125;filter &#123; grok &#123; patterns_dir =&gt; [\"./patterns\"] match =&gt; &#123; \"message\" =&gt; \"%&#123;STR:logLevel&#125; %&#123;STR:packName&#125;.%&#123;STR:thread&#125;.%&#123;STR:className&#125; %&#123;STR:date&#125;\" &#125;true&#125; &#125;output &#123;trueelasticsearch &#123;truetruehosts =&gt; \"127.0.0.1:9200\"truetrueindex =&gt; \"order_shenghuojiaofei-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\"truetruetemplate_overwrite =&gt; truetruetrue &#125;true &#125; 启动 logstash -f pro.conf 查询语句I. 字段查询(可以使用通配符*或?) 1field:value 例：city:Keyport*， age:26 II. 范围查询 12age:[20 TO 30] age:&#123;20 TO 30&#125;注：[ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内 III. 逻辑操作 1234AND OR 例子：firstname:H* AND age:20 firstname:H* OR age:20+ ：搜索结果中必须包含此项- ：不能含有此项例： +firstname:H* -age:20 city:H* firstname字段结果中必须存在H开头的，不能有年龄是20的，city字段H开头的可有可无 VI. 分组查询 1234分组(firstname:H* OR age:20) AND state:KS 先查询名字H开头年龄或者是20的结果，然后再与国家是KS的结合字段分组firstname:(+H* -He*) 搜索firstname字段里H开头的结果，并且排除firstname里He开头的结果 量化分析点击发现 Discover 输入查询条件 鼠标放置在字段上会添加展示改字段 Kibana参考文档 仪表盘Visualize 生成的报表信息，可以保存，放置在仪表盘里面展示","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://lxchinesszz.github.io/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"ELK服务搭建之初识","slug":"ELK服务搭建之初识","date":"2016-01-12T03:27:45.000Z","updated":"2018-04-14T04:37:23.949Z","comments":true,"path":"2016/01/12/ELK服务搭建之初识/","link":"","permalink":"https://lxchinesszz.github.io/2016/01/12/ELK服务搭建之初识/","excerpt":"","text":"logback配置详情 ELK E elasticsearch 负责对日志进行索引 L logstash 负责收集日志,输出到els K Kibaba 负责展示es索引的页面 Kibaba5.5.0 只支持Es5.5.0及以上版本 安装 elasticsearch 注意问题 1234Likely root cause: expected '&lt;document start&gt;', but found BlockMappingStart in 'reader', line 54, column 1: network.bind_host: 0.0.0.0 ^ 解决办法 参数key 前面要加空格 最小配置1234567path.data: /Users/liuxin/elasticsearch-5.5.2/datapath.logs: /Users/liuxin/elasticsearch-5.5.2/logsnetwork.bind_host: 0.0.0.0 network.publish_host: 127.0.0.1 network.host: m000 elasticsearch.yml配置详解 下载地址 安装Logstash解压配置环境变量 12345678910111213141516 liuxin@MacBook-Pro  ~/logstash-2.4.0  cat pro.confinput &#123; file &#123; type =&gt; \"rabbitmq-test\" path =&gt; \"/Users/liuxin/rabbitmql_pro.log\"true &#125;true &#125;true output &#123;true elasticsearch &#123;true hosts =&gt; \"127.0.0.1:9200\"truetrue index =&gt; \"logstash-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\"truetrue template_overwrite =&gt; truetruetruetrue &#125;truetruetrue &#125; liuxin@MacBook-Pro  ~/logstash-2.4.0  启动命令 : logstash -f pro.conf Logstash详解 安装Kibaba最小配置 123server.port: 5601server.host: \"localhost\"elasticsearch.url: \"http://localhost:9200\" 启动 bash kibana 以上方法是通过logstash读取文件的形式收集日志也可以应用主动发起日志logback.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;configuration debug=\"false\"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name=\"LOG_HOME\" value=\"E:/logs\" /&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log_%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" /&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.QueryParameters\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.query.HQLQueryPlan\" level=\"DEBUG\" /&gt; &lt;!--myibatis log configure--&gt; &lt;logger name=\"com.apache.ibatis\" level=\"TRACE\" /&gt; &lt;logger name=\"java.sql.Connection\" level=\"DEBUG\" /&gt; &lt;logger name=\"java.sql.Statement\" level=\"DEBUG\" /&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"DEBUG\" /&gt; &lt;appender name=\"stash\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt; &lt;destination&gt;192.168.10.200:8082&lt;/destination&gt; &lt;!-- encoder is required --&gt; &lt;encoder charset=\"UTF-8\" class=\"net.logstash.logback.encoder.LogstashEncoder\" /&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=\"INFO\"&gt; &lt;!-- 只有添加stash关联才会被收集--&gt; &lt;appender-ref ref=\"stash\" /&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt;&lt;/configuration&gt; pom 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt;&lt;/dependency&gt;&lt;!--实现slf4j接口并整合--&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.logstash.log4j&lt;/groupId&gt; &lt;artifactId&gt;jsonevent-layout&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt;&lt;/dependency&gt;","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://lxchinesszz.github.io/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"CentOs配置防火墙","slug":"CentOs配置防火墙","date":"2015-06-12T10:31:57.000Z","updated":"2018-04-14T04:37:13.862Z","comments":true,"path":"2015/06/12/CentOs配置防火墙/","link":"","permalink":"https://lxchinesszz.github.io/2015/06/12/CentOs配置防火墙/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334使用命令的方式配置CentOS7防火墙##Addfirewall-cmd --permanent --zone=public --add-port=80/tcp##Removefirewall-cmd --permanent --zone=public --remove-port=80/tcp##Reloadfirewall-cmd --reload复制代码检查是否生效firewall-cmd --zone=public --query-port=80/tcp列出所有的开放端口firewall-cmd --list-all查看防火墙状态systemctl status firewalld.service启动防火墙systemctl start firewalld.service关闭防火墙systemctl stop firewalld.service重新启动防火墙systemctl restart firewalld.service","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"本地服务器搭建","slug":"本地服务器搭建","date":"2015-04-12T05:35:42.000Z","updated":"2018-04-14T04:40:36.678Z","comments":true,"path":"2015/04/12/本地服务器搭建/","link":"","permalink":"https://lxchinesszz.github.io/2015/04/12/本地服务器搭建/","excerpt":"","text":"工作之余，本人一直想买一台服务器，介于价格，一忍再忍，穷逼一个，无奈之下，萌生一个想法，通过自己的两台电脑，自己搭建一个服务器。 尤其之前用的ubuntu系统，用了三个多月，期间发现很多bug，所以准备换回centOS6，首先使用大白菜，把系统换位win10专业版，然后安装VMware10，在虚拟机里面安装CentOS6，因为两台电脑之间用的是同一个网络，所以可以互相连接。以下是我的操作步骤。 准备工作 两台电脑，同一个网络 1.服务器创建用户 首先创建一个组 groupadd -g 1500 maclink //g参数就是组id 如果不加默认是1000 开始 添加一个用户 useradd macuser -g maclink //添加一个用户名为macuser的用户在macgroup组中 如果你忘记你创建的组，那么使用下面的命令查看所有的组cat /etc/group 2.查看互相的ip mac系统和centOS中查看ip地址是 ifconfig # 这里我的mac地址是 192.168.1.107 # centOS中地址是设置和主机共享同一个网段 使用桥接方式，不要使用NAT方式，否则不是在一个网段 # centOS 中ip是 192.168.1.109 # 本篇文章最重要的地方就是这里，虚拟机中的服务器必须要和将要连接的电脑共处一个网段 # 所以必须使用桥接。 window系统中命令 ipconfig #windows下ip地址是 192.168.1.104 互相ping查看一下是否可以互相访问到Last login: Sun Feb 19 13:46:15 on ttys000 mac@MacBook-Air  ~  ping 192.168.1.109 PING 192.168.1.109 (192.168.1.109): 56 data bytes 64 bytes from 192.168.1.109: icmp_seq=0 ttl=64 time=139.139 ms 64 bytes from 192.168.1.109: icmp_seq=1 ttl=64 time=14.407 ms 64 bytes from 192.168.1.109: icmp_seq=2 ttl=64 time=173.413 ms 64 bytes from 192.168.1.109: icmp_seq=3 ttl=64 time=205.352 ms # 如果看到这里，那么已经成功一大半了 3.centOS中开方端口 ssl mac@192.168.1.109 //默认使用的22端口 ，因为没有使用安全连接，他会让你选择yes和no ✘ ⚙ mac@MacBook-Air  ~  ssh mac@192.168.1.109 The authenticity of host &apos;192.168.1.109 (192.168.1.109)&apos; can&apos;t be established. RSA key fingerprint is SHA256:8GcRL3cDzo3UHBCOTq5ExwKJ37VfTwJLBxZU0xWHBPY. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;192.168.1.109&apos; (RSA) to the list of known hosts. mac@192.168.1.109&apos;s password: [mac@localhost ~]$ ls Desktop Documents Downloads Music Pictures Public Templates Videos [mac@localhost ~]$ ls 这篇的内容就是这样，下一篇，使用安全连接 主要内容： 服务器生成安全密钥 服务器开放一个供访问的安全端口 使用ssl 公钥 安全连接 最后终级目标是将局域网地址映射到公网","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"本地服务器搭建之秘钥登录","slug":"本地服务器搭建之秘钥登录","date":"2015-04-12T05:35:42.000Z","updated":"2018-04-14T04:40:39.823Z","comments":true,"path":"2015/04/12/本地服务器搭建之秘钥登录/","link":"","permalink":"https://lxchinesszz.github.io/2015/04/12/本地服务器搭建之秘钥登录/","excerpt":"","text":"作者：@lxchinesszz本文为作者原创，转载请注明出处 紧接上文，上文的重点不是连接，而是如何在局域网中用废弃的电脑搭建，是不是感觉很easy，那么这篇文章我们的重点就放在了安全上了，因为毕竟服务器是我们放应用或者数据库的地方，安全性一定要可靠。小编是做Java开发的，一只热爱技术的小菜鸟，因为工作中常常要一条龙服务，即，自己写需求文档，自己码代码，自己测试，自己部署，自己维护。虽然很累，但是很充实，很能提高自己。我也希望把自己的工作经验分享出来，对那些想小编一样热爱技术的小伙，有所帮助。说半天废话，下面开始。 密钥登录原理： 密钥常是一对的，即公钥和私钥，将公钥添加到服务器上的某个账户，然后客户端连接的时候，使用私钥完成认证就可以登录 A.使用私钥登录1.制作密钥对 首先在服务器制作，需要的登录账户，然后执行以下命令 12345678910[root@host ~]$ ssh-keygen #建立密钥对Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): #按 EnterCreated directory '/root/.ssh'.Enter passphrase (empty for no passphrase): # 输入密钥锁码，或直接按 Enter 留空Enter same passphrase again: # 再输入一遍密钥锁码Your identification has been saved in /root/.ssh/id_rsa. # 私钥Your public key has been saved in /root/.ssh/id_rsa.pub. # 公钥The key fingerprint is:0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:df:9b:cc:08 root@host 2.安装公钥到服务端 讲公钥安装到服务器 12[root@host ~]$ cd .ssh[root@host .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys 设置权限 12[root@host .ssh]$ chmod 600 authorized_keys #不让其他用户写入 600 权限[root@host .ssh]$ chmod 700 ~/.ssh #读写执行的权限 700 ssh的配置文件都在/etc/ssh/ 里面 1234[centos@localhost ~]$ cd /etc/ssh/[centos@localhost ssh]$ ls ssh_config #是客户单配置的 sshd_config #是服务端配置的 在sshd_config中配置使用RSA登录 1234RSAAuthentication yesPubkeyAuthentication yesPermitRootLogin yes # 允许root用户通过ssh登录PasswordAuthentication no #不允许密码登录，只用使用私钥登录[一般我也用yes] 最后服务端重启 ssh 1[root@host .ssh]$ service sshd restart 3.操作客户端 3.1把服务端私钥复制到客户端，cat id_rsa，就是一下内容 123456789101112131415161718192021222324252627282930-----BEGIN RSA PRIVATE KEY-----Proc-Type: 4,ENCRYPTEDDEK-Info: DES-EDE3-CBC,A757691CABE05419yvEX5nQY3+OeZ56kTt8i41YChrQgL9OwglA3SIU2ymrWvY+5IxXMOQbjJmoSFtRzOr0lB1eWZx8ZimGdG+y9KoN4AkUzX+HqzaC8/eMczrv2KXP6DpOvV6MTdHoBrTb8pJOSVzw1K1jmGPaCdWg3XJ7iNSdYr+FVHC6gmJhCCvSHjXLHYBseTSJNXzs4DpQrrTAnU1NXVt0ce3R7DCO/hGClS5zeQ7j7fpQ48cwBgNJumCcr5eU/TWlUMKm7Q8ZazLaugTg387qKaieFY6v8CvpqT4Oqt+j1+6B05sr2S4XiiWHdlcieG4fgSRc5I7kpEhzZWM2LdK6NtxkbWVzd0ZOu5dZDIaMykC2KJJwT+NW3yKZvN1iebm7jzLC3Pv1BdAqnzxMuwBVNbkvrmVWzi8+OvSfH3ttCoRVnshAAvPylBazAZpWn5k6f0QC8MkUQAIEFex80xBPJTT+L6HuijrO2Z1K6qeWe+ptUAqX3FrcuneH1Nn3MnOhNVb4HZvk0xoy3/+2xe3sYKOUsMqjpWlI3DzGnZ81R8z1sTquRQy3hHDZ8cA6k1wUWoVTpJArbCLphYurek+YN3kFGLhvKnd6YjnH3d2sq/qSIMp4m3T8iBkex5raf4iNpFwKzb3S9D6QSWl9Nfnd2tAWkApXU4TPOcbX7XtX1P5yexyNxAZaUHuDsPStO/53WHfu8G2BPnM2Pefaj1sUcODLK+4JR+edmtA9rjHXVx7Kd3OKRmpocmzYWgEOQJtklr+cL7SJJHzoKBjx0NB5/iW23KxSnj7gJhnrDbcD9wY5g63DuMsNnreMfk6trTbXe5ck/mfYN6bTCXkVczm5Q8BKY0cJF2n/2dJyow9RFJtxDTzm11SvqdXtZoanC5mttePViu3J88dbNETFw0DwutyY3KPq3taX40Ps76Ahh6BTb5QD8ctxpYx63MOfQG/BrPFD9M6All5YLzi1In3hc0s6GN2yvx/fdjNZpYFgxA0GH66evtlo3HMr/Id8zgZ+ZSikHMXpvpiXS4uBIgeCZeRaTbq/Bd2V2sN3ENQgV7UTVrnHDc5IWH+qpg8AZxnvmP6BBATNQ2WAc6I10JqkrtfwjKuSYGyJmg6fY5uSKkZo9JQ1uviWEyhdKDhtYgStxyoIznrbJE7PQ3iE3VanB0zmhJHdFJ9xsy5yggMSnRfLCmLsXrczJX0ALwtCDGrrAR3wAg1fn7WmdUfyfnAugJGOBMx25vOLASL3q5zKoxEr7ayln51uuWRE2oK63low68lcWt42aS/ozMsev6Wg7QQjg7HRYEavYZGmCv9OBAblOmneUQjajT2F6zY1R4Cajkk3XmBO2GHXJ685hTiBMQsGf81NMtGd2Zkd5jbcHYhfOe1TKRhgp9cxtzKuyzD2Hj5Bltw8Pq26JVqhLAXZpy73kVsCpU8KplyvZM349kM+VwzOwvvuoWuS+pi9iYYv2f4CjDWZ4dfzg30+ekEc2QTwsZrYbG8SyIOn4oZSE+ygFNge/o2ftqwpRSwJhV8sUlrhBHQb/plePpQQfRQlnifiqR/z2JQ4y28purVt5GKPuwsK4SpHCQTpXW3OkdA==-----END RSA PRIVATE KEY----- 把里面的内容复制（这个是我的）自己的文件下 12341.你也可以把服务端的id_rsa 下载到你的客户端，放在当前用户的.ssh目录下2.也可以复制里面的内容然后再.ssh目录下，重新创建一个id_rsavi ~/.ssh/id_rsa # 创建私钥 4.直接可以登录了【然后就会发现问题】123456789101112131415✘ ⚙ mac@MacBook-Air  ~/.ssh  ssh centos@192.168.1.112@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: UNPROTECTED PRIVATE KEY FILE! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@Permissions 0644 for '/Users/mac/.ssh/id_rsa' are too open.It is required that your private key files are NOT accessible by others.This private key will be ignored.Load key \"/Users/mac/.ssh/id_rsa\": bad permissionscentos@192.168.1.112's password:# 遇到这个问题一般就是权限问题 赋权700 ，然后就ok了⚙ mac@MacBook-Air  ~/.ssh  chmod 700 id_rsa⚙ mac@MacBook-Air  ~/.ssh  ssh centos@192.168.1.112Enter passphrase for key '/Users/mac/.ssh/id_rsa':Last login: Sun Feb 19 12:56:05 2017 from 192.168.1.113 B.设置安全端口 默认使用22端口，这个在etc/ssh/ssh_config 就可以看到 我们可以不使用22端口，此时我们可以在服务器重新创建一个端口，然后使用防火墙屏蔽其他端口 开启端口 开启一个10222端口 12345/sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT #写入修改 /etc/init.d/iptables save #保存修改 service iptables restart #重启防火墙，修改生效 ​ 然后可以查看一下端口状态 查看的时候一定要用root用户，否则查看不到的，所以我切换了10222 端口连接 端口的知识属于计算机的基础知识，如果你能看到这里，说明你的基础已经够了，不过下面我会专门写一篇关于底层的计算机的文章。 1234567891011121314151617181920[centos@localhost ssh]$ su root密码：[root@localhost ssh]# /etc/init.d/iptables status表格：filterChain INPUT (policy ACCEPT)num target prot opt source destination1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:102222 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:102223 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED4 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/05 ACCEPT all -- 0.0.0.0/0 0.0.0.0/06 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:227 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT)num target prot opt source destination1 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT)num target prot opt source destination 服务端在/etc/ssh/sshd_config 中监听10222端口，然后就可以使用 1ssh -p 10222 centos@192.168.1.112","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"服务器防止ping配置","slug":"服务器防止ping配置","date":"2015-04-12T05:31:25.000Z","updated":"2018-04-14T04:40:32.609Z","comments":true,"path":"2015/04/12/服务器防止ping配置/","link":"","permalink":"https://lxchinesszz.github.io/2015/04/12/服务器防止ping配置/","excerpt":"","text":"1echo 0 &gt;/proc/sys/net/ipv4/icmp_echo_ignore_all 0 开启ping1 不开启","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"me","slug":"me","date":"2015-03-11T15:37:26.000Z","updated":"2018-04-13T07:14:26.304Z","comments":true,"path":"2015/03/11/me/","link":"","permalink":"https://lxchinesszz.github.io/2015/03/11/me/","excerpt":"","text":"个人信息 笔名: chinesszz , 网名: X , 非著名码农。生于1993年，籍贯河南，现居上海。电子商务专业,专注于基础架构和rpc通信框架研发。目前就职于某互联网软件服务公司 专注于企业微服务架构研究及开源框架底层源码研究 熟练运用各种流行的JavaEE技术进行组合式架构设计与开发。业余时间研究并发编程，中间件，异地多活，Spring Cloud，Netty等开源项目，以及软件架构设计，程序性能优化，JVM，高并发等！ 个人爱好 热爱技术,相信技术改变生活.喜欢阅读优秀框架源码,学习其设计模式,及编程技巧 热爱编程,熟练掌握Java,Python等主流编程语言及服务器Linux Bash脚本编程, 具有良好的笔记习惯, 具有快速学习的能力 喜欢记笔记,记录分享传播工作中学习到的知识,分享给同样热爱技术的人儿 宗旨本博客主要分享小编在日常工作遇到的实际问题和学习中读过的好文。希望通过博客文章,将知识分享给大家,我认为在企业应用架构实践中非常实用的干货内容。 意见反馈若本号内容有做得不到位的地方（比如：涉及版权或其他问题），请及时联系我进行整改。 联系方式邮箱: lxchinesszz@163.com 微信&amp;头条","categories":[{"name":"about","slug":"about","permalink":"https://lxchinesszz.github.io/categories/about/"}],"tags":[],"keywords":[{"name":"about","slug":"about","permalink":"https://lxchinesszz.github.io/categories/about/"}]},{"title":"Contos安装yum源","slug":"Contos安装yum源","date":"2015-01-11T05:30:05.000Z","updated":"2018-04-14T04:37:17.796Z","comments":true,"path":"2015/01/11/Contos安装yum源/","link":"","permalink":"https://lxchinesszz.github.io/2015/01/11/Contos安装yum源/","excerpt":"","text":"cd /etc/yum.repos.d/ 因为使用yum安装都是安装的rpm包，所以可以使用 rpm -ql 查看安装的目录 12345[root@iz2ze283ts0vfkcqfvduzdz ~]# cd /etc/yum.repos.d/[root@iz2ze283ts0vfkcqfvduzdz yum.repos.d]# lsCentOS-Base-Aliyun.repo epel-Aliyun.repo epel-testing.repo nginx.repoCentOS-Base.repo epel.repo jenkins.repo[root@iz2ze283ts0vfkcqfvduzdz yum.repos.d]#","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"Git常用命令","slug":"GIt命令","date":"2015-01-11T03:49:42.000Z","updated":"2018-04-14T03:35:23.072Z","comments":true,"path":"2015/01/11/GIt命令/","link":"","permalink":"https://lxchinesszz.github.io/2015/01/11/GIt命令/","excerpt":"","text":"查看配置文件 1git config --list 本地项目添加到github 12345678910111213git init 初始化git add ./ 进行跟踪git commit -m '' 提交本地#根据github仓库git remote add origin https:liuxin..#如果上面操作失败说明已经绑定了一个，就删除之前的git remote rm origin#推到远程仓库git push -u origin master 查看最近提交信息 1git log 添加并提交git commit -am ‘message’相当于添加跟踪并提交 12git commit -am \"some str\"git push 回退到上一次提交的状态git revert HEAD1git revert HEAD 回退到某个版本git reset 057d 12回退到某个版本 git reset 830bc084264841... 查看当前分支git branch123KK-MINI:svc_shenghuojiaofei liuxin$ git branch develop* master 创建分支git branch feature12345KK-MINI:svc_shenghuojiaofei liuxin$ git branch featureKK-MINI:svc_shenghuojiaofei liuxin$ git branch develop feature* master 切换分支12345678KK-MINI:svc_shenghuojiaofei liuxin$ git checkout featureM .gitignoreM src/main/resource/application.propertiesSwitched to branch 'feature'KK-MINI:svc_shenghuojiaofei liuxin$ git branch develop* feature master 提交到最新分支 12345KK-MINI:svc_shenghuojiaofei liuxin$ git push -u origin featureTotal 0 (delta 0), reused 0 (delta 0)To https://github.com/kpboluome/svc_shenghuojiaofei.git * [new branch] feature -&gt; featureBranch feature set up to track remote branch feature from origin. 删除远程分支 git push origin --delete testfenzhi 删除本地分支 git branch -D stg 同步feature分支到master分支 git checkout master git merge feature git push origin master 回退所有内容到上一个版本 1git reset HEAD^ 回退a.py这个文件的版本到上一个版本 1git reset HEAD^ a.py ` 拉取远程分支到本地分支可以把远程某各分支拉去到本地的branchname下，如果没有branchname，则会在本地新建branchname git fetch origin branchname:branchname","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://lxchinesszz.github.io/tags/Git/"}],"keywords":[]}]}