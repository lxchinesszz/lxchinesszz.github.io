{"meta":{"title":"程序猿升级课","subtitle":null,"description":"一个关注于程序猿技术提升的博客","author":"liuxin","url":"https://lxchinesszz.github.io"},"pages":[],"posts":[{"title":"Netty组件介绍","slug":"Netty组件介绍","date":"2018-04-11T09:39:03.000Z","updated":"2018-04-11T09:59:38.762Z","comments":true,"path":"2018/04/11/Netty组件介绍/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/11/Netty组件介绍/","excerpt":"","text":"在学习Netty之前，建议首先学习一个NIO，对关键的NIO组件有一个清醒认识 Buffer Selector 总览 Bootstrap or ServerBootstrap EventLoop EventLoopGroup ChannelPipeline Future or ChannelFuture ChannelInitializer ChannelHandler ByteToMessageDecoder MessageToByteEncoder ChannelPipline Channel ChannelHandlerContext ServerBootstrap一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。 option() 针对boss线程,用于连接 childOption() 针对work线程,用于处理数据 BootStrap123456789101112131415161718192021222324252627EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .remoteAddress(new InetSocketAddress(host, port)) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new SimpleChannelInboundHandler&lt;ByteBuf&gt;() &#123; //在连接的时候将数据发送给 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.channel().writeAndFlush(request); &#125; //接受信息 @Override protected void messageReceived(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf) throws Exception &#123; result = new byte[byteBuf.readableBytes()]; byteBuf.readBytes(result); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect().sync(); future.addListener(ChannelFutureListener.CLOSE).sync(); EventLoop一个EventLoop可以为多个Channel服务。 EventLoopGroup会包含多个EventLoop ChannelPipeline,ChannelHandler从PipeLine这个单词中可以看出来，是一个管道，处理连接。我们的业务代码handler一般都是放在这个管道中的 那么疑问来了，这个管道中的处理顺序是什么样呢？ 1234ChannelPipeline cp = channel.pipeline(); cp.addLast(\"encoder\", new HttpResponseEncoder());//1.负责输出cp.addLast(\"decoder\", new HttpRequestDecoder());//2.负责把客户端的数据解码cp.addLast(\"handler\", new HttpDispatchServerHandler());//3.自定义的业务处理器 按照我们执行顺序肯定不是根据添加顺序来处理的，应该是:2,把客户端的数据解码-&gt;3.对解码数据处理-&gt;1.加密返回给客户端。 那么 Netty 是怎么处理的呢？ ChannelHandler有两个子类ChannelInboundHandler和ChannelOutboundHandler，这两个类对应了两个数据流向，如果数据是从外部流入我们的应用程序，我们就看做是inbound，相反便是outbound ChannelInitializer顾名思义,这个就是channel初始化的容器，在这个里面设置处理器 123456789101112131415161718192021222324ServerBootstrap bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup();//负责绑定channel到selector workerGroup = new NioEventLoopGroup();//负责从selector中读取事件 bootstrap.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) .localAddress(6969).option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000) .childOption(ChannelOption.SO_KEEPALIVE, true).childHandler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel channel) throws Exception &#123; ChannelPipeline cp = channel.pipeline(); cp.addLast(\"idleStateHandler\", new IdleStateHandler(5, 5, 5, TimeUnit.SECONDS)); cp.addLast(\"decoder\", new HttpRequestDecoder()); cp.addLast(\"encoder\", new HttpResponseEncoder()); cp.addLast(\"aggregator\", new HttpObjectAggregator(1048576)); cp.addLast(\"deflater\", new HttpContentCompressor()); cp.addLast(\"handler\", new HttpDispatchServerHandler()); cp.addLast(\"out\", new AcceptorIdleStateTrigger()); &#125; &#125;).option(ChannelOption.SO_BACKLOG, 128); try &#123; channel = bootstrap.bind().awaitUninterruptibly().channel(); showBanner(6969); &#125; catch (Exception ie) &#123; throw new RuntimeException(ie); &#125; ###ChannelFuture Netty中的连接都可以是异步的，但是也可以设置为非异步 ChannelFutureChannel 每个操作都会返回一个 ChannelFutrue 因为是异步的，所以我们为每个异步的结果，添加一个监听,比如: 12345678# 当完成关闭动作，就执行监听器内容f = f.channel().closeFuture().await(); f.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; System.out.println(\"success complete!!ok!!\"); &#125; &#125;); 当然还有一种方法， 就是await()，此返回会等待上一个操作完成，在进行下一个操作。但是推荐使用第一种。 ByteToMessageDecoder解密器，可以自定义协议，通过集成改接口，重写 decode 方法把二进制，转换为我们系统可以处理的对象 12345678910111213141516171819202122import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.handler.codec.ByteToMessageDecoder;import java.util.List;/** * 把字节转换为int * 继承抽象类ByteToMessageDecoder实现解码器 */public class ByteToIntegerDecoder extends ByteToMessageDecoder &#123; @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; if (in.readableBytes() &gt;= 4) &#123; // Check if there are at least 4 bytes readable int n = in.readInt(); System.err.println(\"ByteToIntegerDecoder decode msg is \" + n); out.add(n); //Read integer from inbound ByteBuf, add to the List of decodec messages &#125; &#125;&#125; 编码器将我们系统处理完的信息，编码成，二进制，传出，给调用者 123456789101112import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerContext;import io.netty.handler.codec.MessageToByteEncoder;public class IntegerToByteEncoder extends MessageToByteEncoder&lt;Integer&gt; &#123; @Override public void encode(ChannelHandlerContext ctx, Integer msg, ByteBuf out) throws Exception &#123; System.err.println(\"IntegerToByteEncoder encode msg is \" + msg); out.writeInt(msg); &#125;&#125; 解码后的数据怎么使用对于加密后的数据，可以直接强制转换为我们解码的对象 123456789public class BusinessHandler extends ChannelInboundHandlerAdapter &#123;trueprivate Logger logger = LoggerFactory.getLogger(BusinessHandler.class);true@Overridetruepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;true//因为我们的解码其中指定是Int类型，所以我们就可以，强制转换为Int，这里为了好理解，假如我们的解码器，中是转换了Person，那么在我们的处理器中就，可以强制换换为PersontruetruePerson person = (Person) msg;truetruelogger.info(\"BusinessHandler read msg from client :\" + person);true&#125; ChannelPipline 管道 管道中包括(ChannleInBoundHandler)入栈的和(ChannelOutBoundHandler)出栈的当连接发生,由ChannelPipline协调将消息给ChannelHandler处理 当一个ChannelHandler被绑定在了多个ChannelPipeline实例上,为了线程安全会报错.要使用@Sharable注解 Channel 消息的传载实体ChannelHandlerContext ChannelHandlerContext将Channel和ChannelHandler做一个关联因为一个Channel可能与多个ChannelHandler绑定 注意ChannelHandler与下一个ChannelHandler…的交互并不是他们直接产生的,而是有ChannelHandlerContext调用的 从中学习到一个编程技巧,就是当一个实体与多个处理器产生关系的时候,可以定义一个上下文,用来管理关系","categories":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/tags/Netty/"}],"keywords":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/categories/Netty/"}]},{"title":"SpringBoot原生定时任务解析","slug":"SpringBoot原生定时任务解析","date":"2018-04-11T09:35:09.853Z","updated":"2018-04-11T09:35:09.854Z","comments":true,"path":"2018/04/11/SpringBoot原生定时任务解析/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/11/SpringBoot原生定时任务解析/","excerpt":"","text":"#SpringBoot原生定时任务，不需要引入任何依赖 ==只要了解，几个注解就可以使用== 1.在启动类上加入@EnableScheduling标签 2.在定时任务方法上加入@Schedule(fixedDelay=5000) 3.就是如此简单，简单的不可想象 123456789101112131415161718192021222324package zebra.shjf;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.scheduling.annotation.EnableScheduling;@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TestQuartzApplication.class, args); &#125;&#125;@Componentpublic class ScheduledTasks&#123; @Scheduled(fixedDelay = 5000) public void execute() &#123; System.out.println(\"当前时间：\" + new Date()); &#125;&#125;","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring定时器","slug":"Spring定时器","permalink":"https://lxchinesszz.github.io/tags/Spring定时器/"}],"keywords":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)","slug":"Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)","date":"2018-04-11T09:35:06.704Z","updated":"2018-04-11T09:35:06.704Z","comments":true,"path":"2018/04/11/Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/11/Spring整合Quartz2.1.1(执行中，得到application上下文，执行bean方法)/","excerpt":"","text":"==前文==，Quartz中迭代后，变化很大，让我走了很多的误区，这里简单解释一点，希望大家可以跳过误区，建议大家从下往上读（希望对大家有点帮助），我是一只爱分享的小菜鸟 JobDetail和Trigger和Schedule都是接口，统统不能new 1.如果只是执行一些自定义的类，其实使用SpringBoot的自带的任务就可以完成，简单的不能想象。这个可以看-&gt;我的另一篇SpringBoot原生定时任务解析。2.如果要是要动态的执行一些有Spring管理的bean，可能要稍微费点功夫了，网上有很多的教程，那部分都是xml形式配置的，本人菜鸟一枚（十分迷惑），十分不喜欢xml配置，看着眼花，当程序读取的时候还是要解析java对象来执行的，那么为何不直接配置成配置类呢？这个问题先方下，以后会详细解释如何使用Spring Boot配置类。开始代码展示1234567891011121314151617181920212223242526 //job是一个接口，当定时任务执行的时候，就要运行这个方法，那么可以推测 JobExecutionContext这个对象中包含了我们可能使用的关于这个定时任务的所有细节，请看代码public interface Job &#123; void execute(JobExecutionContext var1) throws JobExecutionException;&#125;/** * Created by liuxin on 16/12/21. * 方案1：反射执行类和执行方法（不解析，没有用，刚开始走了误区，自己反射方法执行，大家尽量不要用） * 方案2：读取bean（这个才是重点） */public class ScheduledTasks implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(\"------进入定时方法区域-------\"); try &#123; ConfigurableApplicationContext cac = (ConfigurableApplicationContext) jobExecutionContext.getJobDetail().getJobDataMap().get(\"ConfigurableApplicationContext\"); HelloService helloService = (HelloService) cac.getBean(\"helloService\"); helloService.hh(); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 上面的代码中看到这个JobExecutionContext可以得到JobDetail，而这个JobDetail对象是我们自己创建的用来详细介绍我们定时任务的，也就是我们要执行的方法的详细在这个里存放，123jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);这个是我们在main方法中测试时候，提前放进去，的在执行execute方法时候，取到的上下文对象，用来得到bean的这么说是不是很清楚了？接着看代码 测试的bean对象1234567@Servicepublic class HelloService &#123; static int i=0; public void hh()&#123; System.out.println(++i); &#125;&#125; 为了证明这个bean在上下文中，我们打印一下，上下文中的所有的bean 123456789101112131415161718192021222324252627282930313233@SpringBootApplicationpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean 可以看到helloService在倒数3 &#125;&#125; . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.2.RELEASE)org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorytestQuartzApplicationorg.springframework.boot.autoconfigure.internalCachingMetadataReaderFactoryorg.springframework.context.annotation.ConfigurationClassPostProcessor.importAwareProcessororg.springframework.context.annotation.ConfigurationClassPostProcessor.enhancedConfigurationProcessorhelloServiceredisConfigjedis 那么现在的任务就是把，这个上下文对象防盗JobDetil的map中，2.2.1的区别来了，不在是一起new的jobDetail了,由JobBuilder和TriggerBuilder构建1234567891011121314151617@SpringBootApplication@EnableSchedulingpublic class TestQuartzApplication &#123; public static void main(String[] args) throws Exception &#123; ConfigurableApplicationContext cac = SpringApplication.run(TestQuartzApplication.class, args); String[] names = cac.getBeanDefinitionNames(); Arrays.asList(names).forEach(name -&gt; System.out.println(name));//打印bean SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobDetail jobDetail = JobBuilder.newJob(ScheduledTasks.class).withIdentity(\"testkey\", \"testvalue\").withDescription(\"一个测试的类\").build(); jobDetail.getJobDataMap().put(\"ConfigurableApplicationContext\",cac);//重点是这句话 Trigger trigger = TriggerBuilder.newTrigger().startNow().withSchedule(CronScheduleBuilder.cronSchedule(\"0/1 * * * * ?\")).startNow().build(); scheduler.scheduleJob(jobDetail,trigger); scheduler.start(); &#125;&#125;","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring整合Quartz","slug":"Spring整合Quartz","permalink":"https://lxchinesszz.github.io/tags/Spring整合Quartz/"}],"keywords":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://lxchinesszz.github.io/categories/Spring-Boot/"}]},{"title":"Spring Cloud初步理解","slug":"Spring Cloud初步理解","date":"2018-04-11T09:34:58.344Z","updated":"2018-04-11T09:34:58.345Z","comments":true,"path":"2018/04/11/Spring Cloud初步理解/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/11/Spring Cloud初步理解/","excerpt":"","text":"Ribbon实现负载均衡 关键字：Feign、Ribbon、eureka、负载均衡 大致：步骤，启动eureka服务(注册中心) 使用Spring Cloud Netflix中的Eureka实现服务注册中心，以及服务注册发现； 将service(port:2222,port:2223)注册到eureka服务中 使用Ribbon代理去访问service 会实现负载均衡 服务间通过Ribbon或Feign实现服务的消费以及均衡负载 通过Spring Cloud Config实现应用多环境的外部化配置及版本管理 使得服务集群更为健壮，使用Hystrix熔断机制避免微服务架构中个别服务出现异常引起的故障蔓延 引入断路器 Rabbion中引入Hystrix 123456789101112@Servicepublic class ComputeService &#123; @Autowired RestTemplate restTemplate; @HystrixCommand(fallbackMethod = \"addServiceFallback\") public String addService() &#123; return restTemplate.getForEntity(\"http://COMPUTE-SERVICE/add?a=10&amp;b=20\", String.class).getBody(); &#125; public String addServiceFallback() &#123; return \"error\"; &#125;&#125;","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://lxchinesszz.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://lxchinesszz.github.io/tags/Spring-Cloud/"}],"keywords":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://lxchinesszz.github.io/categories/Spring-Cloud/"}]},{"title":"HEXO之博客搭建","slug":"HEXO之博客搭建","date":"2018-04-11T03:49:42.000Z","updated":"2018-04-12T03:23:04.861Z","comments":false,"path":"2018/04/11/HEXO之博客搭建/","link":"","permalink":"https://lxchinesszz.github.io/2018/04/11/HEXO之博客搭建/","excerpt":"","text":"HEXO 安装hexo博客工具1npm install -g hexo-cli 初始化目录1hexo init 生成静态页面1hexo g 清理缓存1hexo clean 推送到服务器推送时候要先: npm install hexo-deployer-git –save安装依赖 修改 123456# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://lxchinesszz.gitee.io/chinesszz/ 访问地址root: /chinesszz 访问项目permalink: :year/:month/:day/:title/permalink_defaults: 1hexo d 本地服务预览1hexo s 查看1浏览器: http://127.0.0.1:4000/ 绑定码云 修改配置项目根目录_config.yml 文件，修改deploy的值然后保存 1234deploy: type: git repo: https://gitee.com/lxchinesszz/chinesszz.git branch: 分支 在oschina中点击服务,启动pages静态访问 绑定到GITHUB 当绑定到github上需要常见仓库为 用户名.github.io 购买域名并转发到github 购买域名,并备案 配置域名转发 在github上仓库点击Setting设置域名","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://lxchinesszz.github.io/tags/博客搭建/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"TCP-Keepalive解读","slug":"TCP-Keepalive解读","date":"2017-04-12T05:33:55.000Z","updated":"2018-04-12T05:34:25.429Z","comments":true,"path":"2017/04/12/TCP-Keepalive解读/","link":"","permalink":"https://lxchinesszz.github.io/2017/04/12/TCP-Keepalive解读/","excerpt":"","text":"Netty 扩展TCP是无感知的虚拟连接，中间断开两端不会立刻得到通知。一般在使用长连接的环境下，需要心跳保活机制可以勉强感知其存活。业务层面有心跳机制，TCP协议也提供了心跳保活机制。 TCP 活性探测理解因为TCP是无感知的虚拟连接，所以在设计底层编程的时候，如果客户端和服务端互相不知道是否中断，那么服务端可能会一直等下去，==默认情况下使用keepalive周期为2个小时，如不选择更改，属于误用范畴，造成资源浪费== Java/netty服务器如何使用只需要在服务器端一方设置即可，客户端完全不用设置，比如基于netty 4服务器程序： 12345678910111213141516171819ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .childOption(ChannelOption.SO_KEEPALIVE, true) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast( new EchoServerHandler()); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(port).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); Java程序只能做到设置SO_KEEPALIVE选项，至于TCP_KEEPCNT，TCP_KEEPIDLE，TCP_KEEPINTVL等参数配置，只能依赖于sysctl配置，系统进行读取。 具体为： ChannelOption.SO_BACKLOG, 1024BACKLOG用于构造服务端套接字ServerSocket对象，标识当服务器请求处理线程全满时，用于临时存放已完成三次握手的请求的队列的最大长度。如果未设置或所设置的值小于1，Java将使用默认值50。 ChannelOption.SO_KEEPALIVE, true是否启用心跳保活机制。在双方TCP套接字建立连接后（即都进入ESTABLISHED状态）并且在两个小时左右上层没有任何数据传输的情况下，这套机制才会被激活。 ChannelOption.TCP_NODELAY, true在TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。这里就涉及到一个名为Nagle的算法，该算法的目的就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。 TCP_NODELAY就是用于启用或关于Nagle算法。如果要求高实时性，有数据发送时就马上发送，就将该选项设置为true关闭Nagle算法；如果要减少发送次数减少网络交互，就设置为false等累积一定大小后再发送。默认为false。 系统内核参数配置以下环境是在Linux服务器上进行。应用程序若想使用，需要设置SO_KEEPALIVE套接口选项才能够生效。 tcp_keepalive_time，在TCP保活打开的情况下，最后一次数据交换到TCP发送第一个保活探测包的间隔，即允许的持续空闲时长，或者说每次正常发送心跳的周期，默认值为7200s（2h）。 tcp_keepalive_probes 在tcp_keepalive_time之后，没有接收到对方确认，继续发送保活探测包次数，默认值为9（次） tcp_keepalive_intvl，在tcp_keepalive_time之后，没有接收到对方确认，继续发送保活探测包的发送频率，默认值为75s。发送频率tcp_keepalive_intvl乘以发送次数tcp_keepalive_probes，就得到了从开始探测到放弃探测确定连接断开的时间 若设置，服务器在客户端连接空闲的时候，每90秒发送一次保活探测包到客户端，若没有及时收到客户端的TCP Keepalive ACK确认，将继续等待15秒*2=30秒。总之可以在90s+30s=120秒（两分钟）时间内可检测到连接失效与否。 以下改动，需要写入到/etc/sysctl.conf文件： 123456net.ipv4.tcp_keepalive_time=90net.ipv4.tcp_keepalive_intvl=15net.ipv4.tcp_keepalive_probes=2保存退出，然后执行sysctl -p生效。可通过 sysctl -a | grep keepalive 命令检测一下是否已经生效。针对已经设置SO_KEEPALIVE的套接字，应用程序不用重启，内核直接生效。 引用TCP Keepalive笔记","categories":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/tags/Netty/"}],"keywords":[{"name":"Netty","slug":"Netty","permalink":"https://lxchinesszz.github.io/categories/Netty/"}]},{"title":"线程数究竟设多少合理","slug":"线程数究竟设多少合理","date":"2017-02-12T03:34:53.000Z","updated":"2018-04-12T05:35:22.217Z","comments":true,"path":"2017/02/12/线程数究竟设多少合理/","link":"","permalink":"https://lxchinesszz.github.io/2017/02/12/线程数究竟设多少合理/","excerpt":"","text":"分享一篇，关于线程的经典文章。 一、需求缘起Web-Server通常有个配置，最大工作线程数，后端服务一般也有个配置，工作线程池的线程数量，这个线程数的配置不同的业务架构师有不同的经验值，有些业务设置为CPU核数的2倍，有些业务设置为CPU核数的8倍，有些业务设置为CPU核数的32倍。“工作线程数”的设置依据是什么，到底设置为多少能够最大化CPU性能，是本文要讨论的问题。 二、一些共性认知在进行进一步深入讨论之前，先以提问的方式就一些共性认知达成一致。 提问：工作线程数是不是设置的越大越好？回答：肯定不是的 1）一来服务器CPU核数有限，同时并发的线程数是有限的，1核CPU设置10000个工作线程没有意义 2）线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低 提问：调用sleep()函数的时候，线程是否一直占用CPU？ 回答：不占用，等待时会把CPU让出来，给其他需要CPU资源的线程使用 不止调用sleep()函数，在进行一些阻塞调用，例如网络编程中的阻塞accept()【等待客户端连接】和阻塞recv()【等待下游回包】也不占用CPU资源 提问：如果CPU是单核，设置多线程有意义么，能提高并发性能么？ 回答：即使是单核，使用多线程也是有意义的1）多线程编码可以让我们的服务/代码更加清晰，有些IO线程收发包，有些Worker线程进行任务处理，有些Timeout线程进行超时检测 2）如果有一个任务一直占用CPU资源在进行计算，那么此时增加线程并不能增加并发，例如这样的一个代码 while(1){ i++; } 该代码一直不停的占用CPU资源进行计算，会使CPU占用率达到100% 3）通常来说，Worker线程一般不会一直占用CPU进行计算，此时即使CPU是单核，增加Worker线程也能够提高并发，因为这个线程在休息的时候，其他的线程可以继续工作 三、常见服务线程模型了解常见的服务线程模型，有助于理解服务并发的原理，一般来说互联网常见的服务线程模型有如下两种 IO线程与工作线程通过队列解耦类模型 如上图，大部分Web-Server与服务框架都是使用这样的一种“IO线程与Worker线程通过队列解耦”类线程模型： 1）有少数几个IO线程监听上游发过来的请求，并进行收发包（生产者） 2）有一个或者多个任务队列，作为IO线程与Worker线程异步解耦的数据传输通道（临界资源） 3）有多个工作线程执行正真的任务（消费者） 这个线程模型应用很广，符合大部分场景，这个线程模型的特点是，工作线程内部是同步阻塞执行任务的（回想一下tomcat线程中是怎么执行Java程序的，dubbo工作线程中是怎么执行任务的），因此可以通过增加Worker线程数来增加并发能力，今天要讨论的重点是“该模型Worker线程数设置为多少能达到最大的并发”。 纯异步线程模型任何地方都没有阻塞，这种线程模型只需要设置很少的线程数就能够做到很高的吞吐量，Lighttpd有一种单进程单线程模式，并发处理能力很强，就是使用的的这种模型。该模型的缺点是： 1）如果使用单线程模式，难以利用多CPU多核的优势 2）程序员更习惯写同步代码，callback的方式对代码的可读性有冲击，对程序员的要求也更高 3）框架更复杂，往往需要server端收发组件，server端队列，client端收发组件，client端队列，上下文管理组件，有限状态机组件，超时管理组件的支持however，这个模型不是今天讨论的重点。 四、工作线程的工作模式了解工作线程的工作模式，对量化分析线程数的设置非常有帮助： 上图是一个典型的工作线程的处理过程，从开始处理start到结束处理end，该任务的处理共有7个步骤： 1）从工作队列里拿出任务，进行一些本地初始化计算，例如http协议分析、参数解析、参数校验等 2）访问cache拿一些数据 3）拿到cache里的数据后，再进行一些本地计算，这些计算和业务逻辑相关 4）通过RPC调用下游service再拿一些数据，或者让下游service去处理一些相关的任务 5）RPC调用结束后，再进行一些本地计算，怎么计算和业务逻辑相关 6）访问DB进行一些数据操作 7）操作完数据库之后做一些收尾工作，同样这些收尾工作也是本地计算，和业务逻辑相关 分析整个处理的时间轴，会发现： 1）其中1，3，5，7步骤中【上图中粉色时间轴】，线程进行本地业务逻辑计算时需要占用CPU 2）而2，4，6步骤中【上图中橙色时间轴】，访问cache、service、DB过程中线程处于一个等待结果的状态，不需要占用CPU，进一步的分解，这个“等待结果”的时间共分为三部分： 2.1）请求在网络上传输到下游的cache、service、DB 2.2）下游cache、service、DB进行任务处理 2.3）cache、service、DB将报文在网络上传回工作线程 五、量化分析并合理设置工作线程数最后一起来回答工作线程数设置为多少合理的问题。 通过上面的分析，Worker线程在执行的过程中，有一部计算时间需要占用CPU，另一部分等待时间不需要占用CPU，通过量化分析，例如打日志进行统计，可以统计出整个Worker线程执行过程中这两部分时间的比例，例如： 1）时间轴1，3，5，7【上图中粉色时间轴】的计算执行时间是100ms 2）时间轴2，4，6【上图中橙色时间轴】的等待时间也是100ms 得到的结果是，这个线程计算和等待的时间是1：1，即有50%的时间在计算（占用CPU），50%的时间在等待（不占用CPU）： 1）假设此时是单核，则设置为2个工作线程就可以把CPU充分利用起来，让CPU跑到100% 2）假设此时是N核，则设置为2N个工作现场就可以把CPU充分利用起来，让CPU跑到N*100% 结论：N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。 经验：一般来说，非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务），瓶颈都在后端数据库，本地CPU计算的时间很少，所以设置几十或者几百个工作线程也都是可能的。 六、结论N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。 开源中国原文","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://lxchinesszz.github.io/tags/线程/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"Logback高级用法","slug":"Logback高级用法","date":"2016-06-12T05:26:12.000Z","updated":"2018-04-12T05:27:14.068Z","comments":true,"path":"2016/06/12/Logback高级用法/","link":"","permalink":"https://lxchinesszz.github.io/2016/06/12/Logback高级用法/","excerpt":"","text":"在日常的生产中，尤其是在微服务盛行的今天,我们的服务很可能是作为分布式应用上的一个点，会接受来自不同客户端的请求，那么在服务的为每行日志标记出来自的客户端呢？本篇我们通过介绍Logback的高级用法，来为大家实现。 日志扩展 扩展知识 在分布式应用的今天，如何通过日志把客户端请求的不同应用的日志串起来，展示呢 首先分析原理其实很简单，就是为每个线程保存点私有变量，这个私有变量的值，由我们自定义，用于区分不同的应用。 说到线程的私有变量，可能老程序猿，就想到这个类及 ThreadLocal ,关于个类的源码分析，小编已经写过了，这里就不解释了，继续… ,我们今天用到的这个 MDC 就是为每个线程请求保存私有变量，然后在输出日志的时候打印出来，这样就能标识出，每一行日志的来源。 代码实现Logback 框架已经为我们实现了一套常用的请求，今天我们就用，这个来演示。MDCInsertingServletFilter 我们看一下该类的源码分析一下: 12345678910111213141516171819202122232425262728public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; this.insertIntoMDC(request); try &#123; chain.doFilter(request, response); &#125; finally &#123; this.clearMDC(); &#125; &#125; void insertIntoMDC(ServletRequest request) &#123; MDC.put(\"req.remoteHost\", request.getRemoteHost()); if(request instanceof HttpServletRequest) &#123; HttpServletRequest httpServletRequest = (HttpServletRequest)request; MDC.put(\"req.requestURI\", httpServletRequest.getRequestURI()); StringBuffer requestURL = httpServletRequest.getRequestURL(); if(requestURL != null) &#123; MDC.put(\"req.requestURL\", requestURL.toString()); &#125; MDC.put(\"req.method\", httpServletRequest.getMethod()); MDC.put(\"req.queryString\", httpServletRequest.getQueryString()); MDC.put(\"req.userAgent\", httpServletRequest.getHeader(\"User-Agent\")); MDC.put(\"req.xForwardedFor\", httpServletRequest.getHeader(\"X-Forwarded-For\")); &#125; &#125; 就是利用 MDC 为每个处理请求的线程添加上私有变量。就是如此，不过我们要注意的是为了让MDC中的信息在任何时候都是正确有效的，我们需要在request被处理之前，就讲相关信息放入mdc，再在处理完后，clear掉。大家看到其实这个类是继承了 Filter 就是一个过滤器，在这里小编用的是 SpringBoot实现的 那么如何使用呢？ 12345678910111213141516171819/** * @Package: firebird.logger.config.filter * @Description: 应用配置 * @author: liuxin * @date: 2017/8/29 下午5:32 */@Componentpublic class ApplicationConfig &#123; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); Filter actionFilter = new MDCInsertingServletFilter(); registrationBean.setFilter(actionFilter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add(\"/*\"); registrationBean.setUrlPatterns(urlPatterns); return registrationBean; &#125;&#125; Loback打印日志该教程还是参考了我之前写的日志错误提醒框架，所以注释部分包括了使用 Sentry的部分代码，如果对错误收集框架感兴趣的同学，可以看我的另一篇博客SpringBoot整合Sentry 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;configuration&gt; &lt;!-- 彩色日志 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(--)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt;/&gt; &lt;property name=\"MDC_LOG_PATTERN\" value=\"IP:%X&#123;req.remoteHost&#125; -url:%X&#123;req.requestURI&#125; -Method:%X&#123;req.method&#125; - QueryString:%X&#123;req.queryString&#125; - device:%X&#123;req.userAgent&#125; -ips:%X&#123;req.xForwardedFor&#125; - %m%n \"&gt;&lt;/property&gt; &lt;appender name=\"Console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;layout&gt; &lt;pattern&gt;$&#123;MDC_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!--&lt;appender name=\"Sentry\" class=\"com.getsentry.raven.logback.SentryAppender\"&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;每个项目生成不通的key&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;dsn&gt;http://d73b23c481654b9ca0e4e8a9db310169:daaf5dc2edef462690791ef324316738@sentry.boluome.com/7&lt;/dsn&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash; 设置拦截的最低级别为warn 警告&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;--&gt; &lt;!--&lt;level&gt;WARN&lt;/level&gt;--&gt; &lt;!--&lt;/filter&gt;--&gt; &lt;!--&lt;/appender&gt;--&gt; &lt;!--&lt;logger name=\"logback.SentryAppenderIT\" level=\"INFO\"&gt;--&gt; &lt;!--&lt;appender-ref ref=\"Sentry\"/&gt;--&gt; &lt;!--&lt;/logger&gt;--&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"Console\"/&gt; &lt;!--&lt;appender-ref ref=\"Sentry\"/&gt;--&gt; &lt;/root&gt;&lt;/configuration&gt; 可以看到 MDC_LOG_PATTERN 中获取了从MDC过滤器中的参数，这样我们就能打印出来了 代码测试12345678910111213141516171819IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - URL : http://localhost:10111/loggerIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 请求类型 : GETIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 请求IP : 0:0:0:0:0:0:0:1IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 方法 : firebird.logger.rest.OtoRestController.testLoggerIP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 参数列表 : []IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - hello world !!!IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - hello world !!!IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - 返回参数 : 请查看日志IP:0:0:0:0:0:0:0:1 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8 -ips: - -----------------方法执行完毕,耗时:1ms-------------------IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - ----------testLogger方法开始执行----------------------------IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - URL : http://192.168.199.235:10111/loggerIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 请求类型 : GETIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 请求IP : 192.168.199.191IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 方法 : firebird.logger.rest.OtoRestController.testLoggerIP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 参数列表 : []IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - hello world !!!IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - hello world !!!IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - 返回参数 : 请查看日志IP:192.168.199.191 -url:/logger -Method:GET - QueryString: - device:Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_3 like Mac OS X) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.0 Mobile/14G60 Safari/602.1 -ips: - -----------------方法执行完毕,耗时:0ms------------------- 扩展方法如何实现呢? 不积跬步无以至千里,接下来还有要学习如何使用 Logstash kibana elasticsearch","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://lxchinesszz.github.io/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"Tomcat7和Tomcat8的区别","slug":"Tomcat7和Tomcat8的区别","date":"2016-03-12T05:12:59.000Z","updated":"2018-04-12T05:33:27.883Z","comments":true,"path":"2016/03/12/Tomcat7和Tomcat8的区别/","link":"","permalink":"https://lxchinesszz.github.io/2016/03/12/Tomcat7和Tomcat8的区别/","excerpt":"","text":"因为一次意外的原意，我部署了两个web容器 本地mac上是tomcat8 远程服务器是tomcat7 同时这两个web容器都使用nginx代理,项目打包在本地没有任何问题 但是在远程服务器就会出现图片加载不出来，应该是以汉字结尾的数据，不能够加载，刚开始是找到不到问题，原因。 因为所有以中文命名的图片和表格都是在一个文件夹，下面，所以以为，改文件夹没有被编译进去，但是最后发现确实是在。 然后我手动在远程服务器改文件夹，下面touch dadfa&gt;1.txt然后去访问1.txt结果却能访问，忽然豁然开朗，找到原因就是因为汉字不能够解析，然后搜索解决办法 tomcat7:URIEncodingThis specifies the character encoding used to decode the URI bytes, after %xx decoding the URL. If not specified, ISO-8859-1 will be used 这个参数用来设置解码url参数，如果没指定，默认是ISO-8859-1。 tomcat8:URIEncodingThis specifies the character encoding used to decode the URI bytes, after %xx decoding the URL. If not specified, UTF-8 will be used unless the org.apache.catalina.STRICT_SERVLET_COMPLIANCE system property is set to true in which case ISO-8859-1 will be used.这个参数用来设置解码url参数，如果没指定，默认是UTF-8，除非设置了org.apache.catalina.STRICT_SERVLET_COMPLIANCE这个系统参数为true，这个时候会使用ISO-8859-1。 123456&lt;Connector port=\"8080\" URIEncoding=\"utf-8\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"ELK服务搭建之Kibana使用说明","slug":"ELK服务搭建之Kibana使用说明","date":"2016-01-12T03:29:04.000Z","updated":"2018-04-12T05:29:32.634Z","comments":true,"path":"2016/01/12/ELK服务搭建之Kibana使用说明/","link":"","permalink":"https://lxchinesszz.github.io/2016/01/12/ELK服务搭建之Kibana使用说明/","excerpt":"","text":"前言logstash 通过配置文件把收集到的日志文件，通过正则匹配分析，发送到es服务器构建索引，并通过Kibana展示 目录 Logstash正则构建 查询语句 量化分析 Visualize 仪表盘 Dashboard Logstash正则匹配正则工具官方文档 在logstash目录 mkdir patterns 12# contents of ./patterns/postfix:STR [a-zA-Z]&#123;1,&#125; 12345678910111213141516171819input &#123; file &#123; type =&gt; \"order_shenghuojiaofei\"truepath =&gt; \"/Users/liuxin/rabbitmql_pro.log\" &#125; &#125;filter &#123; grok &#123; patterns_dir =&gt; [\"./patterns\"] match =&gt; &#123; \"message\" =&gt; \"%&#123;STR:logLevel&#125; %&#123;STR:packName&#125;.%&#123;STR:thread&#125;.%&#123;STR:className&#125; %&#123;STR:date&#125;\" &#125;true&#125; &#125;output &#123;trueelasticsearch &#123;truetruehosts =&gt; \"127.0.0.1:9200\"truetrueindex =&gt; \"order_shenghuojiaofei-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\"truetruetemplate_overwrite =&gt; truetruetrue &#125;true &#125; 启动 logstash -f pro.conf 查询语句I. 字段查询(可以使用通配符*或?) 1field:value 例：city:Keyport*， age:26 II. 范围查询 12age:[20 TO 30] age:&#123;20 TO 30&#125;注：[ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内 III. 逻辑操作 1234AND OR 例子：firstname:H* AND age:20 firstname:H* OR age:20+ ：搜索结果中必须包含此项- ：不能含有此项例： +firstname:H* -age:20 city:H* firstname字段结果中必须存在H开头的，不能有年龄是20的，city字段H开头的可有可无 VI. 分组查询 1234分组(firstname:H* OR age:20) AND state:KS 先查询名字H开头年龄或者是20的结果，然后再与国家是KS的结合字段分组firstname:(+H* -He*) 搜索firstname字段里H开头的结果，并且排除firstname里He开头的结果 量化分析点击发现 Discover 输入查询条件 鼠标放置在字段上会添加展示改字段 Kibana参考文档 仪表盘Visualize 生成的报表信息，可以保存，放置在仪表盘里面展示","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://lxchinesszz.github.io/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"ELK服务搭建之初识","slug":"ELK服务搭建之初识","date":"2016-01-12T03:27:45.000Z","updated":"2018-04-12T05:28:26.145Z","comments":true,"path":"2016/01/12/ELK服务搭建之初识/","link":"","permalink":"https://lxchinesszz.github.io/2016/01/12/ELK服务搭建之初识/","excerpt":"","text":"logback配置详情 ELK E elasticsearch 负责对日志进行索引 L logstash 负责收集日志,输出到els K Kibaba 负责展示es索引的页面 Kibaba5.5.0 只支持Es5.5.0及以上版本 安装 elasticsearch 注意问题 1234Likely root cause: expected '&lt;document start&gt;', but found BlockMappingStart in 'reader', line 54, column 1: network.bind_host: 0.0.0.0 ^ 解决办法 参数key 前面要加空格 最小配置1234567path.data: /Users/liuxin/elasticsearch-5.5.2/datapath.logs: /Users/liuxin/elasticsearch-5.5.2/logsnetwork.bind_host: 0.0.0.0 network.publish_host: 127.0.0.1 network.host: m000 elasticsearch.yml配置详解 下载地址 安装Logstash解压配置环境变量 12345678910111213141516 liuxin@MacBook-Pro  ~/logstash-2.4.0  cat pro.confinput &#123; file &#123; type =&gt; \"rabbitmq-test\" path =&gt; \"/Users/liuxin/rabbitmql_pro.log\"true &#125;true &#125;true output &#123;true elasticsearch &#123;true hosts =&gt; \"127.0.0.1:9200\"truetrue index =&gt; \"logstash-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\"truetrue template_overwrite =&gt; truetruetruetrue &#125;truetruetrue &#125; liuxin@MacBook-Pro  ~/logstash-2.4.0  启动命令 : logstash -f pro.conf Logstash详解 安装Kibaba最小配置 123server.port: 5601server.host: \"localhost\"elasticsearch.url: \"http://localhost:9200\" 启动 bash kibana 以上方法是通过logstash读取文件的形式收集日志也可以应用主动发起日志logback.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;configuration debug=\"false\"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name=\"LOG_HOME\" value=\"E:/logs\" /&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log_%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" /&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.QueryParameters\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.query.HQLQueryPlan\" level=\"DEBUG\" /&gt; &lt;!--myibatis log configure--&gt; &lt;logger name=\"com.apache.ibatis\" level=\"TRACE\" /&gt; &lt;logger name=\"java.sql.Connection\" level=\"DEBUG\" /&gt; &lt;logger name=\"java.sql.Statement\" level=\"DEBUG\" /&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"DEBUG\" /&gt; &lt;appender name=\"stash\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt; &lt;destination&gt;192.168.10.200:8082&lt;/destination&gt; &lt;!-- encoder is required --&gt; &lt;encoder charset=\"UTF-8\" class=\"net.logstash.logback.encoder.LogstashEncoder\" /&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=\"INFO\"&gt; &lt;!-- 只有添加stash关联才会被收集--&gt; &lt;appender-ref ref=\"stash\" /&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt;&lt;/configuration&gt; pom 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt;&lt;/dependency&gt;&lt;!--实现slf4j接口并整合--&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.logstash.log4j&lt;/groupId&gt; &lt;artifactId&gt;jsonevent-layout&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt;&lt;/dependency&gt;","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://lxchinesszz.github.io/tags/日志/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"CentOs配置防火墙","slug":"CentOs配置防火墙","date":"2015-06-12T10:31:57.000Z","updated":"2018-04-12T05:32:22.429Z","comments":true,"path":"2015/06/12/CentOs配置防火墙/","link":"","permalink":"https://lxchinesszz.github.io/2015/06/12/CentOs配置防火墙/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334使用命令的方式配置CentOS7防火墙##Addfirewall-cmd --permanent --zone=public --add-port=80/tcp##Removefirewall-cmd --permanent --zone=public --remove-port=80/tcp##Reloadfirewall-cmd --reload复制代码检查是否生效firewall-cmd --zone=public --query-port=80/tcp列出所有的开放端口firewall-cmd --list-all查看防火墙状态systemctl status firewalld.service启动防火墙systemctl start firewalld.service关闭防火墙systemctl stop firewalld.service重新启动防火墙systemctl restart firewalld.service","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"本地服务器搭建之秘钥登录","slug":"本地服务器搭建之秘钥登录","date":"2015-04-12T05:35:42.000Z","updated":"2018-04-12T05:36:51.604Z","comments":true,"path":"2015/04/12/本地服务器搭建之秘钥登录/","link":"","permalink":"https://lxchinesszz.github.io/2015/04/12/本地服务器搭建之秘钥登录/","excerpt":"","text":"作者：@lxchinesszz本文为作者原创，转载请注明出处 紧接上文，上文的重点不是连接，而是如何在局域网中用废弃的电脑搭建，是不是感觉很easy，那么这篇文章我们的重点就放在了安全上了，因为毕竟服务器是我们放应用或者数据库的地方，安全性一定要可靠。小编是做Java开发的，一只热爱技术的小菜鸟，因为工作中常常要一条龙服务，即，自己写需求文档，自己码代码，自己测试，自己部署，自己维护。虽然很累，但是很充实，很能提高自己。我也希望把自己的工作经验分享出来，对那些想小编一样热爱技术的小伙，有所帮助。说半天废话，下面开始。 密钥登录原理： 密钥常是一对的，即公钥和私钥，将公钥添加到服务器上的某个账户，然后客户端连接的时候，使用私钥完成认证就可以登录 A.使用私钥登录1.制作密钥对 首先在服务器制作，需要的登录账户，然后执行以下命令 12345678910[root@host ~]$ ssh-keygen #建立密钥对Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): #按 EnterCreated directory '/root/.ssh'.Enter passphrase (empty for no passphrase): # 输入密钥锁码，或直接按 Enter 留空Enter same passphrase again: # 再输入一遍密钥锁码Your identification has been saved in /root/.ssh/id_rsa. # 私钥Your public key has been saved in /root/.ssh/id_rsa.pub. # 公钥The key fingerprint is:0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:df:9b:cc:08 root@host 2.安装公钥到服务端 讲公钥安装到服务器 12[root@host ~]$ cd .ssh[root@host .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys 设置权限 12[root@host .ssh]$ chmod 600 authorized_keys #不让其他用户写入 600 权限[root@host .ssh]$ chmod 700 ~/.ssh #读写执行的权限 700 ssh的配置文件都在/etc/ssh/ 里面 1234[centos@localhost ~]$ cd /etc/ssh/[centos@localhost ssh]$ ls ssh_config #是客户单配置的 sshd_config #是服务端配置的 在sshd_config中配置使用RSA登录 1234RSAAuthentication yesPubkeyAuthentication yesPermitRootLogin yes # 允许root用户通过ssh登录PasswordAuthentication no #不允许密码登录，只用使用私钥登录[一般我也用yes] 最后服务端重启 ssh 1[root@host .ssh]$ service sshd restart 3.操作客户端 3.1把服务端私钥复制到客户端，cat id_rsa，就是一下内容 123456789101112131415161718192021222324252627282930-----BEGIN RSA PRIVATE KEY-----Proc-Type: 4,ENCRYPTEDDEK-Info: DES-EDE3-CBC,A757691CABE05419yvEX5nQY3+OeZ56kTt8i41YChrQgL9OwglA3SIU2ymrWvY+5IxXMOQbjJmoSFtRzOr0lB1eWZx8ZimGdG+y9KoN4AkUzX+HqzaC8/eMczrv2KXP6DpOvV6MTdHoBrTb8pJOSVzw1K1jmGPaCdWg3XJ7iNSdYr+FVHC6gmJhCCvSHjXLHYBseTSJNXzs4DpQrrTAnU1NXVt0ce3R7DCO/hGClS5zeQ7j7fpQ48cwBgNJumCcr5eU/TWlUMKm7Q8ZazLaugTg387qKaieFY6v8CvpqT4Oqt+j1+6B05sr2S4XiiWHdlcieG4fgSRc5I7kpEhzZWM2LdK6NtxkbWVzd0ZOu5dZDIaMykC2KJJwT+NW3yKZvN1iebm7jzLC3Pv1BdAqnzxMuwBVNbkvrmVWzi8+OvSfH3ttCoRVnshAAvPylBazAZpWn5k6f0QC8MkUQAIEFex80xBPJTT+L6HuijrO2Z1K6qeWe+ptUAqX3FrcuneH1Nn3MnOhNVb4HZvk0xoy3/+2xe3sYKOUsMqjpWlI3DzGnZ81R8z1sTquRQy3hHDZ8cA6k1wUWoVTpJArbCLphYurek+YN3kFGLhvKnd6YjnH3d2sq/qSIMp4m3T8iBkex5raf4iNpFwKzb3S9D6QSWl9Nfnd2tAWkApXU4TPOcbX7XtX1P5yexyNxAZaUHuDsPStO/53WHfu8G2BPnM2Pefaj1sUcODLK+4JR+edmtA9rjHXVx7Kd3OKRmpocmzYWgEOQJtklr+cL7SJJHzoKBjx0NB5/iW23KxSnj7gJhnrDbcD9wY5g63DuMsNnreMfk6trTbXe5ck/mfYN6bTCXkVczm5Q8BKY0cJF2n/2dJyow9RFJtxDTzm11SvqdXtZoanC5mttePViu3J88dbNETFw0DwutyY3KPq3taX40Ps76Ahh6BTb5QD8ctxpYx63MOfQG/BrPFD9M6All5YLzi1In3hc0s6GN2yvx/fdjNZpYFgxA0GH66evtlo3HMr/Id8zgZ+ZSikHMXpvpiXS4uBIgeCZeRaTbq/Bd2V2sN3ENQgV7UTVrnHDc5IWH+qpg8AZxnvmP6BBATNQ2WAc6I10JqkrtfwjKuSYGyJmg6fY5uSKkZo9JQ1uviWEyhdKDhtYgStxyoIznrbJE7PQ3iE3VanB0zmhJHdFJ9xsy5yggMSnRfLCmLsXrczJX0ALwtCDGrrAR3wAg1fn7WmdUfyfnAugJGOBMx25vOLASL3q5zKoxEr7ayln51uuWRE2oK63low68lcWt42aS/ozMsev6Wg7QQjg7HRYEavYZGmCv9OBAblOmneUQjajT2F6zY1R4Cajkk3XmBO2GHXJ685hTiBMQsGf81NMtGd2Zkd5jbcHYhfOe1TKRhgp9cxtzKuyzD2Hj5Bltw8Pq26JVqhLAXZpy73kVsCpU8KplyvZM349kM+VwzOwvvuoWuS+pi9iYYv2f4CjDWZ4dfzg30+ekEc2QTwsZrYbG8SyIOn4oZSE+ygFNge/o2ftqwpRSwJhV8sUlrhBHQb/plePpQQfRQlnifiqR/z2JQ4y28purVt5GKPuwsK4SpHCQTpXW3OkdA==-----END RSA PRIVATE KEY----- 把里面的内容复制（这个是我的）自己的文件下 12341.你也可以把服务端的id_rsa 下载到你的客户端，放在当前用户的.ssh目录下2.也可以复制里面的内容然后再.ssh目录下，重新创建一个id_rsavi ~/.ssh/id_rsa # 创建私钥 4.直接可以登录了【然后就会发现问题】123456789101112131415✘ ⚙ mac@MacBook-Air  ~/.ssh  ssh centos@192.168.1.112@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: UNPROTECTED PRIVATE KEY FILE! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@Permissions 0644 for '/Users/mac/.ssh/id_rsa' are too open.It is required that your private key files are NOT accessible by others.This private key will be ignored.Load key \"/Users/mac/.ssh/id_rsa\": bad permissionscentos@192.168.1.112's password:# 遇到这个问题一般就是权限问题 赋权700 ，然后就ok了⚙ mac@MacBook-Air  ~/.ssh  chmod 700 id_rsa⚙ mac@MacBook-Air  ~/.ssh  ssh centos@192.168.1.112Enter passphrase for key '/Users/mac/.ssh/id_rsa':Last login: Sun Feb 19 12:56:05 2017 from 192.168.1.113 B.设置安全端口 默认使用22端口，这个在etc/ssh/ssh_config 就可以看到 我们可以不使用22端口，此时我们可以在服务器重新创建一个端口，然后使用防火墙屏蔽其他端口 开启端口 开启一个10222端口 12345/sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT #写入修改 /etc/init.d/iptables save #保存修改 service iptables restart #重启防火墙，修改生效 ​ 然后可以查看一下端口状态 查看的时候一定要用root用户，否则查看不到的，所以我切换了10222 端口连接 端口的知识属于计算机的基础知识，如果你能看到这里，说明你的基础已经够了，不过下面我会专门写一篇关于底层的计算机的文章。 1234567891011121314151617181920[centos@localhost ssh]$ su root密码：[root@localhost ssh]# /etc/init.d/iptables status表格：filterChain INPUT (policy ACCEPT)num target prot opt source destination1 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:102222 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:102223 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED4 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/05 ACCEPT all -- 0.0.0.0/0 0.0.0.0/06 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:227 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT)num target prot opt source destination1 REJECT all -- 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT)num target prot opt source destination 服务端在/etc/ssh/sshd_config 中监听10222端口，然后就可以使用 1ssh -p 10222 centos@192.168.1.112","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"本地服务器搭建","slug":"本地服务器搭建","date":"2015-04-12T05:35:42.000Z","updated":"2018-04-12T05:36:06.998Z","comments":true,"path":"2015/04/12/本地服务器搭建/","link":"","permalink":"https://lxchinesszz.github.io/2015/04/12/本地服务器搭建/","excerpt":"","text":"工作之余，本人一直想买一台服务器，介于价格，一忍再忍，穷逼一个，无奈之下，萌生一个想法，通过自己的两台电脑，自己搭建一个服务器。 尤其之前用的ubuntu系统，用了三个多月，期间发现很多bug，所以准备换回centOS6，首先使用大白菜，把系统换位win10专业版，然后安装VMware10，在虚拟机里面安装CentOS6，因为两台电脑之间用的是同一个网络，所以可以互相连接。以下是我的操作步骤。 准备工作 两台电脑，同一个网络 1.服务器创建用户 首先创建一个组 groupadd -g 1500 maclink //g参数就是组id 如果不加默认是1000 开始 添加一个用户 useradd macuser -g maclink //添加一个用户名为macuser的用户在macgroup组中 如果你忘记你创建的组，那么使用下面的命令查看所有的组cat /etc/group 2.查看互相的ip mac系统和centOS中查看ip地址是 ifconfig # 这里我的mac地址是 192.168.1.107 # centOS中地址是设置和主机共享同一个网段 使用桥接方式，不要使用NAT方式，否则不是在一个网段 # centOS 中ip是 192.168.1.109 # 本篇文章最重要的地方就是这里，虚拟机中的服务器必须要和将要连接的电脑共处一个网段 # 所以必须使用桥接。 window系统中命令 ipconfig #windows下ip地址是 192.168.1.104 互相ping查看一下是否可以互相访问到Last login: Sun Feb 19 13:46:15 on ttys000 mac@MacBook-Air  ~  ping 192.168.1.109 PING 192.168.1.109 (192.168.1.109): 56 data bytes 64 bytes from 192.168.1.109: icmp_seq=0 ttl=64 time=139.139 ms 64 bytes from 192.168.1.109: icmp_seq=1 ttl=64 time=14.407 ms 64 bytes from 192.168.1.109: icmp_seq=2 ttl=64 time=173.413 ms 64 bytes from 192.168.1.109: icmp_seq=3 ttl=64 time=205.352 ms # 如果看到这里，那么已经成功一大半了 3.centOS中开方端口 ssl mac@192.168.1.109 //默认使用的22端口 ，因为没有使用安全连接，他会让你选择yes和no ✘ ⚙ mac@MacBook-Air  ~  ssh mac@192.168.1.109 The authenticity of host &apos;192.168.1.109 (192.168.1.109)&apos; can&apos;t be established. RSA key fingerprint is SHA256:8GcRL3cDzo3UHBCOTq5ExwKJ37VfTwJLBxZU0xWHBPY. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;192.168.1.109&apos; (RSA) to the list of known hosts. mac@192.168.1.109&apos;s password: [mac@localhost ~]$ ls Desktop Documents Downloads Music Pictures Public Templates Videos [mac@localhost ~]$ ls 这篇的内容就是这样，下一篇，使用安全连接 主要内容： 服务器生成安全密钥 服务器开放一个供访问的安全端口 使用ssl 公钥 安全连接 最后终级目标是将局域网地址映射到公网","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"服务器防止ping配置","slug":"服务器防止ping配置","date":"2015-04-12T05:31:25.000Z","updated":"2018-04-12T05:31:40.869Z","comments":true,"path":"2015/04/12/服务器防止ping配置/","link":"","permalink":"https://lxchinesszz.github.io/2015/04/12/服务器防止ping配置/","excerpt":"","text":"1echo 0 &gt;/proc/sys/net/ipv4/icmp_echo_ignore_all 0 开启ping1 不开启","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"me","slug":"me","date":"2015-03-11T15:37:26.000Z","updated":"2018-04-12T05:41:45.245Z","comments":true,"path":"2015/03/11/me/","link":"","permalink":"https://lxchinesszz.github.io/2015/03/11/me/","excerpt":"","text":"个人信息笔名: chinesszz , 网名: X , 非著名码农。生于1993年，籍贯河南，现居上海。电子商务专业,专注于基础架构和rpc通信框架研发。目前就职于某互联网软件服务公司 专注于企业微服务架构研究及开源框架底层源码研究 熟练运用各种流行的JavaEE技术进行组合式架构设计与开发。业余时间研究并发编程，中间件，异地多活，Spring Cloud，Netty等开源项目，以及软件架构设计，程序性能优化，JVM，高并发等！ 个人爱好 热爱技术,相信技术改变生活.喜欢阅读优秀框架源码,学习其设计模式,及编程技巧 热爱编程,熟练掌握Java,Python等主流编程语言及服务器Linux Bash脚本编程, 具有良好的笔记习惯, 具有快速学习的能力 喜欢记笔记,记录分享传播工作中学习到的知识,分享给同样热爱技术的人儿 宗旨本博客主要分享小编在日常工作遇到的实际问题和学习中读过的好文。希望通过博客文章,将知识分享给大家,我认为在企业应用架构实践中非常实用的干货内容。 意见反馈若本号内容有做得不到位的地方（比如：涉及版权或其他问题），请及时联系我进行整改。 联系方式邮箱: lxchinesszz@163.com 微信&amp;头条","categories":[{"name":"about","slug":"about","permalink":"https://lxchinesszz.github.io/categories/about/"}],"tags":[],"keywords":[{"name":"about","slug":"about","permalink":"https://lxchinesszz.github.io/categories/about/"}]},{"title":"Contos安装yum源","slug":"Contos安装yum源","date":"2015-01-11T05:30:05.000Z","updated":"2018-04-12T05:30:41.480Z","comments":true,"path":"2015/01/11/Contos安装yum源/","link":"","permalink":"https://lxchinesszz.github.io/2015/01/11/Contos安装yum源/","excerpt":"","text":"cd /etc/yum.repos.d/ 因为使用yum安装都是安装的rpm包，所以可以使用 rpm -ql 查看安装的目录 12345[root@iz2ze283ts0vfkcqfvduzdz ~]# cd /etc/yum.repos.d/[root@iz2ze283ts0vfkcqfvduzdz yum.repos.d]# lsCentOS-Base-Aliyun.repo epel-Aliyun.repo epel-testing.repo nginx.repoCentOS-Base.repo epel.repo jenkins.repo[root@iz2ze283ts0vfkcqfvduzdz yum.repos.d]#","categories":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://lxchinesszz.github.io/tags/服务器/"}],"keywords":[{"name":"杂记","slug":"杂记","permalink":"https://lxchinesszz.github.io/categories/杂记/"}]},{"title":"Git常用命令","slug":"GIt命令","date":"2015-01-11T03:49:42.000Z","updated":"2018-04-11T09:33:42.145Z","comments":true,"path":"2015/01/11/GIt命令/","link":"","permalink":"https://lxchinesszz.github.io/2015/01/11/GIt命令/","excerpt":"","text":"查看配置文件 1git config --list 本地项目添加到github 12345678910111213git init 初始化git add ./ 进行跟踪git commit -m '' 提交本地#根据github仓库git remote add origin https:liuxin..#如果上面操作失败说明已经绑定了一个，就删除之前的git remote rm origin#推到远程仓库git push -u origin master 查看最近提交信息 1git log 添加并提交git commit -am ‘message’相当于添加跟踪并提交 12git commit -am \"some str\"git push 回退到上一次提交的状态git revert HEAD1git revert HEAD 回退到某个版本git reset 057d 12回退到某个版本 git reset 830bc084264841... 查看当前分支git branch123KK-MINI:svc_shenghuojiaofei liuxin$ git branch develop* master 创建分支git branch feature12345KK-MINI:svc_shenghuojiaofei liuxin$ git branch featureKK-MINI:svc_shenghuojiaofei liuxin$ git branch develop feature* master 切换分支12345678KK-MINI:svc_shenghuojiaofei liuxin$ git checkout featureM .gitignoreM src/main/resource/application.propertiesSwitched to branch 'feature'KK-MINI:svc_shenghuojiaofei liuxin$ git branch develop* feature master 提交到最新分支 12345KK-MINI:svc_shenghuojiaofei liuxin$ git push -u origin featureTotal 0 (delta 0), reused 0 (delta 0)To https://github.com/kpboluome/svc_shenghuojiaofei.git * [new branch] feature -&gt; featureBranch feature set up to track remote branch feature from origin. 删除远程分支 git push origin --delete testfenzhi 删除本地分支 git branch -D stg 同步feature分支到master分支 git checkout master git merge feature git push origin master 回退所有内容到上一个版本 1git reset HEAD^ 回退a.py这个文件的版本到上一个版本 1git reset HEAD^ a.py ` 拉取远程分支到本地分支可以把远程某各分支拉去到本地的branchname下，如果没有branchname，则会在本地新建branchname git fetch origin branchname:branchname","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://lxchinesszz.github.io/tags/Git/"}],"keywords":[]}]}